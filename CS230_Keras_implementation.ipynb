{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS230_Keras_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VasuPatel001/CS-230/blob/main/CS230_Keras_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0hBTyMQfYmA"
      },
      "source": [
        "CS 230 Project work: \n",
        "This project analyzes the delta increase in electricity consumption from the extreme weather data in California. \n",
        "\n",
        "We will begin by importing our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDuxYNl4Wvzb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkiR1nbSMLeq",
        "outputId": "036cf7a3-3098-4a4c-a0c6-a004e23cd77d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iogCdyX1EBt"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/Shareddrives/CS_229_project/Electricity_Consumption_data/dataset.csv', usecols = ['AWND','PRCP','TAVG','TMIN','TMAX','CLASS_2']) #'SNWD' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xI2hU8t1SvH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "8c9a4cfd-1aa0-4b7e-a1d5-5dee10e8ed57"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AWND</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>TAVG</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>CLASS_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.581053</td>\n",
              "      <td>0.033469</td>\n",
              "      <td>77.408226</td>\n",
              "      <td>90.762660</td>\n",
              "      <td>65.968350</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.805790</td>\n",
              "      <td>0.076531</td>\n",
              "      <td>76.123030</td>\n",
              "      <td>90.015770</td>\n",
              "      <td>64.507890</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.076316</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>74.880130</td>\n",
              "      <td>88.255520</td>\n",
              "      <td>63.290222</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.569474</td>\n",
              "      <td>0.112245</td>\n",
              "      <td>73.870660</td>\n",
              "      <td>87.555210</td>\n",
              "      <td>62.066246</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.417368</td>\n",
              "      <td>0.071633</td>\n",
              "      <td>71.583595</td>\n",
              "      <td>84.826500</td>\n",
              "      <td>60.249210</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2331</th>\n",
              "      <td>4.100555</td>\n",
              "      <td>0.002041</td>\n",
              "      <td>49.119740</td>\n",
              "      <td>61.213593</td>\n",
              "      <td>40.197410</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2332</th>\n",
              "      <td>4.106471</td>\n",
              "      <td>0.021042</td>\n",
              "      <td>50.217533</td>\n",
              "      <td>59.652596</td>\n",
              "      <td>42.461040</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2333</th>\n",
              "      <td>4.422353</td>\n",
              "      <td>0.018667</td>\n",
              "      <td>49.600650</td>\n",
              "      <td>59.207790</td>\n",
              "      <td>41.918830</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2334</th>\n",
              "      <td>4.894118</td>\n",
              "      <td>0.004545</td>\n",
              "      <td>48.342020</td>\n",
              "      <td>59.690556</td>\n",
              "      <td>39.638435</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2335</th>\n",
              "      <td>4.735000</td>\n",
              "      <td>0.014583</td>\n",
              "      <td>50.446255</td>\n",
              "      <td>62.892510</td>\n",
              "      <td>40.843647</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2336 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          AWND      PRCP       TAVG       TMAX       TMIN  CLASS_2\n",
              "0     6.581053  0.033469  77.408226  90.762660  65.968350        3\n",
              "1     6.805790  0.076531  76.123030  90.015770  64.507890        3\n",
              "2     7.076316  0.037755  74.880130  88.255520  63.290222        2\n",
              "3     6.569474  0.112245  73.870660  87.555210  62.066246        2\n",
              "4     7.417368  0.071633  71.583595  84.826500  60.249210        2\n",
              "...        ...       ...        ...        ...        ...      ...\n",
              "2331  4.100555  0.002041  49.119740  61.213593  40.197410        1\n",
              "2332  4.106471  0.021042  50.217533  59.652596  42.461040        1\n",
              "2333  4.422353  0.018667  49.600650  59.207790  41.918830        1\n",
              "2334  4.894118  0.004545  48.342020  59.690556  39.638435        0\n",
              "2335  4.735000  0.014583  50.446255  62.892510  40.843647        0\n",
              "\n",
              "[2336 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lqmh1Gfl0dG"
      },
      "source": [
        "We now have imported our dataset. We move into creating our layers and then working through our layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB7AEXV91gGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9557186c-a8c2-4e7f-8b4d-168c22570025"
      },
      "source": [
        "#split train & test dataset\n",
        "train = dataset.sample(frac=0.95) #random_state=0\n",
        "test = dataset.drop(train.index)\n",
        "print(train.shape, test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2219, 6) (117, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_d8fi54MmUC"
      },
      "source": [
        "One hot encoding for Train & Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvWTdJ8N1hdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ef0f87-3c44-4d17-ed0a-4aeb359adb0d"
      },
      "source": [
        "#Create one-hot encoding for TRAIN dataset\n",
        "existing_vals = np.unique(train['CLASS_2'].values)\n",
        "mapping = {val: idx for idx, val in enumerate(existing_vals)}\n",
        "y_train = np.array([mapping[y] for y in train['CLASS_2'].values])\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "print(y_train.shape)\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2219, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br4Uxt-sMhUR",
        "outputId": "8005065e-0c57-4ae4-e94b-48f3bb4a4d09"
      },
      "source": [
        "#Create one-hot encoding for TEST dataset\n",
        "existing_vals = np.unique(test['CLASS_2'].values)\n",
        "mapping = {val: idx for idx, val in enumerate(existing_vals)}\n",
        "y_test = np.array([mapping[x] for x in test['CLASS_2'].values])\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "print(y_test.shape)\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(117, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qvf-GkB3-A1"
      },
      "source": [
        "sns.pairplot(train[['CLASS_2', 'AWND', 'PRCP', 'SNWD', 'TAVG', 'TMIN', 'TMAX']], diag_kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ujKmDhR0420y",
        "outputId": "e3881719-cda8-4443-85ca-4fb42b1a7096"
      },
      "source": [
        "train.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AWND</th>\n",
              "      <td>2102.0</td>\n",
              "      <td>6.519634</td>\n",
              "      <td>1.906891</td>\n",
              "      <td>2.522857</td>\n",
              "      <td>5.122941</td>\n",
              "      <td>6.461944</td>\n",
              "      <td>7.568333</td>\n",
              "      <td>14.142222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRCP</th>\n",
              "      <td>2211.0</td>\n",
              "      <td>0.088104</td>\n",
              "      <td>0.254537</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006122</td>\n",
              "      <td>0.047115</td>\n",
              "      <td>3.456250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAVG</th>\n",
              "      <td>2211.0</td>\n",
              "      <td>55.301625</td>\n",
              "      <td>17.893704</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.580130</td>\n",
              "      <td>55.825950</td>\n",
              "      <td>68.889085</td>\n",
              "      <td>109.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TMAX</th>\n",
              "      <td>2211.0</td>\n",
              "      <td>67.186107</td>\n",
              "      <td>16.061513</td>\n",
              "      <td>14.368421</td>\n",
              "      <td>54.529084</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>81.899015</td>\n",
              "      <td>98.060320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TMIN</th>\n",
              "      <td>2211.0</td>\n",
              "      <td>45.657361</td>\n",
              "      <td>11.622738</td>\n",
              "      <td>12.100000</td>\n",
              "      <td>37.513959</td>\n",
              "      <td>44.870663</td>\n",
              "      <td>55.507496</td>\n",
              "      <td>78.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASS_2</th>\n",
              "      <td>2219.0</td>\n",
              "      <td>1.290671</td>\n",
              "      <td>0.926398</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          count       mean        std  ...        50%        75%         max\n",
              "AWND     2102.0   6.519634   1.906891  ...   6.461944   7.568333   14.142222\n",
              "PRCP     2211.0   0.088104   0.254537  ...   0.006122   0.047115    3.456250\n",
              "TAVG     2211.0  55.301625  17.893704  ...  55.825950  68.889085  109.000000\n",
              "TMAX     2211.0  67.186107  16.061513  ...  67.000000  81.899015   98.060320\n",
              "TMIN     2211.0  45.657361  11.622738  ...  44.870663  55.507496   78.000000\n",
              "CLASS_2  2219.0   1.290671   0.926398  ...   1.000000   2.000000    4.000000\n",
              "\n",
              "[6 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "p6tu0rv5STap",
        "outputId": "495422c9-ee63-45ad-c40e-853f5b1cd9a5"
      },
      "source": [
        "test.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AWND</th>\n",
              "      <td>112.0</td>\n",
              "      <td>6.549851</td>\n",
              "      <td>1.871273</td>\n",
              "      <td>2.972857</td>\n",
              "      <td>5.298865</td>\n",
              "      <td>6.519706</td>\n",
              "      <td>7.806805</td>\n",
              "      <td>12.339444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRCP</th>\n",
              "      <td>117.0</td>\n",
              "      <td>0.076639</td>\n",
              "      <td>0.155709</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.008163</td>\n",
              "      <td>0.056735</td>\n",
              "      <td>0.782917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAVG</th>\n",
              "      <td>117.0</td>\n",
              "      <td>55.282767</td>\n",
              "      <td>17.697591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.212220</td>\n",
              "      <td>55.444443</td>\n",
              "      <td>68.885710</td>\n",
              "      <td>95.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TMAX</th>\n",
              "      <td>117.0</td>\n",
              "      <td>67.332090</td>\n",
              "      <td>16.207734</td>\n",
              "      <td>25.605263</td>\n",
              "      <td>54.705128</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>81.873020</td>\n",
              "      <td>96.248405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TMIN</th>\n",
              "      <td>117.0</td>\n",
              "      <td>46.428440</td>\n",
              "      <td>11.736354</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>38.603176</td>\n",
              "      <td>45.443730</td>\n",
              "      <td>55.942123</td>\n",
              "      <td>74.236840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASS_2</th>\n",
              "      <td>117.0</td>\n",
              "      <td>1.290598</td>\n",
              "      <td>1.009095</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         count       mean        std  ...        50%        75%        max\n",
              "AWND     112.0   6.549851   1.871273  ...   6.519706   7.806805  12.339444\n",
              "PRCP     117.0   0.076639   0.155709  ...   0.008163   0.056735   0.782917\n",
              "TAVG     117.0  55.282767  17.697591  ...  55.444443  68.885710  95.000000\n",
              "TMAX     117.0  67.332090  16.207734  ...  67.000000  81.873020  96.248405\n",
              "TMIN     117.0  46.428440  11.736354  ...  45.443730  55.942123  74.236840\n",
              "CLASS_2  117.0   1.290598   1.009095  ...   1.000000   2.000000   4.000000\n",
              "\n",
              "[6 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaDtLACtRq5L"
      },
      "source": [
        "Train and test data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBRZsslm6YC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91681440-2f22-4893-f6d0-418e84d8c37d"
      },
      "source": [
        "#train data normalization\n",
        "train_features = train.copy()\n",
        "train_labels = train_features.pop('CLASS_2')\n",
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "378     3\n",
              "1345    0\n",
              "1321    1\n",
              "1480    1\n",
              "2219    3\n",
              "       ..\n",
              "1231    1\n",
              "1035    1\n",
              "2178    3\n",
              "2072    1\n",
              "1730    0\n",
              "Name: CLASS_2, Length: 2219, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYiNAmceOHpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f9412a-af12-4bad-de2b-6a2f44094b6d"
      },
      "source": [
        "#test data normalization\n",
        "test_features = test.copy()\n",
        "test_labels = test_features.pop('CLASS_2')\n",
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35      3\n",
              "51      2\n",
              "58      4\n",
              "101     2\n",
              "108     1\n",
              "       ..\n",
              "2239    3\n",
              "2242    2\n",
              "2266    2\n",
              "2281    1\n",
              "2304    1\n",
              "Name: CLASS_2, Length: 117, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Fp7QJocycz",
        "outputId": "b1921d56-13b2-4c79-bb46-5e758147b036"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnrfNh186YIm"
      },
      "source": [
        "# train_features.shape\n",
        "x_train_clean = train_features.fillna(0).dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QKt5fMp-Rpyo",
        "outputId": "73ece172-ddd1-47e3-da6c-3d04c5083049"
      },
      "source": [
        "#test feature cleaning \n",
        "x_test_clean = test_features.fillna(0).dropna()\n",
        "x_test_clean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AWND</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>TAVG</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>5.510526</td>\n",
              "      <td>0.002041</td>\n",
              "      <td>70.357600</td>\n",
              "      <td>84.490510</td>\n",
              "      <td>57.310127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>6.275789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.155556</td>\n",
              "      <td>84.968254</td>\n",
              "      <td>57.701588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>6.310000</td>\n",
              "      <td>0.002041</td>\n",
              "      <td>76.155556</td>\n",
              "      <td>90.707940</td>\n",
              "      <td>62.888890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>5.967895</td>\n",
              "      <td>0.005714</td>\n",
              "      <td>68.885710</td>\n",
              "      <td>82.628570</td>\n",
              "      <td>57.120636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>6.358947</td>\n",
              "      <td>0.546735</td>\n",
              "      <td>58.917460</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>52.463493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2239</th>\n",
              "      <td>8.264117</td>\n",
              "      <td>0.019149</td>\n",
              "      <td>71.077670</td>\n",
              "      <td>83.404530</td>\n",
              "      <td>59.611652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2242</th>\n",
              "      <td>6.235882</td>\n",
              "      <td>0.004255</td>\n",
              "      <td>67.135925</td>\n",
              "      <td>80.822010</td>\n",
              "      <td>55.110030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2266</th>\n",
              "      <td>5.418334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.154340</td>\n",
              "      <td>86.845660</td>\n",
              "      <td>57.784565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2281</th>\n",
              "      <td>8.894117</td>\n",
              "      <td>0.032609</td>\n",
              "      <td>54.893547</td>\n",
              "      <td>66.161290</td>\n",
              "      <td>45.558064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2304</th>\n",
              "      <td>5.863572</td>\n",
              "      <td>0.387083</td>\n",
              "      <td>57.356915</td>\n",
              "      <td>67.331190</td>\n",
              "      <td>49.202570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          AWND      PRCP       TAVG       TMAX       TMIN\n",
              "35    5.510526  0.002041  70.357600  84.490510  57.310127\n",
              "51    6.275789  0.000000  70.155556  84.968254  57.701588\n",
              "58    6.310000  0.002041  76.155556  90.707940  62.888890\n",
              "101   5.967895  0.005714  68.885710  82.628570  57.120636\n",
              "108   6.358947  0.546735  58.917460  67.000000  52.463493\n",
              "...        ...       ...        ...        ...        ...\n",
              "2239  8.264117  0.019149  71.077670  83.404530  59.611652\n",
              "2242  6.235882  0.004255  67.135925  80.822010  55.110030\n",
              "2266  5.418334  0.000000  71.154340  86.845660  57.784565\n",
              "2281  8.894117  0.032609  54.893547  66.161290  45.558064\n",
              "2304  5.863572  0.387083  57.356915  67.331190  49.202570\n",
              "\n",
              "[117 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt6zgMZnSH81"
      },
      "source": [
        "Normalizing our train & test clean data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8XIfk1H6YPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08a4ba8-f2a5-4288-d79f-4247e06108ef"
      },
      "source": [
        "#normalize x_train_clean \n",
        "normalizer = tf.keras.layers.Normalization()\n",
        "normalizer.adapt(x_train_clean)\n",
        "x_train_norm = normalizer(x_train_clean)\n",
        "x_train_norm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2219, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM-JR3vBSlkn",
        "outputId": "b2ed2c15-adf4-478b-a99f-9543b694c9c8"
      },
      "source": [
        "#normalize x_test_clean\n",
        "normalizer = tf.keras.layers.Normalization()\n",
        "normalizer.adapt(x_test_clean)\n",
        "x_test_norm = normalizer(x_test_clean)\n",
        "x_test_norm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([117, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpj3CHXPPnr5"
      },
      "source": [
        "Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzPD35aNX20J"
      },
      "source": [
        "#Import CLASS_2es\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "\n",
        "#Model Definition\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(5,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbpGwJ8yZmkj"
      },
      "source": [
        "#Configure model training\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy']) # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKJT5w7DPsc1"
      },
      "source": [
        "Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Z7a2wiZ1qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bb870d-041a-4bf9-942b-94f2060391ff"
      },
      "source": [
        "#train model\n",
        "from keras import backend as K\n",
        "K.set_value(model.optimizer.learning_rate, 0.0005)\n",
        "history = model.fit(x_train_norm, y_train, validation_split=0.1, epochs=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "63/63 [==============================] - 1s 6ms/step - loss: 1.4173 - accuracy: 0.4827 - val_loss: 1.1031 - val_accuracy: 0.5315\n",
            "Epoch 2/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0905 - accuracy: 0.5714 - val_loss: 0.8847 - val_accuracy: 0.6396\n",
            "Epoch 3/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9588 - accuracy: 0.6164 - val_loss: 0.8011 - val_accuracy: 0.6667\n",
            "Epoch 4/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9449 - accuracy: 0.6029 - val_loss: 0.7674 - val_accuracy: 0.6802\n",
            "Epoch 5/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8885 - accuracy: 0.6279 - val_loss: 0.7491 - val_accuracy: 0.6712\n",
            "Epoch 6/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8791 - accuracy: 0.6179 - val_loss: 0.7478 - val_accuracy: 0.6847\n",
            "Epoch 7/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8495 - accuracy: 0.6309 - val_loss: 0.7364 - val_accuracy: 0.6892\n",
            "Epoch 8/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8588 - accuracy: 0.6259 - val_loss: 0.7198 - val_accuracy: 0.6712\n",
            "Epoch 9/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8495 - accuracy: 0.6470 - val_loss: 0.7488 - val_accuracy: 0.6847\n",
            "Epoch 10/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8328 - accuracy: 0.6360 - val_loss: 0.7229 - val_accuracy: 0.6712\n",
            "Epoch 11/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8257 - accuracy: 0.6480 - val_loss: 0.7257 - val_accuracy: 0.6757\n",
            "Epoch 12/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8416 - accuracy: 0.6375 - val_loss: 0.7210 - val_accuracy: 0.6757\n",
            "Epoch 13/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8161 - accuracy: 0.6570 - val_loss: 0.7267 - val_accuracy: 0.6847\n",
            "Epoch 14/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8306 - accuracy: 0.6425 - val_loss: 0.7202 - val_accuracy: 0.6892\n",
            "Epoch 15/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8049 - accuracy: 0.6460 - val_loss: 0.7366 - val_accuracy: 0.6712\n",
            "Epoch 16/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8150 - accuracy: 0.6345 - val_loss: 0.7129 - val_accuracy: 0.6892\n",
            "Epoch 17/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7948 - accuracy: 0.6525 - val_loss: 0.7184 - val_accuracy: 0.6802\n",
            "Epoch 18/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7864 - accuracy: 0.6540 - val_loss: 0.7271 - val_accuracy: 0.6937\n",
            "Epoch 19/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8042 - accuracy: 0.6485 - val_loss: 0.7228 - val_accuracy: 0.6892\n",
            "Epoch 20/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.8051 - accuracy: 0.6460 - val_loss: 0.7149 - val_accuracy: 0.6667\n",
            "Epoch 21/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7894 - accuracy: 0.6540 - val_loss: 0.7343 - val_accuracy: 0.6712\n",
            "Epoch 22/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7744 - accuracy: 0.6655 - val_loss: 0.7164 - val_accuracy: 0.6757\n",
            "Epoch 23/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7866 - accuracy: 0.6545 - val_loss: 0.7126 - val_accuracy: 0.6847\n",
            "Epoch 24/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7836 - accuracy: 0.6620 - val_loss: 0.7159 - val_accuracy: 0.6667\n",
            "Epoch 25/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7824 - accuracy: 0.6535 - val_loss: 0.7113 - val_accuracy: 0.6712\n",
            "Epoch 26/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7665 - accuracy: 0.6630 - val_loss: 0.7158 - val_accuracy: 0.6847\n",
            "Epoch 27/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7797 - accuracy: 0.6595 - val_loss: 0.7170 - val_accuracy: 0.6667\n",
            "Epoch 28/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7666 - accuracy: 0.6620 - val_loss: 0.7001 - val_accuracy: 0.6712\n",
            "Epoch 29/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7660 - accuracy: 0.6600 - val_loss: 0.6924 - val_accuracy: 0.6757\n",
            "Epoch 30/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7732 - accuracy: 0.6610 - val_loss: 0.6955 - val_accuracy: 0.6667\n",
            "Epoch 31/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7661 - accuracy: 0.6570 - val_loss: 0.7070 - val_accuracy: 0.6757\n",
            "Epoch 32/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7651 - accuracy: 0.6645 - val_loss: 0.6977 - val_accuracy: 0.6757\n",
            "Epoch 33/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7701 - accuracy: 0.6610 - val_loss: 0.7134 - val_accuracy: 0.6802\n",
            "Epoch 34/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7663 - accuracy: 0.6595 - val_loss: 0.7049 - val_accuracy: 0.6757\n",
            "Epoch 35/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7604 - accuracy: 0.6585 - val_loss: 0.7261 - val_accuracy: 0.6757\n",
            "Epoch 36/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7624 - accuracy: 0.6640 - val_loss: 0.6987 - val_accuracy: 0.6802\n",
            "Epoch 37/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7692 - accuracy: 0.6590 - val_loss: 0.6974 - val_accuracy: 0.6667\n",
            "Epoch 38/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7542 - accuracy: 0.6725 - val_loss: 0.6982 - val_accuracy: 0.6712\n",
            "Epoch 39/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.6620 - val_loss: 0.7066 - val_accuracy: 0.6622\n",
            "Epoch 40/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7490 - accuracy: 0.6645 - val_loss: 0.7026 - val_accuracy: 0.6577\n",
            "Epoch 41/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.6665 - val_loss: 0.6898 - val_accuracy: 0.6667\n",
            "Epoch 42/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7520 - accuracy: 0.6680 - val_loss: 0.6919 - val_accuracy: 0.6667\n",
            "Epoch 43/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7508 - accuracy: 0.6650 - val_loss: 0.6924 - val_accuracy: 0.6757\n",
            "Epoch 44/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.6600 - val_loss: 0.6930 - val_accuracy: 0.6802\n",
            "Epoch 45/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.6590 - val_loss: 0.7058 - val_accuracy: 0.6712\n",
            "Epoch 46/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.6640 - val_loss: 0.6922 - val_accuracy: 0.6712\n",
            "Epoch 47/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.6565 - val_loss: 0.6986 - val_accuracy: 0.6667\n",
            "Epoch 48/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.6670 - val_loss: 0.6936 - val_accuracy: 0.6577\n",
            "Epoch 49/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7664 - accuracy: 0.6680 - val_loss: 0.6864 - val_accuracy: 0.6757\n",
            "Epoch 50/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7340 - accuracy: 0.6650 - val_loss: 0.6956 - val_accuracy: 0.6712\n",
            "Epoch 51/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.6665 - val_loss: 0.6990 - val_accuracy: 0.6802\n",
            "Epoch 52/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.6710 - val_loss: 0.6853 - val_accuracy: 0.6622\n",
            "Epoch 53/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7565 - accuracy: 0.6610 - val_loss: 0.6886 - val_accuracy: 0.6667\n",
            "Epoch 54/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7524 - accuracy: 0.6665 - val_loss: 0.7003 - val_accuracy: 0.6712\n",
            "Epoch 55/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7258 - accuracy: 0.6740 - val_loss: 0.6806 - val_accuracy: 0.6622\n",
            "Epoch 56/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7297 - accuracy: 0.6715 - val_loss: 0.6796 - val_accuracy: 0.6802\n",
            "Epoch 57/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.6660 - val_loss: 0.6790 - val_accuracy: 0.6712\n",
            "Epoch 58/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.6685 - val_loss: 0.6767 - val_accuracy: 0.6622\n",
            "Epoch 59/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7322 - accuracy: 0.6685 - val_loss: 0.7019 - val_accuracy: 0.6667\n",
            "Epoch 60/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.6735 - val_loss: 0.6897 - val_accuracy: 0.6712\n",
            "Epoch 61/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7327 - accuracy: 0.6695 - val_loss: 0.6944 - val_accuracy: 0.6712\n",
            "Epoch 62/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.6740 - val_loss: 0.6854 - val_accuracy: 0.6712\n",
            "Epoch 63/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.6750 - val_loss: 0.6868 - val_accuracy: 0.6667\n",
            "Epoch 64/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.6685 - val_loss: 0.6874 - val_accuracy: 0.6757\n",
            "Epoch 65/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.6680 - val_loss: 0.6870 - val_accuracy: 0.6802\n",
            "Epoch 66/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.6635 - val_loss: 0.6871 - val_accuracy: 0.6712\n",
            "Epoch 67/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.6755 - val_loss: 0.6897 - val_accuracy: 0.6802\n",
            "Epoch 68/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7164 - accuracy: 0.6755 - val_loss: 0.6714 - val_accuracy: 0.6757\n",
            "Epoch 69/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.6730 - val_loss: 0.6770 - val_accuracy: 0.6667\n",
            "Epoch 70/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7215 - accuracy: 0.6705 - val_loss: 0.6940 - val_accuracy: 0.6757\n",
            "Epoch 71/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.6760 - val_loss: 0.6783 - val_accuracy: 0.6757\n",
            "Epoch 72/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7233 - accuracy: 0.6720 - val_loss: 0.6898 - val_accuracy: 0.6802\n",
            "Epoch 73/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.6635 - val_loss: 0.6943 - val_accuracy: 0.6757\n",
            "Epoch 74/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7267 - accuracy: 0.6725 - val_loss: 0.6989 - val_accuracy: 0.6757\n",
            "Epoch 75/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7296 - accuracy: 0.6690 - val_loss: 0.6840 - val_accuracy: 0.6802\n",
            "Epoch 76/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7227 - accuracy: 0.6675 - val_loss: 0.6671 - val_accuracy: 0.6667\n",
            "Epoch 77/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7235 - accuracy: 0.6720 - val_loss: 0.6748 - val_accuracy: 0.6757\n",
            "Epoch 78/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7226 - accuracy: 0.6760 - val_loss: 0.6800 - val_accuracy: 0.6622\n",
            "Epoch 79/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.6725 - val_loss: 0.6944 - val_accuracy: 0.6712\n",
            "Epoch 80/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7253 - accuracy: 0.6695 - val_loss: 0.6949 - val_accuracy: 0.6757\n",
            "Epoch 81/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.6760 - val_loss: 0.6976 - val_accuracy: 0.6802\n",
            "Epoch 82/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7177 - accuracy: 0.6785 - val_loss: 0.6793 - val_accuracy: 0.6757\n",
            "Epoch 83/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.6785 - val_loss: 0.6813 - val_accuracy: 0.6847\n",
            "Epoch 84/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.6705 - val_loss: 0.6771 - val_accuracy: 0.6802\n",
            "Epoch 85/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.6725 - val_loss: 0.6787 - val_accuracy: 0.6757\n",
            "Epoch 86/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.6760 - val_loss: 0.6669 - val_accuracy: 0.6757\n",
            "Epoch 87/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7240 - accuracy: 0.6765 - val_loss: 0.6746 - val_accuracy: 0.6802\n",
            "Epoch 88/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7088 - accuracy: 0.6780 - val_loss: 0.6830 - val_accuracy: 0.6847\n",
            "Epoch 89/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 0.6715 - val_loss: 0.6817 - val_accuracy: 0.6802\n",
            "Epoch 90/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7177 - accuracy: 0.6715 - val_loss: 0.6804 - val_accuracy: 0.6757\n",
            "Epoch 91/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.6835 - val_loss: 0.6826 - val_accuracy: 0.6712\n",
            "Epoch 92/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7182 - accuracy: 0.6790 - val_loss: 0.6744 - val_accuracy: 0.6622\n",
            "Epoch 93/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7065 - accuracy: 0.6795 - val_loss: 0.6768 - val_accuracy: 0.6847\n",
            "Epoch 94/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7053 - accuracy: 0.6825 - val_loss: 0.6756 - val_accuracy: 0.6802\n",
            "Epoch 95/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7251 - accuracy: 0.6700 - val_loss: 0.6758 - val_accuracy: 0.6667\n",
            "Epoch 96/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7129 - accuracy: 0.6760 - val_loss: 0.6758 - val_accuracy: 0.6712\n",
            "Epoch 97/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7161 - accuracy: 0.6695 - val_loss: 0.6888 - val_accuracy: 0.6712\n",
            "Epoch 98/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.6700 - val_loss: 0.6935 - val_accuracy: 0.6892\n",
            "Epoch 99/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.6685 - val_loss: 0.6876 - val_accuracy: 0.6712\n",
            "Epoch 100/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.6785 - val_loss: 0.6729 - val_accuracy: 0.6757\n",
            "Epoch 101/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7093 - accuracy: 0.6665 - val_loss: 0.6744 - val_accuracy: 0.6712\n",
            "Epoch 102/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.6750 - val_loss: 0.6740 - val_accuracy: 0.6712\n",
            "Epoch 103/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.6795 - val_loss: 0.7002 - val_accuracy: 0.6712\n",
            "Epoch 104/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7150 - accuracy: 0.6775 - val_loss: 0.6793 - val_accuracy: 0.6712\n",
            "Epoch 105/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7169 - accuracy: 0.6715 - val_loss: 0.6668 - val_accuracy: 0.6757\n",
            "Epoch 106/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7142 - accuracy: 0.6730 - val_loss: 0.6788 - val_accuracy: 0.6712\n",
            "Epoch 107/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7125 - accuracy: 0.6810 - val_loss: 0.6958 - val_accuracy: 0.6847\n",
            "Epoch 108/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7113 - accuracy: 0.6745 - val_loss: 0.6759 - val_accuracy: 0.6757\n",
            "Epoch 109/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.6865 - val_loss: 0.6748 - val_accuracy: 0.6802\n",
            "Epoch 110/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7072 - accuracy: 0.6740 - val_loss: 0.6777 - val_accuracy: 0.6622\n",
            "Epoch 111/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.6730 - val_loss: 0.6832 - val_accuracy: 0.6802\n",
            "Epoch 112/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.6785 - val_loss: 0.6634 - val_accuracy: 0.6712\n",
            "Epoch 113/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7196 - accuracy: 0.6745 - val_loss: 0.6655 - val_accuracy: 0.6802\n",
            "Epoch 114/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.6830 - val_loss: 0.6841 - val_accuracy: 0.6712\n",
            "Epoch 115/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7089 - accuracy: 0.6790 - val_loss: 0.6889 - val_accuracy: 0.6802\n",
            "Epoch 116/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7156 - accuracy: 0.6780 - val_loss: 0.6809 - val_accuracy: 0.6802\n",
            "Epoch 117/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.6845 - val_loss: 0.6744 - val_accuracy: 0.6622\n",
            "Epoch 118/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7151 - accuracy: 0.6765 - val_loss: 0.6665 - val_accuracy: 0.6667\n",
            "Epoch 119/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.6725 - val_loss: 0.6803 - val_accuracy: 0.6622\n",
            "Epoch 120/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.6740 - val_loss: 0.6954 - val_accuracy: 0.6757\n",
            "Epoch 121/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.6770 - val_loss: 0.6711 - val_accuracy: 0.6622\n",
            "Epoch 122/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.6840 - val_loss: 0.6768 - val_accuracy: 0.6757\n",
            "Epoch 123/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.6775 - val_loss: 0.6693 - val_accuracy: 0.6712\n",
            "Epoch 124/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.6765 - val_loss: 0.6723 - val_accuracy: 0.6667\n",
            "Epoch 125/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.6805 - val_loss: 0.6837 - val_accuracy: 0.6712\n",
            "Epoch 126/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.6790 - val_loss: 0.6725 - val_accuracy: 0.6577\n",
            "Epoch 127/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.6810 - val_loss: 0.6593 - val_accuracy: 0.6712\n",
            "Epoch 128/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.6780 - val_loss: 0.6660 - val_accuracy: 0.6712\n",
            "Epoch 129/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7075 - accuracy: 0.6775 - val_loss: 0.6588 - val_accuracy: 0.6802\n",
            "Epoch 130/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.6815 - val_loss: 0.6713 - val_accuracy: 0.6802\n",
            "Epoch 131/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.6725 - val_loss: 0.6852 - val_accuracy: 0.6847\n",
            "Epoch 132/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.6825 - val_loss: 0.6734 - val_accuracy: 0.6802\n",
            "Epoch 133/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.6875 - val_loss: 0.6828 - val_accuracy: 0.6667\n",
            "Epoch 134/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.6775 - val_loss: 0.6685 - val_accuracy: 0.6757\n",
            "Epoch 135/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.6760 - val_loss: 0.6554 - val_accuracy: 0.6802\n",
            "Epoch 136/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7070 - accuracy: 0.6760 - val_loss: 0.6693 - val_accuracy: 0.6757\n",
            "Epoch 137/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.6745 - val_loss: 0.6690 - val_accuracy: 0.6757\n",
            "Epoch 138/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7113 - accuracy: 0.6750 - val_loss: 0.6682 - val_accuracy: 0.6802\n",
            "Epoch 139/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.6770 - val_loss: 0.6500 - val_accuracy: 0.6802\n",
            "Epoch 140/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.6780 - val_loss: 0.6696 - val_accuracy: 0.6712\n",
            "Epoch 141/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.6835 - val_loss: 0.6796 - val_accuracy: 0.6622\n",
            "Epoch 142/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6785 - val_loss: 0.6736 - val_accuracy: 0.6667\n",
            "Epoch 143/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.6785 - val_loss: 0.6676 - val_accuracy: 0.6757\n",
            "Epoch 144/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.6735 - val_loss: 0.6806 - val_accuracy: 0.6757\n",
            "Epoch 145/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.6870 - val_loss: 0.6733 - val_accuracy: 0.6757\n",
            "Epoch 146/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.6815 - val_loss: 0.6820 - val_accuracy: 0.6847\n",
            "Epoch 147/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6992 - accuracy: 0.6770 - val_loss: 0.6765 - val_accuracy: 0.6847\n",
            "Epoch 148/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.6830 - val_loss: 0.6726 - val_accuracy: 0.6757\n",
            "Epoch 149/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6982 - accuracy: 0.6745 - val_loss: 0.6770 - val_accuracy: 0.6712\n",
            "Epoch 150/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.6820 - val_loss: 0.6581 - val_accuracy: 0.6847\n",
            "Epoch 151/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.6845 - val_loss: 0.6773 - val_accuracy: 0.6802\n",
            "Epoch 152/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.6815 - val_loss: 0.6571 - val_accuracy: 0.6847\n",
            "Epoch 153/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.6770 - val_loss: 0.6667 - val_accuracy: 0.6712\n",
            "Epoch 154/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.6770 - val_loss: 0.6705 - val_accuracy: 0.6757\n",
            "Epoch 155/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.6765 - val_loss: 0.6632 - val_accuracy: 0.6757\n",
            "Epoch 156/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.6800 - val_loss: 0.6586 - val_accuracy: 0.6757\n",
            "Epoch 157/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.6800 - val_loss: 0.6795 - val_accuracy: 0.6757\n",
            "Epoch 158/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.6755 - val_loss: 0.6797 - val_accuracy: 0.6757\n",
            "Epoch 159/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.6800 - val_loss: 0.6782 - val_accuracy: 0.6757\n",
            "Epoch 160/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.6775 - val_loss: 0.6838 - val_accuracy: 0.6757\n",
            "Epoch 161/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.6830 - val_loss: 0.6675 - val_accuracy: 0.6712\n",
            "Epoch 162/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.6720 - val_loss: 0.6644 - val_accuracy: 0.6712\n",
            "Epoch 163/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.6825 - val_loss: 0.6675 - val_accuracy: 0.6757\n",
            "Epoch 164/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.6820 - val_loss: 0.6762 - val_accuracy: 0.6802\n",
            "Epoch 165/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6785 - val_loss: 0.6678 - val_accuracy: 0.6757\n",
            "Epoch 166/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.6840 - val_loss: 0.6819 - val_accuracy: 0.6802\n",
            "Epoch 167/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.6830 - val_loss: 0.6859 - val_accuracy: 0.6802\n",
            "Epoch 168/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.6695 - val_loss: 0.6665 - val_accuracy: 0.6712\n",
            "Epoch 169/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.6845 - val_loss: 0.6693 - val_accuracy: 0.6802\n",
            "Epoch 170/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.6830 - val_loss: 0.6676 - val_accuracy: 0.6757\n",
            "Epoch 171/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.6785 - val_loss: 0.6660 - val_accuracy: 0.6802\n",
            "Epoch 172/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.6770 - val_loss: 0.6921 - val_accuracy: 0.6847\n",
            "Epoch 173/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.6900 - val_loss: 0.6770 - val_accuracy: 0.6712\n",
            "Epoch 174/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.6825 - val_loss: 0.6756 - val_accuracy: 0.6712\n",
            "Epoch 175/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.6820 - val_loss: 0.6698 - val_accuracy: 0.6757\n",
            "Epoch 176/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.6835 - val_loss: 0.6659 - val_accuracy: 0.6757\n",
            "Epoch 177/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.6745 - val_loss: 0.6742 - val_accuracy: 0.6757\n",
            "Epoch 178/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.6850 - val_loss: 0.6636 - val_accuracy: 0.6802\n",
            "Epoch 179/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.6825 - val_loss: 0.6815 - val_accuracy: 0.6712\n",
            "Epoch 180/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.6800 - val_loss: 0.6852 - val_accuracy: 0.6847\n",
            "Epoch 181/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.6830 - val_loss: 0.6774 - val_accuracy: 0.6847\n",
            "Epoch 182/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.6800 - val_loss: 0.6766 - val_accuracy: 0.6802\n",
            "Epoch 183/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.6830 - val_loss: 0.6735 - val_accuracy: 0.6802\n",
            "Epoch 184/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.6840 - val_loss: 0.6745 - val_accuracy: 0.6712\n",
            "Epoch 185/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.6870 - val_loss: 0.6797 - val_accuracy: 0.6667\n",
            "Epoch 186/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.6765 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
            "Epoch 187/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.6735 - val_loss: 0.6701 - val_accuracy: 0.6757\n",
            "Epoch 188/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.6845 - val_loss: 0.6794 - val_accuracy: 0.6847\n",
            "Epoch 189/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.6830 - val_loss: 0.6831 - val_accuracy: 0.6847\n",
            "Epoch 190/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.6765 - val_loss: 0.6834 - val_accuracy: 0.6757\n",
            "Epoch 191/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.6740 - val_loss: 0.6719 - val_accuracy: 0.6712\n",
            "Epoch 192/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.6740 - val_loss: 0.6611 - val_accuracy: 0.6847\n",
            "Epoch 193/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.6790 - val_loss: 0.6770 - val_accuracy: 0.6802\n",
            "Epoch 194/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.6805 - val_loss: 0.6699 - val_accuracy: 0.6802\n",
            "Epoch 195/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.6705 - val_loss: 0.6610 - val_accuracy: 0.6892\n",
            "Epoch 196/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6770 - val_loss: 0.6748 - val_accuracy: 0.6802\n",
            "Epoch 197/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.6845 - val_loss: 0.6620 - val_accuracy: 0.6892\n",
            "Epoch 198/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.6795 - val_loss: 0.6558 - val_accuracy: 0.6802\n",
            "Epoch 199/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.6770 - val_loss: 0.6673 - val_accuracy: 0.6757\n",
            "Epoch 200/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.6790 - val_loss: 0.6875 - val_accuracy: 0.6802\n",
            "Epoch 201/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.6815 - val_loss: 0.6575 - val_accuracy: 0.6847\n",
            "Epoch 202/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.6760 - val_loss: 0.6672 - val_accuracy: 0.6802\n",
            "Epoch 203/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6865 - val_loss: 0.6774 - val_accuracy: 0.6847\n",
            "Epoch 204/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.6835 - val_loss: 0.6605 - val_accuracy: 0.6847\n",
            "Epoch 205/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.6790 - val_loss: 0.6697 - val_accuracy: 0.6802\n",
            "Epoch 206/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.6765 - val_loss: 0.6926 - val_accuracy: 0.6802\n",
            "Epoch 207/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.6870 - val_loss: 0.6687 - val_accuracy: 0.6937\n",
            "Epoch 208/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.6825 - val_loss: 0.6649 - val_accuracy: 0.6757\n",
            "Epoch 209/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.6845 - val_loss: 0.6784 - val_accuracy: 0.6757\n",
            "Epoch 210/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.6820 - val_loss: 0.6838 - val_accuracy: 0.6847\n",
            "Epoch 211/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.6940 - val_loss: 0.6752 - val_accuracy: 0.6802\n",
            "Epoch 212/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.6820 - val_loss: 0.6673 - val_accuracy: 0.6802\n",
            "Epoch 213/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.6820 - val_loss: 0.6750 - val_accuracy: 0.6757\n",
            "Epoch 214/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.6890 - val_loss: 0.6732 - val_accuracy: 0.6847\n",
            "Epoch 215/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.6840 - val_loss: 0.6710 - val_accuracy: 0.6802\n",
            "Epoch 216/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.6900 - val_loss: 0.6751 - val_accuracy: 0.6757\n",
            "Epoch 217/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.6865 - val_loss: 0.6781 - val_accuracy: 0.6712\n",
            "Epoch 218/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.6830 - val_loss: 0.6803 - val_accuracy: 0.6802\n",
            "Epoch 219/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.6780 - val_loss: 0.6660 - val_accuracy: 0.6892\n",
            "Epoch 220/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.6820 - val_loss: 0.6683 - val_accuracy: 0.6712\n",
            "Epoch 221/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.6920 - val_loss: 0.6603 - val_accuracy: 0.6712\n",
            "Epoch 222/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.6810 - val_loss: 0.6807 - val_accuracy: 0.6802\n",
            "Epoch 223/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.6775 - val_loss: 0.6662 - val_accuracy: 0.6757\n",
            "Epoch 224/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.6845 - val_loss: 0.6916 - val_accuracy: 0.6802\n",
            "Epoch 225/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.6885 - val_loss: 0.6746 - val_accuracy: 0.6667\n",
            "Epoch 226/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.6850 - val_loss: 0.6662 - val_accuracy: 0.6757\n",
            "Epoch 227/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.6850 - val_loss: 0.6798 - val_accuracy: 0.6622\n",
            "Epoch 228/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.6760 - val_loss: 0.6794 - val_accuracy: 0.6712\n",
            "Epoch 229/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6885 - val_loss: 0.6671 - val_accuracy: 0.6802\n",
            "Epoch 230/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.6815 - val_loss: 0.6662 - val_accuracy: 0.6712\n",
            "Epoch 231/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.6880 - val_loss: 0.6691 - val_accuracy: 0.6757\n",
            "Epoch 232/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.6815 - val_loss: 0.6622 - val_accuracy: 0.6802\n",
            "Epoch 233/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.6890 - val_loss: 0.6739 - val_accuracy: 0.6802\n",
            "Epoch 234/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.6830 - val_loss: 0.6611 - val_accuracy: 0.6937\n",
            "Epoch 235/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.6825 - val_loss: 0.6802 - val_accuracy: 0.6712\n",
            "Epoch 236/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.6810 - val_loss: 0.6747 - val_accuracy: 0.6712\n",
            "Epoch 237/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.6850 - val_loss: 0.6862 - val_accuracy: 0.6802\n",
            "Epoch 238/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.6835 - val_loss: 0.6928 - val_accuracy: 0.6802\n",
            "Epoch 239/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.6735 - val_loss: 0.6764 - val_accuracy: 0.6802\n",
            "Epoch 240/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6940 - val_loss: 0.6845 - val_accuracy: 0.6937\n",
            "Epoch 241/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.6875 - val_loss: 0.6683 - val_accuracy: 0.6847\n",
            "Epoch 242/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.6860 - val_loss: 0.6639 - val_accuracy: 0.6847\n",
            "Epoch 243/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.6860 - val_loss: 0.6603 - val_accuracy: 0.6802\n",
            "Epoch 244/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.6835 - val_loss: 0.6843 - val_accuracy: 0.6982\n",
            "Epoch 245/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.6820 - val_loss: 0.6892 - val_accuracy: 0.6757\n",
            "Epoch 246/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6840 - val_loss: 0.6786 - val_accuracy: 0.6802\n",
            "Epoch 247/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.6900 - val_loss: 0.6740 - val_accuracy: 0.6802\n",
            "Epoch 248/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.6870 - val_loss: 0.6849 - val_accuracy: 0.6802\n",
            "Epoch 249/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.6795 - val_loss: 0.6793 - val_accuracy: 0.6802\n",
            "Epoch 250/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.6820 - val_loss: 0.6778 - val_accuracy: 0.6892\n",
            "Epoch 251/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.6830 - val_loss: 0.6816 - val_accuracy: 0.6757\n",
            "Epoch 252/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.6810 - val_loss: 0.6795 - val_accuracy: 0.6892\n",
            "Epoch 253/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6840 - val_loss: 0.6582 - val_accuracy: 0.6892\n",
            "Epoch 254/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.6855 - val_loss: 0.6819 - val_accuracy: 0.6892\n",
            "Epoch 255/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.6850 - val_loss: 0.6753 - val_accuracy: 0.6937\n",
            "Epoch 256/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6955 - val_loss: 0.6800 - val_accuracy: 0.6712\n",
            "Epoch 257/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.6875 - val_loss: 0.6706 - val_accuracy: 0.6847\n",
            "Epoch 258/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.6810 - val_loss: 0.6784 - val_accuracy: 0.6757\n",
            "Epoch 259/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.6785 - val_loss: 0.6588 - val_accuracy: 0.6937\n",
            "Epoch 260/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.6755 - val_loss: 0.6677 - val_accuracy: 0.6937\n",
            "Epoch 261/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.6750 - val_loss: 0.6882 - val_accuracy: 0.6757\n",
            "Epoch 262/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.6885 - val_loss: 0.6721 - val_accuracy: 0.6982\n",
            "Epoch 263/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.6870 - val_loss: 0.6675 - val_accuracy: 0.6847\n",
            "Epoch 264/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.6830 - val_loss: 0.6733 - val_accuracy: 0.6847\n",
            "Epoch 265/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.6910 - val_loss: 0.6631 - val_accuracy: 0.6847\n",
            "Epoch 266/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6910 - val_loss: 0.6625 - val_accuracy: 0.6847\n",
            "Epoch 267/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6860 - val_loss: 0.6802 - val_accuracy: 0.6937\n",
            "Epoch 268/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.6870 - val_loss: 0.6669 - val_accuracy: 0.6847\n",
            "Epoch 269/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.6915 - val_loss: 0.6818 - val_accuracy: 0.6892\n",
            "Epoch 270/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6930 - val_loss: 0.6921 - val_accuracy: 0.6802\n",
            "Epoch 271/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.6835 - val_loss: 0.6950 - val_accuracy: 0.6982\n",
            "Epoch 272/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6835 - val_loss: 0.6697 - val_accuracy: 0.6937\n",
            "Epoch 273/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.7016 - val_loss: 0.6746 - val_accuracy: 0.6847\n",
            "Epoch 274/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.6870 - val_loss: 0.6773 - val_accuracy: 0.6937\n",
            "Epoch 275/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6970 - val_loss: 0.6720 - val_accuracy: 0.6937\n",
            "Epoch 276/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.6930 - val_loss: 0.6699 - val_accuracy: 0.6982\n",
            "Epoch 277/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.6860 - val_loss: 0.6732 - val_accuracy: 0.6892\n",
            "Epoch 278/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.6820 - val_loss: 0.6734 - val_accuracy: 0.6802\n",
            "Epoch 279/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.6915 - val_loss: 0.6674 - val_accuracy: 0.6847\n",
            "Epoch 280/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.6880 - val_loss: 0.6654 - val_accuracy: 0.6802\n",
            "Epoch 281/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6885 - val_loss: 0.6728 - val_accuracy: 0.6847\n",
            "Epoch 282/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.6850 - val_loss: 0.6785 - val_accuracy: 0.6937\n",
            "Epoch 283/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.6800 - val_loss: 0.6887 - val_accuracy: 0.6892\n",
            "Epoch 284/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6935 - val_loss: 0.6697 - val_accuracy: 0.6982\n",
            "Epoch 285/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6895 - val_loss: 0.6609 - val_accuracy: 0.6982\n",
            "Epoch 286/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.6905 - val_loss: 0.6582 - val_accuracy: 0.6847\n",
            "Epoch 287/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6910 - val_loss: 0.6825 - val_accuracy: 0.6937\n",
            "Epoch 288/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.6920 - val_loss: 0.6808 - val_accuracy: 0.7027\n",
            "Epoch 289/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6925 - val_loss: 0.6823 - val_accuracy: 0.6937\n",
            "Epoch 290/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.6850 - val_loss: 0.6666 - val_accuracy: 0.6937\n",
            "Epoch 291/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.6840 - val_loss: 0.6697 - val_accuracy: 0.6847\n",
            "Epoch 292/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6955 - val_loss: 0.6698 - val_accuracy: 0.6937\n",
            "Epoch 293/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.6835 - val_loss: 0.6829 - val_accuracy: 0.6802\n",
            "Epoch 294/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6945 - val_loss: 0.6558 - val_accuracy: 0.6937\n",
            "Epoch 295/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.6990 - val_loss: 0.6813 - val_accuracy: 0.6937\n",
            "Epoch 296/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.6815 - val_loss: 0.6650 - val_accuracy: 0.7072\n",
            "Epoch 297/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.6870 - val_loss: 0.6702 - val_accuracy: 0.6982\n",
            "Epoch 298/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6880 - val_loss: 0.6774 - val_accuracy: 0.6892\n",
            "Epoch 299/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.6780 - val_loss: 0.6681 - val_accuracy: 0.6847\n",
            "Epoch 300/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6775 - val_loss: 0.6701 - val_accuracy: 0.6937\n",
            "Epoch 301/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.6860 - val_loss: 0.6667 - val_accuracy: 0.6892\n",
            "Epoch 302/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6895 - val_loss: 0.6712 - val_accuracy: 0.6892\n",
            "Epoch 303/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.6895 - val_loss: 0.6634 - val_accuracy: 0.6892\n",
            "Epoch 304/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.6840 - val_loss: 0.6643 - val_accuracy: 0.6937\n",
            "Epoch 305/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6930 - val_loss: 0.6670 - val_accuracy: 0.6802\n",
            "Epoch 306/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6880 - val_loss: 0.6755 - val_accuracy: 0.6847\n",
            "Epoch 307/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.6875 - val_loss: 0.6547 - val_accuracy: 0.6847\n",
            "Epoch 308/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6930 - val_loss: 0.6795 - val_accuracy: 0.6982\n",
            "Epoch 309/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.6875 - val_loss: 0.6741 - val_accuracy: 0.6892\n",
            "Epoch 310/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6935 - val_loss: 0.6747 - val_accuracy: 0.6892\n",
            "Epoch 311/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.6900 - val_loss: 0.6794 - val_accuracy: 0.6892\n",
            "Epoch 312/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.6880 - val_loss: 0.6583 - val_accuracy: 0.7162\n",
            "Epoch 313/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6930 - val_loss: 0.6682 - val_accuracy: 0.6982\n",
            "Epoch 314/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.6965 - val_loss: 0.6707 - val_accuracy: 0.6892\n",
            "Epoch 315/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.6975 - val_loss: 0.6687 - val_accuracy: 0.6892\n",
            "Epoch 316/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.6920 - val_loss: 0.6774 - val_accuracy: 0.6847\n",
            "Epoch 317/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6905 - val_loss: 0.6660 - val_accuracy: 0.7027\n",
            "Epoch 318/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.6780 - val_loss: 0.6673 - val_accuracy: 0.6982\n",
            "Epoch 319/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6860 - val_loss: 0.6667 - val_accuracy: 0.6937\n",
            "Epoch 320/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6815 - val_loss: 0.6538 - val_accuracy: 0.6892\n",
            "Epoch 321/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.6950 - val_loss: 0.6623 - val_accuracy: 0.6982\n",
            "Epoch 322/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.6815 - val_loss: 0.6901 - val_accuracy: 0.6892\n",
            "Epoch 323/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.6835 - val_loss: 0.6857 - val_accuracy: 0.6892\n",
            "Epoch 324/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6935 - val_loss: 0.6804 - val_accuracy: 0.6982\n",
            "Epoch 325/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.6900 - val_loss: 0.6899 - val_accuracy: 0.6937\n",
            "Epoch 326/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.6890 - val_loss: 0.6871 - val_accuracy: 0.6802\n",
            "Epoch 327/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6890 - val_loss: 0.6822 - val_accuracy: 0.6892\n",
            "Epoch 328/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.6975 - val_loss: 0.6583 - val_accuracy: 0.6937\n",
            "Epoch 329/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6895 - val_loss: 0.6799 - val_accuracy: 0.7027\n",
            "Epoch 330/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6970 - val_loss: 0.6780 - val_accuracy: 0.6982\n",
            "Epoch 331/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.6970 - val_loss: 0.6656 - val_accuracy: 0.6892\n",
            "Epoch 332/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.6910 - val_loss: 0.6788 - val_accuracy: 0.6937\n",
            "Epoch 333/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6935 - val_loss: 0.6841 - val_accuracy: 0.6892\n",
            "Epoch 334/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6970 - val_loss: 0.6826 - val_accuracy: 0.6982\n",
            "Epoch 335/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.6890 - val_loss: 0.6720 - val_accuracy: 0.6892\n",
            "Epoch 336/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6870 - val_loss: 0.6896 - val_accuracy: 0.6982\n",
            "Epoch 337/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.6845 - val_loss: 0.6839 - val_accuracy: 0.6937\n",
            "Epoch 338/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6930 - val_loss: 0.6834 - val_accuracy: 0.6847\n",
            "Epoch 339/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6900 - val_loss: 0.6854 - val_accuracy: 0.7027\n",
            "Epoch 340/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6850 - val_loss: 0.6632 - val_accuracy: 0.6937\n",
            "Epoch 341/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6920 - val_loss: 0.6795 - val_accuracy: 0.6937\n",
            "Epoch 342/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6905 - val_loss: 0.6801 - val_accuracy: 0.6892\n",
            "Epoch 343/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.6880 - val_loss: 0.6772 - val_accuracy: 0.6892\n",
            "Epoch 344/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.6925 - val_loss: 0.6727 - val_accuracy: 0.6937\n",
            "Epoch 345/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6830 - val_loss: 0.6768 - val_accuracy: 0.6847\n",
            "Epoch 346/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.6945 - val_loss: 0.6611 - val_accuracy: 0.6982\n",
            "Epoch 347/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6880 - val_loss: 0.6736 - val_accuracy: 0.6892\n",
            "Epoch 348/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6885 - val_loss: 0.6779 - val_accuracy: 0.6937\n",
            "Epoch 349/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6895 - val_loss: 0.6806 - val_accuracy: 0.7027\n",
            "Epoch 350/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.6920 - val_loss: 0.6821 - val_accuracy: 0.6937\n",
            "Epoch 351/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.6850 - val_loss: 0.6681 - val_accuracy: 0.6937\n",
            "Epoch 352/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.7071 - val_loss: 0.6843 - val_accuracy: 0.7072\n",
            "Epoch 353/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6915 - val_loss: 0.6707 - val_accuracy: 0.7027\n",
            "Epoch 354/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.6965 - val_loss: 0.6732 - val_accuracy: 0.7027\n",
            "Epoch 355/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6945 - val_loss: 0.6710 - val_accuracy: 0.7072\n",
            "Epoch 356/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6985 - val_loss: 0.6790 - val_accuracy: 0.6982\n",
            "Epoch 357/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6850 - val_loss: 0.6738 - val_accuracy: 0.7072\n",
            "Epoch 358/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6910 - val_loss: 0.6616 - val_accuracy: 0.7072\n",
            "Epoch 359/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.6915 - val_loss: 0.6816 - val_accuracy: 0.6937\n",
            "Epoch 360/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.6815 - val_loss: 0.6829 - val_accuracy: 0.7027\n",
            "Epoch 361/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.6875 - val_loss: 0.6755 - val_accuracy: 0.6982\n",
            "Epoch 362/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.6915 - val_loss: 0.6724 - val_accuracy: 0.7072\n",
            "Epoch 363/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6865 - val_loss: 0.6775 - val_accuracy: 0.6937\n",
            "Epoch 364/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6955 - val_loss: 0.6826 - val_accuracy: 0.6892\n",
            "Epoch 365/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6885 - val_loss: 0.6921 - val_accuracy: 0.6847\n",
            "Epoch 366/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6910 - val_loss: 0.6681 - val_accuracy: 0.6892\n",
            "Epoch 367/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.6900 - val_loss: 0.6836 - val_accuracy: 0.6892\n",
            "Epoch 368/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6840 - val_loss: 0.6881 - val_accuracy: 0.6982\n",
            "Epoch 369/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6945 - val_loss: 0.6866 - val_accuracy: 0.6937\n",
            "Epoch 370/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.7001 - val_loss: 0.6911 - val_accuracy: 0.6937\n",
            "Epoch 371/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6875 - val_loss: 0.6855 - val_accuracy: 0.6847\n",
            "Epoch 372/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.7026 - val_loss: 0.6788 - val_accuracy: 0.6937\n",
            "Epoch 373/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6965 - val_loss: 0.6858 - val_accuracy: 0.6847\n",
            "Epoch 374/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6895 - val_loss: 0.6755 - val_accuracy: 0.6802\n",
            "Epoch 375/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6850 - val_loss: 0.6928 - val_accuracy: 0.6892\n",
            "Epoch 376/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6890 - val_loss: 0.6964 - val_accuracy: 0.6847\n",
            "Epoch 377/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.6970 - val_loss: 0.6938 - val_accuracy: 0.7027\n",
            "Epoch 378/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6975 - val_loss: 0.6792 - val_accuracy: 0.6757\n",
            "Epoch 379/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6920 - val_loss: 0.6830 - val_accuracy: 0.6802\n",
            "Epoch 380/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6990 - val_loss: 0.6743 - val_accuracy: 0.6847\n",
            "Epoch 381/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.6940 - val_loss: 0.6796 - val_accuracy: 0.6937\n",
            "Epoch 382/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6970 - val_loss: 0.6809 - val_accuracy: 0.6982\n",
            "Epoch 383/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.7001 - val_loss: 0.6796 - val_accuracy: 0.6892\n",
            "Epoch 384/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6930 - val_loss: 0.6696 - val_accuracy: 0.6802\n",
            "Epoch 385/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6865 - val_loss: 0.6811 - val_accuracy: 0.6937\n",
            "Epoch 386/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6965 - val_loss: 0.6797 - val_accuracy: 0.6982\n",
            "Epoch 387/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6980 - val_loss: 0.6656 - val_accuracy: 0.6847\n",
            "Epoch 388/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.6955 - val_loss: 0.6750 - val_accuracy: 0.6847\n",
            "Epoch 389/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6960 - val_loss: 0.6726 - val_accuracy: 0.6937\n",
            "Epoch 390/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.6945 - val_loss: 0.6903 - val_accuracy: 0.6847\n",
            "Epoch 391/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6840 - val_loss: 0.6815 - val_accuracy: 0.6937\n",
            "Epoch 392/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6930 - val_loss: 0.6667 - val_accuracy: 0.6847\n",
            "Epoch 393/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6975 - val_loss: 0.6714 - val_accuracy: 0.6892\n",
            "Epoch 394/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6950 - val_loss: 0.6694 - val_accuracy: 0.6892\n",
            "Epoch 395/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6950 - val_loss: 0.6929 - val_accuracy: 0.6892\n",
            "Epoch 396/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.6900 - val_loss: 0.6741 - val_accuracy: 0.6892\n",
            "Epoch 397/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.6955 - val_loss: 0.6808 - val_accuracy: 0.6847\n",
            "Epoch 398/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.6915 - val_loss: 0.6607 - val_accuracy: 0.6847\n",
            "Epoch 399/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6890 - val_loss: 0.6657 - val_accuracy: 0.6982\n",
            "Epoch 400/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6955 - val_loss: 0.6891 - val_accuracy: 0.6802\n",
            "Epoch 401/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.6925 - val_loss: 0.6859 - val_accuracy: 0.6937\n",
            "Epoch 402/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.6905 - val_loss: 0.6581 - val_accuracy: 0.6847\n",
            "Epoch 403/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.7026 - val_loss: 0.6885 - val_accuracy: 0.6937\n",
            "Epoch 404/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6657 - accuracy: 0.6875 - val_loss: 0.6883 - val_accuracy: 0.6937\n",
            "Epoch 405/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.7046 - val_loss: 0.6829 - val_accuracy: 0.6982\n",
            "Epoch 406/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6985 - val_loss: 0.6754 - val_accuracy: 0.6892\n",
            "Epoch 407/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6830 - val_loss: 0.6806 - val_accuracy: 0.6982\n",
            "Epoch 408/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6890 - val_loss: 0.6848 - val_accuracy: 0.6937\n",
            "Epoch 409/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6985 - val_loss: 0.6617 - val_accuracy: 0.6847\n",
            "Epoch 410/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.6950 - val_loss: 0.6753 - val_accuracy: 0.6847\n",
            "Epoch 411/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6900 - val_loss: 0.6817 - val_accuracy: 0.6892\n",
            "Epoch 412/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.7026 - val_loss: 0.7078 - val_accuracy: 0.6847\n",
            "Epoch 413/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6930 - val_loss: 0.7030 - val_accuracy: 0.6847\n",
            "Epoch 414/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.6900 - val_loss: 0.6763 - val_accuracy: 0.7027\n",
            "Epoch 415/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6970 - val_loss: 0.6669 - val_accuracy: 0.6802\n",
            "Epoch 416/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6965 - val_loss: 0.6684 - val_accuracy: 0.6757\n",
            "Epoch 417/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6950 - val_loss: 0.6733 - val_accuracy: 0.6802\n",
            "Epoch 418/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6925 - val_loss: 0.6789 - val_accuracy: 0.6847\n",
            "Epoch 419/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7046 - val_loss: 0.6827 - val_accuracy: 0.6937\n",
            "Epoch 420/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6965 - val_loss: 0.6835 - val_accuracy: 0.6892\n",
            "Epoch 421/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6985 - val_loss: 0.6802 - val_accuracy: 0.7027\n",
            "Epoch 422/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7001 - val_loss: 0.6827 - val_accuracy: 0.6982\n",
            "Epoch 423/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6890 - val_loss: 0.6974 - val_accuracy: 0.6937\n",
            "Epoch 424/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.6880 - val_loss: 0.6825 - val_accuracy: 0.6847\n",
            "Epoch 425/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6985 - val_loss: 0.6564 - val_accuracy: 0.7027\n",
            "Epoch 426/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6935 - val_loss: 0.6769 - val_accuracy: 0.6847\n",
            "Epoch 427/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.6895 - val_loss: 0.6755 - val_accuracy: 0.7072\n",
            "Epoch 428/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6985 - val_loss: 0.6774 - val_accuracy: 0.6982\n",
            "Epoch 429/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.6945 - val_loss: 0.6837 - val_accuracy: 0.6937\n",
            "Epoch 430/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6960 - val_loss: 0.6700 - val_accuracy: 0.6937\n",
            "Epoch 431/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6970 - val_loss: 0.6853 - val_accuracy: 0.6892\n",
            "Epoch 432/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6895 - val_loss: 0.6639 - val_accuracy: 0.6847\n",
            "Epoch 433/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6960 - val_loss: 0.6752 - val_accuracy: 0.6937\n",
            "Epoch 434/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6960 - val_loss: 0.6719 - val_accuracy: 0.6937\n",
            "Epoch 435/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6935 - val_loss: 0.6859 - val_accuracy: 0.6802\n",
            "Epoch 436/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.7006 - val_loss: 0.6782 - val_accuracy: 0.7027\n",
            "Epoch 437/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.7001 - val_loss: 0.6707 - val_accuracy: 0.6847\n",
            "Epoch 438/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6860 - val_loss: 0.6861 - val_accuracy: 0.6847\n",
            "Epoch 439/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6975 - val_loss: 0.6792 - val_accuracy: 0.6892\n",
            "Epoch 440/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6885 - val_loss: 0.6954 - val_accuracy: 0.6757\n",
            "Epoch 441/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.6965 - val_loss: 0.6913 - val_accuracy: 0.6802\n",
            "Epoch 442/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6970 - val_loss: 0.7024 - val_accuracy: 0.6757\n",
            "Epoch 443/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6985 - val_loss: 0.6789 - val_accuracy: 0.6847\n",
            "Epoch 444/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.6925 - val_loss: 0.6815 - val_accuracy: 0.6802\n",
            "Epoch 445/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.6905 - val_loss: 0.6727 - val_accuracy: 0.6847\n",
            "Epoch 446/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6970 - val_loss: 0.6973 - val_accuracy: 0.6847\n",
            "Epoch 447/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6905 - val_loss: 0.6793 - val_accuracy: 0.6847\n",
            "Epoch 448/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6965 - val_loss: 0.6760 - val_accuracy: 0.6757\n",
            "Epoch 449/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6985 - val_loss: 0.6669 - val_accuracy: 0.7027\n",
            "Epoch 450/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6960 - val_loss: 0.6806 - val_accuracy: 0.7027\n",
            "Epoch 451/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6970 - val_loss: 0.6824 - val_accuracy: 0.6982\n",
            "Epoch 452/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6980 - val_loss: 0.6769 - val_accuracy: 0.6937\n",
            "Epoch 453/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.6935 - val_loss: 0.6896 - val_accuracy: 0.6847\n",
            "Epoch 454/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6930 - val_loss: 0.6967 - val_accuracy: 0.6847\n",
            "Epoch 455/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6930 - val_loss: 0.6892 - val_accuracy: 0.6937\n",
            "Epoch 456/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.6875 - val_loss: 0.6639 - val_accuracy: 0.6847\n",
            "Epoch 457/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6960 - val_loss: 0.6982 - val_accuracy: 0.6847\n",
            "Epoch 458/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6955 - val_loss: 0.6800 - val_accuracy: 0.6892\n",
            "Epoch 459/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6920 - val_loss: 0.6920 - val_accuracy: 0.6937\n",
            "Epoch 460/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6930 - val_loss: 0.6693 - val_accuracy: 0.7117\n",
            "Epoch 461/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.6970 - val_loss: 0.6957 - val_accuracy: 0.6847\n",
            "Epoch 462/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.7001 - val_loss: 0.6787 - val_accuracy: 0.7027\n",
            "Epoch 463/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.7076 - val_loss: 0.6774 - val_accuracy: 0.6847\n",
            "Epoch 464/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6980 - val_loss: 0.6771 - val_accuracy: 0.6937\n",
            "Epoch 465/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6925 - val_loss: 0.6911 - val_accuracy: 0.6847\n",
            "Epoch 466/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6950 - val_loss: 0.6939 - val_accuracy: 0.6802\n",
            "Epoch 467/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.6945 - val_loss: 0.6897 - val_accuracy: 0.6847\n",
            "Epoch 468/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6910 - val_loss: 0.6770 - val_accuracy: 0.6937\n",
            "Epoch 469/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6885 - val_loss: 0.6805 - val_accuracy: 0.6892\n",
            "Epoch 470/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.6900 - val_loss: 0.6858 - val_accuracy: 0.6937\n",
            "Epoch 471/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.6890 - val_loss: 0.6857 - val_accuracy: 0.6892\n",
            "Epoch 472/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.6855 - val_loss: 0.6813 - val_accuracy: 0.6892\n",
            "Epoch 473/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6965 - val_loss: 0.6777 - val_accuracy: 0.6937\n",
            "Epoch 474/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.7011 - val_loss: 0.6656 - val_accuracy: 0.7072\n",
            "Epoch 475/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6905 - val_loss: 0.6780 - val_accuracy: 0.6892\n",
            "Epoch 476/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6945 - val_loss: 0.6761 - val_accuracy: 0.6802\n",
            "Epoch 477/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6970 - val_loss: 0.6783 - val_accuracy: 0.6892\n",
            "Epoch 478/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6925 - val_loss: 0.6820 - val_accuracy: 0.6847\n",
            "Epoch 479/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.6940 - val_loss: 0.6733 - val_accuracy: 0.7117\n",
            "Epoch 480/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6975 - val_loss: 0.6757 - val_accuracy: 0.7027\n",
            "Epoch 481/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6890 - val_loss: 0.6802 - val_accuracy: 0.6937\n",
            "Epoch 482/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.7016 - val_loss: 0.6875 - val_accuracy: 0.7117\n",
            "Epoch 483/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6920 - val_loss: 0.6922 - val_accuracy: 0.6847\n",
            "Epoch 484/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6955 - val_loss: 0.7026 - val_accuracy: 0.7027\n",
            "Epoch 485/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.7026 - val_loss: 0.6926 - val_accuracy: 0.6937\n",
            "Epoch 486/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.7016 - val_loss: 0.6787 - val_accuracy: 0.6847\n",
            "Epoch 487/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.7051 - val_loss: 0.6940 - val_accuracy: 0.6892\n",
            "Epoch 488/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.6865 - val_loss: 0.6793 - val_accuracy: 0.7027\n",
            "Epoch 489/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6945 - val_loss: 0.6778 - val_accuracy: 0.7117\n",
            "Epoch 490/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6860 - val_loss: 0.6742 - val_accuracy: 0.7072\n",
            "Epoch 491/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6955 - val_loss: 0.6695 - val_accuracy: 0.6982\n",
            "Epoch 492/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.6865 - val_loss: 0.6852 - val_accuracy: 0.6892\n",
            "Epoch 493/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6990 - val_loss: 0.6787 - val_accuracy: 0.6937\n",
            "Epoch 494/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6945 - val_loss: 0.6886 - val_accuracy: 0.6982\n",
            "Epoch 495/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6955 - val_loss: 0.6826 - val_accuracy: 0.7027\n",
            "Epoch 496/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.7031 - val_loss: 0.6868 - val_accuracy: 0.6937\n",
            "Epoch 497/500\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6885 - val_loss: 0.7023 - val_accuracy: 0.6847\n",
            "Epoch 498/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.7076 - val_loss: 0.6847 - val_accuracy: 0.7027\n",
            "Epoch 499/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.7011 - val_loss: 0.6906 - val_accuracy: 0.6757\n",
            "Epoch 500/500\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6985 - val_loss: 0.6974 - val_accuracy: 0.6982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxCntbXXOYpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574ccdfb-b412-42d6-aa0f-d8325086629e"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYwpH13bIvzz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0a3f1607-9727-4413-8656-f16987b52818"
      },
      "source": [
        "#plot training accuracy\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO-4XeLAMXVK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a8effc2f-cd16-44ed-acf0-7a9675e17937"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e87k0aoSeg1IL0joYkoWBG7CIi6KhZW177qLq69l3XVnxVBWcsq9g6IgCAoHaR3kF4SCJAEUmfO749zp6URyhDIvJ/nyTNz+7mTmfveU68YY1BKKRW5XOWdAKWUUuVLA4FSSkU4DQRKKRXhNBAopVSE00CglFIRTgOBUkpFOA0ESpWRiLwvIk+Xcd2NInLO0e5HqeNBA4FSSkU4DQRKKRXhNBCoCsUpknlARJaIyAEReU9E6ojIBBHJFJHJIpIQtP4lIrJcRPaJyDQRaRO0rIuILHS2+wyIK3Ssi0RkkbPtTBHpeIRpvkVE1olIuoh8LyL1nfkiIq+ISKqIZIjIUhFp7ywbICIrnLRtE5H7j+gDUwoNBKpiGgicC7QELgYmAP8CamG/83cBiEhLYCxwj7NsPPCDiMSISAzwLfARkAh84ewXZ9suwBjgr0AS8A7wvYjEHk5CReQs4DlgMFAP2AR86iw+DzjDOY/qzjp7nGXvAX81xlQF2gO/HM5xlQqmgUBVRK8bY3YZY7YBM4A5xpg/jDE5wDdAF2e9IcA4Y8wkY0w+8BJQCTgN6AlEA68aY/KNMV8C84KOMRx4xxgzxxjjMcZ8AOQ62x2Oa4AxxpiFxphc4EGgl4gkA/lAVaA1IMaYlcaYHc52+UBbEalmjNlrjFl4mMdVyk8DgaqIdgW9zy5muorzvj72DhwAY4wX2AI0cJZtM6GjMm4Ket8EuM8pFtonIvuARs52h6NwGrKwd/0NjDG/AG8AbwKpIjJKRKo5qw4EBgCbRORXEel1mMdVyk8DgYpk27EXdMCWyWMv5tuAHUADZ55P46D3W4BnjDE1gv7ijTFjjzINlbFFTdsAjDGvGWO6Am2xRUQPOPPnGWMuBWpji7A+P8zjKuWngUBFss+BC0XkbBGJBu7DFu/MBGYBBcBdIhItIlcA3YO2HQ3cKiI9nErdyiJyoYhUPcw0jAWGiUhnp37hWWxR1kYR6ebsPxo4AOQAXqcO4xoRqe4UaWUA3qP4HFSE00CgIpYxZjVwLfA6sBtbsXyxMSbPGJMHXAHcAKRj6xO+Dtp2PnALtuhmL7DOWfdw0zAZeAT4CpsLOQW4yllcDRtw9mKLj/YA/3aW/QXYKCIZwK3Yugaljojog2mUUiqyaY5AKaUinAYCpZSKcBoIlFIqwmkgUEqpCBdV3gk4XDVr1jTJycnlnQyllDqpLFiwYLcxplZxy066QJCcnMz8+fPLOxlKKXVSEZFNJS3ToiGllIpwGgiUUirCaSBQSqkId9LVERQnPz+frVu3kpOTU95JCbu4uDgaNmxIdHR0eSdFKVVBVIhAsHXrVqpWrUpycjKhg0VWLMYY9uzZw9atW2natGl5J0cpVUFUiKKhnJwckpKSKnQQABARkpKSIiLno5Q6fipEIAAqfBDwiZTzVEodPxUmEBxKTr6HnftzyPfosO1KKRUsogJBamYOHu+xH3Z73759vPXWW4e93YABA9i3b98xT49SSh2OsAUCERkjIqkisuwQ63UTkQIRuTJcaQHwFaiE4+kLJQWCgoKCUrcbP348NWrUCEOKlFKq7MKZI3gf6F/aCiLiBl4Afg5jOnwHs69hiAQjRoxg/fr1dO7cmW7dutGnTx8uueQS2rZtC8Bll11G165dadeuHaNGjfJvl5yczO7du9m4cSNt2rThlltuoV27dpx33nlkZ2cf+4QqpVQxwtZ81BgzXUSSD7HandhH9HU7Vsd94oflrNieUWS+x2vIyfdQKcaN6zArXNvWr8ZjF7crcfnzzz/PsmXLWLRoEdOmTePCCy9k2bJl/iaeY8aMITExkezsbLp168bAgQNJSkoK2cfatWsZO3Yso0ePZvDgwXz11Vdce+21h5VOpZQ6EuVWRyAiDYDLgbfLKw3h0r1795B2/q+99hqdOnWiZ8+ebNmyhbVr1xbZpmnTpnTu3BmArl27snHjxuOVXKVUhCvPDmWvAv80xngP1SRSRIYDwwEaN25c6rol3blnZOezcc8BmteuQnxMeE+7cuXK/vfTpk1j8uTJzJo1i/j4ePr27VtsP4DY2Fj/e7fbrUVDSqnjpjwDQQrwqRMEagIDRKTAGPNt4RWNMaOAUQApKSlHVsofxtriqlWrkpmZWeyy/fv3k5CQQHx8PKtWrWL27NnHPgFKKXUUyi0QGGP8ZSci8j7wY3FB4FgJZ6uhpKQkevfuTfv27alUqRJ16tTxL+vfvz8jR46kTZs2tGrVip49e4YhBUopdeTCFghEZCzQF6gpIluBx4BoAGPMyHAdt7x88sknxc6PjY1lwoQJxS7z1QPUrFmTZcsCrWzvv//+Y54+pZQqSThbDQ09jHVvCFc6lFJKlS5iehaHs2hIKaVOZhETCPyhQCOBUkqFiJxA4G+hqpFAKaWCRUwg0KIhpZQqXsQEAqWUUsXTQFAOqlSpUt5JUEopv4gJBFo0pJRSxasQD68vkzBGghEjRtCoUSNuv/12AB5//HGioqKYOnUqe/fuJT8/n6effppLL7302B9cKaWOUsULBBNGwM6lRWbHGkOzPA9x0S5wHWZGqG4HuOD5EhcPGTKEe+65xx8IPv/8cyZOnMhdd91FtWrV2L17Nz179uSSSy7RZw4rpU44FS8QlIMuXbqQmprK9u3bSUtLIyEhgbp163Lvvfcyffp0XC4X27ZtY9euXdStW7e8k6uUUiEqXiAo4c49L8/DhtRMmiRVpnql6GN+2EGDBvHll1+yc+dOhgwZwscff0xaWhoLFiwgOjqa5OTkYoefVkqp8lbxAkFJ/HUE4akuHjJkCLfccgu7d+/m119/5fPPP6d27dpER0czdepUNm3aFJbjKqXU0YqYQBDuVkPt2rUjMzOTBg0aUK9ePa655houvvhiOnToQEpKCq1btw7TkZVS6uhETCA4HpYuDVRS16xZk1mzZhW7XlZW1vFKklJKHVLE9CNQSilVvIgJBNpoUymlildhAoEpYyXwyd6zuKznqZRSZRW2QCAiY0QkVUSWlbD8UhFZIiKLRGS+iJx+pMeKi4tjz549pV8kK8AYE8YY9uzZQ1xcXHknRSlVgYSzsvh94A3gwxKWTwG+N8YYEekIfA4cUdOahg0bsnXrVtLS0kpcp8DrZdf+XPJ2R1M59uStI4+Li6Nhw4blnQylVAUSzmcWTxeR5FKWBzedqcxR3KtHR0fTtGnTUtfZti+biz/6hRcHdmRw50ZHeiillKpwyrWOQEQuF5FVwDjgxlLWG+4UH80v7a6/1GM5r14tY1dKqRDlGgiMMd8YY1oDlwFPlbLeKGNMijEmpVatWkd0LJcz2JuGAaWUCnVCtBoyxkwHmolIzXAdw+VkCTRHoJRSocotEIhIc3HGZBaRU4FYYE8YjweAV+OAUkqFCFtlsYiMBfoCNUVkK/AYEA1gjBkJDASuE5F8IBsYYsLYSN6XI9B2+EopFSqcrYaGHmL5C8AL4Tp+Yb46Aq9mCZRSKsQJUUdwPLi0aEgppYoVMYEArSxWSqliRUwgCNQRlG86lFLqRBNBgcDXj0AjgVJKBYu4QKB1BEopFSpiAoFoHYFSShUrYgKBv2hI44BSSoWIoEBgX7UfgVJKhYqgQKB1BEopVZyICQRaR6CUUsWLoECgw1ArpVRxIiYQgK0n0EHnlFIqVIQFAtGiIaWUKiQCA0F5p0IppU4sERUIRLSyWCmlCouoQOAS0Q5lSilVSNgCgYiMEZFUEVlWwvJrRGSJiCwVkZki0ilcafFxiXYoU0qpwsKZI3gf6F/K8j+BM40xHYCngFFhTAtgm5BqHFBKqVDhfFTldBFJLmX5zKDJ2UDDcKXFR0SHoVZKqcJOlDqCm4AJ4T6I1hEopVRRYcsRlJWI9MMGgtNLWWc4MBygcePGR3wsl7YaUkqpIso1RyAiHYF3gUuNMXtKWs8YM8oYk2KMSalVq9YRH087lCmlVFHlFghEpDHwNfAXY8ya43RMrSxWSqlCwlY0JCJjgb5ATRHZCjwGRAMYY0YCjwJJwFvOgHAFxpiUcKUHdKwhpZQqTjhbDQ09xPKbgZvDdfziiIDXezyPqJRSJ74TpdXQcaF1BEopVVTEBQINA0opFSqiAoEOOqeUUkVFVCDQDmVKKVVUhAUCzREopVRhERYItB+BUkoVFlGBQOsIlFKqqAgLBKIdypRSqpCICgS2Z3F5p0IppU4sERYItEOZUkoVFlGBQAedU0qpoiIqEOigc0opVVSEBQLNESilVGERFgi0+ahSShUWUYFA6wiUUqqoCAsEWkeglFKFRVQg0EHnlFKqqLAFAhEZIyKpIrKshOWtRWSWiOSKyP3hSkcwrSNQSqmiwpkjeB/oX8rydOAu4KUwpiEgdRVXZn1C5YK9x+VwSil1sghbIDDGTMde7EtanmqMmQfkhysNIdJWMiTrI6p59h2Xwyml1MnipKgjEJHhIjJfROanpaUd4U7c9tXo0+uVUirYSREIjDGjjDEpxpiUWrVqHdlOxJ6qGM8xTJlSSp38TopAcEy4bI7AeDUQKKVUsMgJBL6iIQ0ESikVIipcOxaRsUBfoKaIbAUeA6IBjDEjRaQuMB+oBnhF5B6grTEmIywJctmYZ7SOQCmlQoQtEBhjhh5i+U6gYbiOX4STIzCeguN2SKWUOhlEUNGQ5giUUqo4kRMI/JXFmiNQSqlgkRMIRFsNKaVUcSInEPhyBB4tGlJKqWCREwj8PYu1aEgppYJFUCAQAIxXcwRKKRWsTIFARO4WkWpivSciC0XkvHAn7pjSnsVKKVWssuYIbnQ6ep0HJAB/AZ4PW6rCwSka0rGGlFIqVFkDgTivA4CPjDHLg+adHPw5Aq8+rlIppYKUNRAsEJGfsYFgoohUBU6uwnYnR+DGi0efYK+UUn5lHWLiJqAzsMEYc1BEEoFh4UtWGDg5AsFLgdcQ5S7n9Cil1AmirDmCXsBqY8w+EbkWeBjYH75khYHTasjtBAKllFJWWQPB28BBEekE3AesBz4MW6rCwVc0JF4KtFOZUkr5lTUQFBhbw3op8IYx5k2gaviSFQZO0ZALozkCpZQKUtY6gkwReRDbbLSPiLhwni1w0giqLC7waCBQSimfsuYIhgC52P4EvucI/DtsqQoHf47AS74WDSmllF+ZAoFz8f8YqC4iFwE5xphS6whEZIyIpIrIshKWi4i8JiLrRGSJiJx62Kk/HM7zCFzafFQppUKUdYiJwcBcYBAwGJgjIlceYrP3gf6lLL8AaOH8DcdWSIePEwhsqyHNESillE9Z6wgeAroZY1IBRKQWMBn4sqQNjDHTRSS5lH1eCnzoVELPFpEaIlLPGLOjjGk6PCFFQ5ojUEopn7LWEbh8QcCx5zC2LUkDYEvQ9FZnXnhoz2KllCpWWXMEP4nIRGCsMz0EGB+eJBUlIsOxxUc0btz4yHYS1HxUK4uVUiqgTIHAGPOAiAwEejuzRhljvjnKY28DGgVNN3TmFXf8UcAogJSUlCO7nQ+qLNZ+BEopFVDWHAHGmK+Ar47hsb8H7hCRT4EewP6w1Q+A9iNQSqkSlBoIRCQTKO6qKYAxxlQrZduxQF+gpohsBR7D6YRmjBmJLVoaAKwDDhLuQexcQUNMaKshpZTyKzUQGGOOeBgJY8zQQyw3wO1Huv/DJoJBtGhIKaUKiZxnFgOI2441pEVDSinlF1GBwIjLqSPQoiGllPKJqECAy6VFQ0opVUhkBQJx6xATSilVSEQGAh1iQimlAiIqEIjLjWBIzcgp76QopdQJI8ICgYvqsS5W7cws76QopdQJI6ICAeImMd7Nml0aCJRSyieyAoHLTY04NxvSDmD7symllIqsQCBuYt324fU5+dpySCmlINICgctFlNi3B/MKyjctSil1goisQCAuosXmBA7meco5MUopdWKIsEDgJspl6way8zUQKKUURFogcLmJEicQaI5AKaWASAsE4iZKi4aUUipEZAUClxu3U1mcna+VxUopBZEWCESIQnMESikVLKyBQET6i8hqEVknIiOKWd5ERKaIyBIRmSYiDcOZHsSNW4uGlFIqRNgCgYi4gTeBC4C2wFARaVtotZeAD40xHYEngefClR7AFg05OQKtLFZKKSucOYLuwDpjzAZjTB7wKXBpoXXaAr8476cWs/zYkkAg0ByBUkpZ4QwEDYAtQdNbnXnBFgNXOO8vB6qKSFLhHYnIcBGZLyLz09LSjjxFLjcuf45AK4uVUgrKv7L4fuBMEfkDOBPYBhS5VTfGjDLGpBhjUmrVqnXkRxMXYgyVot2aI1BKKUdUGPe9DWgUNN3QmednjNmOkyMQkSrAQGPMvrClSFzgLSA+xs0BDQRKKQWEN0cwD2ghIk1FJAa4Cvg+eAURqSkivjQ8CIwJY3rA5Qavh6Y1K7NiR0ZYD6WUUieLsAUCY0wBcAcwEVgJfG6MWS4iT4rIJc5qfYHVIrIGqAM8E670AOCOAU8evU5JYtm2/WTm5If1cEopdTIIZ9EQxpjxwPhC8x4Nev8l8GU40xDCCQSnNknA4zWs2plJt+TE43Z4pZQ6EZV3ZfHxFRULBbnUqhILwJ6svHJOkFJKlb8ICwRxUJBLUpUYANIPaCBQSqnICgTuGPDkkljZBoK9BzUQKKVUZAWCqDgoyCM2yk2V2CgWbNpLvkefXayUimwRFghioCAHgHyPl19WpfLMuJXlnCillCpfkRUI3LHgyQVjyC2wOYHvFm07xEZKKVWxRVYgiLKthfAE+g8cyPNo8ZBSKqJFZiAoyOHLW3txbts65BV42ZJ+sHzTpZRS5SisHcpOOG5fjiCPlOSaiMCkFbt44ocV1Koay0uDOpVv+pRSqhxEaI4gF4DkpMoA/LomjS8XbC2vVCmlVLmK0EBgWw4lVo6halwgU6RPLVNKRaLICgRu25EMj+1IJiI0r13Fv7jNoz+xTzuZKaUiTGQFgqg4++oUDQH0aBr6QLTt+3KOZ4qUUqrcRVggcHIEQYHgzrOac2bLwFPP9hzILbyVUkpVaBEWCJwcgSdwsa8cG8W/B3X0T2/bm328U6WUUuUqsgKBr/loQWg9QFLlWP/7EV8vZerq1OOZKqWUKldhDQQi0l9EVovIOhEZUczyxiIyVUT+EJElIjIgnOkJFA2F1gO4XcKfzwUO/dva3WFNhlJKnUjCFghExA28CVwAtAWGikjbQqs9jH2EZRfsM43fCld6gGKLhnxExP8+3+Pl3Rkb+HVNWliTo5RSJ4Jw5gi6A+uMMRuMMXnAp8ClhdYxQDXnfXVgexjTE2g+WlB8E9Gh3RsB8OGsTTw9biX/+HJxWJOjlFIngnAGggbAlqDprc68YI8D14rIVuyzje8sbkciMlxE5ovI/LS0o7hLj7E9icnLKnbxc1d05PTmNf3Tu7Py8HjNkR9PKaVOAuVdWTwUeN8Y0xAYAHwkIkXSZIwZZYxJMcak1KpVq8hOyiyuhn3N3lfiKg1qVPK/93iNtiJSSlV44QwE24BGQdMNnXnBbgI+BzDGzALigJqES1QMxFSB7L0lrtK5cY2Q6fVpxecelFKqoghnIJgHtBCRpiISg60M/r7QOpuBswFEpA02EIS3hrZSQqmBwNe5LMZtP5ph78/j7Wnrw5okpZQqT2ELBMaYAuAOYCKwEts6aLmIPCkilzir3QfcIiKLgbHADcaY8BbKV6oB2eklLq5foxL/GtCar247DbfLtiR64adVPD9hlQ5Kp5SqkCTc191jLSUlxcyfP//Id/DBxXaIiZt+PuSqySPGFZm36qn+xEW7j/z4SilVDkRkgTEmpbhl5V1ZfPwdomgoWEyU/XhuPr2pf964JTuYuV47nCmlKo4IDASJZQ4EY2/pyR39mpOSnOifd98Xi7l69Bw+mr2Jn5fv5GBeAeOX7ghXapVSKuwi61GVYHMEB9PB6wVX6XGwa5MEujZJYMX2jCLLHvl2GQAdGlRn6bb9TLznDFrVrRqyjtdreOz75Qzt3pi29asV2YdSSp0IIi9HUK0+GA9k7SzzJi3rVOHano25vEsDOjSoTuPEeP+ypdv2A8U3M92y9yAfzd7E7Z8sPPp0K6VUmERejiDBKe/fu8kGhTKIcrt4+rIO/mljDPkewz2f/cH4pTagrEsNDQTb92X7O6MJ9jGYB/IKqFklFqWUOpFEXo4goYl93bfpiHchIsREuXjxyk7M+Ec/GtSoxDu/rmfvATskxWfzNnPa879w16d/ABAb7eafXy0h5enJ+ihMpdQJJ/JyBNUbAQKpK8CTD5k7oUajQ25WnCqxUVSJjeLSzvV5a9p6+r40jYN5BeR7bJPc3Vn2or9yRwYrd9h6hk/nbeHWM085JqeilFLHQuTlCKLjoHYbmPk6fDIYXm0POUUrgw/HP/q35tqejdmfne8PAiXZtjdbcwVKqRNK5AUCgItfA+OF9b/Y6QNHP6rFIxe15eXBnbjhtORS11u4eS9dn57MT8tsk9Oflu3kujFzdZRTpVS5icxA0DAlMBIpQJbzaMr87JAH2x+O2Cg3V5zakHPa1AFs09PHLy78HB5Yvj0Dj9cwesaf/LRsJw98sZjpa9L4cNZGFmwqeegLpZQKl8gMBCLQ4NTAdNYu+/pcIxh5un3v9drio4OHd3Hu1jSBizvV59nLO3BD76Y0q1m52PUWbNrLrf9bQGZuAQBP/LCCgW/P8i+fvzGdq0fP1vGNlFJhF5mBAKBW68D7rFQwBrz5sHuNnbdlNvz8MIy//7B2Gxvl5vWhXfydy27v19x5PYWrutlK6YT46JBtfENZABR4vAA8+t1yZq7fw8uTVuPVYiOlVBhFbiBIbBZ4v+Qz+OnBwPTPD8Pyb+z7jFKGj9i7Ef6cXuphBnZtyMbnL+SB81tTJdY20jq1cQL/HdaN566wfROevqw9T17aDoDt+3IAiHbbkU9Hz/iTsfM2Y4xh5Y6MIkHh8/lbeOGnVf7p1Mwc8gq8paZJKaWCRV7zUZ/gQLBtvv3zmfl64L0ppWjmtS620vnx/WU6ZM9mSbz725/8/byWtKtfHYCWdarSvkE1Fm22T0174oflxEa7WLw1sM+HvlnGR7M2sWpnJk9e2o7reiUDcP2Yufy6xlZ03312C6JcQvdnpnBJp/q8NrRLmdKklFKRmyOo0aRs6+U6PYa9HsjNDF1mnDtvT36ZdnVO2zqsfeYCfxAAW6kcG+WmqVOXMGVVKuOX7qRDg+p8e3tvXhzYkdZ1q+IbLfydXzewc38OY+du9gcBgDG//8lv6+yoqN8v3s7CzXtDWiIdyC0ImfZ6Dbd/vJDf1+lIqkpFush7HoGPMTDzNWh3OUTHQ/qf8PursOrHouvWaAz7NtuWRvettn0RDuyGfzsdw/6+CqrVO+oknfHiVDanH+SDG7tzRouaiEjI8t/W7ubmD+eRk1+2op8rujTg+YEdWbZ9P9ePmUvHhtUZeW1XqsZFs3pnJue/aou1zm1bh5pVYhiU0ohTGycc9XkopU48pT2PIHIDQXG2/wGj+kLKTRCfZHsfFw4Mt8+FWq3g8cBdPX+dAfU6HvXhUzNymP1nOpd0KnkMpE/mbOZf3yw94mPUqRbLRzf1YP7GvcXuZ+PzF/rfT1i6gxd+WsWEu8+gUkzow3g+m7cZEWFwypH1ylZKHV+lBYKw1hGISH/g/wA38K4x5vlCy18B+jmT8UBtY0zo0+OPp/pd4LrvoMnp4HY+mo2/w/opsHMZrJ0Ie9bD6gmh22XtgvljbO6iUgLkHYB9W6B266LHKEXtanGlBgGAod0b0adFTfq8OLXEdd67PoW+rWrz8LdLGTt3CwA3nJbMZV0aMPidWVz+5u9FLuw+aZm57D2YR+2qsbwyeQ0b9xykw+MT6d40kfvOa0nXJol8OGsjj363HIBz2tQhsXJMsfsyxhTJ1SgVdovGwo7FcMHzh15XAWGsIxARN/AmcAHQFhgqIiE9rIwx9xpjOhtjOgOvA1+HKz1l1qxvIAgAJPeGsx+Fy0fa6fW/wOTHQrdZ9hX8eC98eq2d/upmeKuHDQglSVt9RENbiAiNEuO5smtDAEZeeyq1qgZGNK1VNZaz29TB7RKevbwDP93ThxcGduDec1rSuVENGifGcyDPw+6sPFKaJPDwhW1C9n/x679x3ivT6f/qDLLzbUV5gdcwc/0e/m/KOvYdzPMHAYBxS3eQk+/hzrF/sGpn4HxW7sig6YPjSR4xjg9mbiz1nHLyPbw2Za32mVDHxre3wpy3YfOco9tPfg6s+A7CXWqyfRFsLaWUY9cKewMaRuGsLO4OrDPGbDDG5AGfApeWsv5Q7APsT0zxibaOYOnngXkpN9rXxU6yN/1mvzyrx9vpSY/ZiuQlX9icxbvnwqpx9ov1Znd4/0JKtXoCbJ4dmC7Ihf3bAHjuig7Mfehs+rev569o/uq20/jy1l7+1UWE1gkuhswdTPXd9pkI0e7Av7xrkwRu7hNoPTWoa0N2ZtjmqzszctiSns0VXRowtHtje3iPl799HPpshUe+XcbLk9bww+LtDB45izd+WcvUValMCHpq29PjVoRs4/Ua3vvtTxZtsS2lPpu3hZcnreHdGRtK/zzK0dTVqaRm5pR3MlRZ1GxpX31DyATL2V/mxh1MfBA+vw62LbS/a09B8ev9OcN2QD1So86Ed88uefnbveD1U206jnDkg0MJZyBoAGwJmt7qzCtCRJoATYFi/nMgIsNFZL6IzE9LO/pxgY5Yw272i+TT7yGo3c6ZcIpAUoMuevNGwxc3wNc3w/sDYOtc+OoWyLEXQHYugdRAHwDABontf0DGdrvtlKfs/B2L4d8t4JW2YAzRbhe1q8YB8MbVXXhhYAe6NkmgSZLTkzljh93XzqWQttJ+qZd8zpiWs+jcyJa+XdQxtBjq4aarea/bNqY/0I9Xh3QGIC7GzbOXt+fMlrWYuX4PM/kvzcEAACAASURBVNfv8a/v6xg3arq9gGfkFPDSz2sY9v48XvtlnX+9fI/hi/lb+GOzfUToa7+s5akfV/DypDXOcvsjemPqOlIzckjLzA3JXQTbkn6Qwe/MYkv6wWKXHws3fzCPkb8G7sBy8j0M++88ho6aXcpWR2DzbFj5wxFvnn4gj/3ZZbyonYhmvAwfXgrZ+47tfn058QOpofONgecbw1c3HXofm2fb4l6A7HR4pg58/pfA8vxseD0Fvr0dPrjINjxZ+BH88T+7/GA6ZO469HGCWyJumVv0swgOPh9cHNrf6Rg6UfoRXAV8aUzxjfaNMaOAUWAri49nwkK0ugDWTYLkPnDJa1C5Jtz0s71IxyfCWz1hdL/QbQpXNldOCoxtBLYIydcPYd8WGyy+vBFiq0NBDuxxLqg/3AO5znpZu6BqXf8ualeNY0i3xoF9bpoJ/70ALnsbqtixj/Dkwde3UA/4toR+D9Xm/Iezo2IhaTgNEyqxOyuXizvVR0SIjQq9Z7j77BZc2bUhD369lN/W7aZXsyS6N03k/6as9a/jdgn929Vl3NIdPPDlkiLHm74mjXdnbODLBVsRvDwrbzHq4x28u8mmedVT/YmLdrNoyz4a1KjE/uw8rh49h9TMXEZ8vYTreyVTr3ol2jeoxvq0LEZP/5N7zm1BveqV7AF2LIF3z4E75/PT1hgyc/KpV70Sp7eoWSQt81esofXqt4np/zSTV6YyeWWqf7jwtEx7F/bEvn/BD93g4v+zGxlj7y6jiq8jKdW+LTDmfPu+lH4o61KzmLE2jWG9mxZZdupTk4iLdrHqqQsO//g5GZC5A+Jr2h71Qd8nv4PpEFcdXMXXJ5VJ+p/w0wi4YrQd2mXuaOhxq/0OT3nCrjP7behXwgVu8xzbEMMdA08mwnlPw2l3lvyoWWMCv6+sQoHAN5TMiu8One4f7g68z7C5cH9OH2DtJNiz1v5BaHFxywvglXb2e/H3lRBT/DAz/vPzee9cm5u5Y15gXvBzU/KyoMOVh077EQhnINgGBDcpaejMK85VwO1hTMux0XGIbTbaY7itFAaIrWLrEbxeiK1m70b6PQiuKFu2F1yUBBBVKfCF9PliGIgLln0JVZ1mqLn7IaaKfaRmzn5IW2U7waVvsE9XK+6H6/O7c6Ga/Tb0cj7W4OxwQZ79khoDHw9iVsc6fFvnDuT3dfbCALhcElJs1DDBPp7zu9t70yChkv9Ja/8d1o1pq9M4s2UtYqJcNE6MZ/u+bFrUqUqTpHha163KlasbMuz9wJe7SVI8jRPjmbF2N++Pn84Ok0gSWQx0/0bBzpm8i72rmrF2N31OSeCyN3+nRnw05+ZO4kP3BC7gOX5ft4ff1+2heqVoLupYj4/nbAag664vuPzSgUQ37EzBnNFEeXLJW/kTt34XyIw+eWk7qleK5tLOdl6Bx8vSTx4mJWoiG6u2xn5V4cb353Fj76bERbuoyx5Ody+HBcsDgWDiQzbX96/t4A4dNiTEzDdsx8TeQReXtRMD752LWoHHy/LtGXRqVMNeID67hluzn2fdwUoM6daI+JiiP9eyNiUuYvwDsORTSDwF0tfDPUttM2kfTz682BQ6DLKj9cbEl7yv0vxwl+19/8tTMHeUneeOsb8Pn13Lit/2wG4Ycx60vggu/I+d9/PDNhC8firUbmt/D4nNYMhHNmBl77WBDYqOKpxWKPftY4wNUrmZTr8hE1p/t7OYVnqFG4yELBsHBdn2b8nn0KCr/WwrFdMOZtbr9qbPd5PnG+LGGNuxdfLjgXUTm0HjXkV2cSyEs2hoHtBCRJqKSAz2Yv994ZVEpDWQAMwqvOyEE1sF+v4zEASCuVxw5wJ7UTjjATj9XrjgBbusZdAdW8b2QJbx9L/b1+VfB3IOmUFDWrQfaF/XT4X8g9BqgJ1Od8rSC/JgwfuQuhI2/mbnGROoV9i1zPZ/APsD8UnfALPehHVTYN0k6q35H7e1yQVvgc1Oez2w8kf442O7fn42jy7oxcK2n9EpLjXkcZvRbhfntq1jx0vav42B7atz59kt6N++Lm3qVUNE6Ne6NrMfPJufrm/Cih6T+PnOHrRvUJ2usprfYu/mWvdkaor9IUSJvbC5XcJrH32OPFuPM1yL2Xcwn39Hj6K1awtvdNnJ502+pVfCfvZn5/uDQBQFDE57Dfe7/fB6DT8vt48RHbdkOze5x3GOawFgx3G6+9NF7MrIId/jZdXOQPb8o6mL/e9/WZXKte/NYWdGDue4A3Uj+WP/wgOfzITZb9qc1sdXwgeX2IuIp8AWyzlZ+pU7MuDnh2DSo/7t16dlsXb+5MD/wykqfHb8Ki5983c2pGXZO8wDaTTNWU5z2UrG6t/s3bXXA4s+wZMf+kwLYwzf/LGVA7kllGMX5vtepDtFYL88E1g29VmbKwVY+gU8W6/4oVTyDtjijI8uDxmKZfufq/js3RfJzS+A3U6O1hcEwH4eP/3Tvm/Wz373i6ss9X3PV/0Y+rvIyYC9f9oLbtpK+7rwQ3izh73w+vhyBHkH7DkFn2NuJhzYA9/+DZ6oAbPegp8fsTn6l9tA5nbodjNUSoQtQXftXo+9wQsO5IWtn2pv+OKqw5Qn4Z0+trTAVwzk9cDutfaGbsM06H1X6PbGwNu9YdIjoSMbdL7aBqwwCFuOwBhTICJ3ABOxzUfHGGOWi8iTwHxjjC8oXAV8ak62Dg3FqVI7dDo+ER7aZe+A1kywLYWmPGHrDMB+AZr1hbod7Lpv9rRfbJ+Og2HhB7DS+ahanAez3rCtIvZvsX0dxv09sP6dCyEq1l5YmvSGTb/bPwjNhXx5I6Quh5qtAvPmOK2ijNfeiX12jZ3uco0NNEDihu/gze9CizJmj7QP+pn2HGyeBbXawO2FytIL8qg76wnqzn7LTp86hGhXIsOjxgHQSraQ0KQt7Axscm2Pxpw9/1lipYBr3FOY7Q00OLtwpR0I8IMedWj5q71Deuzitrz3468AuPDS9F8/8kJULkRBwZYFPBJtL2TJOZ/YcyGDOf++jM88fakn6bwUbX/YZ7qW0Na1iU8KzmaBsZ9P9uJveTr6v/7jR6/+ng25XcAXDzdMs6/PNSCvejNi9jsXsP4v8M3qevjaZb3362o6NqxB2v9uZoAJurBm7sTE1WCiE7i27M2mmVMckSQZvBr9JpW/ysVbowlbWt9Mk9mP4P72Nu52D+Q1z+Us2boPlwj3fraYK7rs5uXBnWD6S7Yoc80E6HUHRFeyFyCnmMcTFYu/wKd6I5s7cEVBy/Ph1xco4uvh9s72wpehah0bSF7tCDg/21lvQJuLISqOuh/0ZQiG5VMSaJe5PbCPS96wxZ3BAznWbAkbptrK0trtbHFr2ip709PktMB6wa1mgottfMbdZy+avoYbdTvYwAk2AMx+M3T99A3w+2s2Fw72+1+pRmjAccfY+oHsoBGI548JpL9xL/udL2z511Cvs83Rb3Ju0DJ3wPR/2+Ay9Vmbzq7D7LL2V9gck8/2hfb36XPGPyCuGpx6XdFjHSPaoex42rcZJvwzUNb42L7QCP/JEFjzU2D6oV3wTF3A2LuLv6+yFcjBdyNV6tohtX37bHwabJ5ps9Lj7jt0miol2h9Qblbg7iMqzv5gwfakXjsJvr8jsI0vEGTvhRea2i98XqHhN8BeGIb8z+ZQfOXhAJe9Te6O5cTOeQMAT+uLodUA3N/dBsDoeo9z3cDLcI3uR3SuzclkV25IpQNbA/sQF1RrSO7B/XzY+Glu6VGXDRmGZj8OBiDTVCKGAmIltDJ1RP7NzPK25dXot+jiWsdU6U4/M7dI0hfGdONO17/Yty+d5XFFKxd/qHULF6eNLvFjLc5ZuS9RNcrDd257N7yuSgrNs+x3eWrlC7ht/1/wFBTwzIDGDJp6NmI8jCy4mFujAhXKnxX0ZUjUtJD9XpP3IDf+ZRg3fTCfU+u4+LrZOPjjo8AKgz8kt1pTYt/twyv1XqL+qefT/oeLqJ9YhYQ2/exwKxMeKD7R9y635d3BkvvYoqMtQQG/6w02d1qYuAJDsQyfZos3/t3c5qQAhk2w9VnFia8JB50hUE693t4UFeeUs21fH59KCbYeYtpzcNcf8FYvaH6OLXat09Y29S6Lv86wOZngzzJYn/tgxn+KX9bpaltEtfQLuOJdG+wWfVx0vSanw7BxNlhNfxHcseAJahl040Ro1OOY5ARK61AWuWMNlYcajWHoWPvPvejVov9c37MPLngRHtxqh7KIqWLndR1my2mv+RxuDvrSt7rA7rNeJzudtdP+UNuXUKnUpLety/BJam6LroKzoAVBzSR3LC5ahnvAaTm0eQ5gig8CYFvE7Fxqc0IA135lXzfN9AcBAPf+LbgP2vJcU7Uet6S/QuwbnW0Q6HYLnHKWDQK1gy5I3YfD/s3E5u/nlvV3wieDaLb3d//iqpJdJAgAPB/9LpNjHqCLyxZZnFG7+Cahp8ZsZsY/+oUGgbMeZoanPQDnxNmy3ElxNsCNiH2IB+OfKP5zcPwSez/PyNv+6a/3Bupg+h2YwKqoq1kUewsxM15EnP9HJ7F3whvj7Ui157mL3gTdFfUN7370Ad1kFdftH1n0wpX+J9lf20Bea8sE/vnVUpIkg98y65HV9wlISA5ZPc0Ees2vya4aWNCwm33dOAO2zObT2EGBZYWCwD7jVJC2DjSRfn6eBxNbDR5Js//X85+zd/23zbQr9C1UYXwwaByskoIA2Jx1rdb2psh3zDr2/8QXw2zQOvdJuPAlmwMvhfG1/rv+R1tJfUnQAJQdnPOt0wHOe8YGGx9f2f2F/7HLzrgfzn4MLhtpK3h9xbwAbYNa0Z/7pH096yF7g3VdUEX2DeOhcc+wFQcF00BQHhr3hJRhRef3+bu92HW5FmKdH6DvItvu8sB6DVMgxlnesr99vWE8PLLH3gHd8KPN5g58Dy4fBbcGLpDcMA4eWA9JLex0QhN75w72zqOwP6fDtgW2GKmXkyv4dzN4IRm+GW6LE9xOGck1X8K1hfoEjjzdVhgCNOxuKycLX6h2LPKXocuFLwcqzsBefK76BAa9Dzc6FXSJzaBBMTc2aycXnefjO0cgu0pjaHcF9LgN966irZkAyNqF66kk/+Te1kOhz/2sP+ddAOK22KKdc/7+Phuv/JnnRjxA696X+Ne/L+9WitPetdH/fqbXXqz2mcpkGNvSqbLkcln+eBZ6m/O7px293LY58g8ZtgVTgmQV2WcP1yrGxjzDF7FP0sUbaL48qvo99s3kx6iRbus+ro2awvmuuSSRwebceNo/NpGHphQeeNDwR89X2druVs579bfA7POehubn+ienJQ0J3Swqzv92eN7f+TbuMgrOedo/b+SsXaQ6LbC48CXo9Tf7vk47uGcZnPnPIuc2s/W/Qqa3Nrm8yDr5jXrD7XOgSi07o24n24AD7Her01WQ5IwLVjmo+Hb4NFu8GuRlroHoyjZNYC/Cf5sNA14KBDUBTrsDKtcKbJhknztCvS52WdIpUKMRdB5q91Gvc2DdQR/Arb/Zv4ZdQ0+mSa9AYA5+ZkqYaSA4kbS6AP42M7S5WZ/7bKsC3x2/zxlOOWXTM+xrbJXQHtFg70Q6DYG6zt1RuyvslzIqxpYZAyQ0hVPOstnp5ufYu5Khn8Lt8+xFe9YbsHWe/YKedmdg39l7bWumGk3sHdlpd0KLc6H52ba4qbDYaracM7jct/FpoT/+Gk1sYIsOaqFSrb5Na7vLA8Vjf51e9AcEoeWqPrWduoUqdeyxmp5Jtfv/gCvHBD4XH99Fov1AWz4clEtKqNUARLjhzDaQ3AdxysYlJp7k9j0QEc5oVce//o3DbmFD//8F9n3WI0WStsI0YVDuo/TOfY1/1v+AdYMms7Oe7Vi0NrEfC0wL/7ozvfbCtDY69OJgOgwKmW7iCjSZHL0rsP16aUyq294xvxPzKtHiYY9z5z9xU8guWOhtyeXTanP6gjNC5v+4oyrPRwUCXJarGi/lD2J07YfYc89mxl/yh3/ZBlcT7tk3mJYvLefABa/zZL5tg78+Ncvfb8R/DsYwaXsMk1amsvLKqfbCCxS4Yrh6UXu2UxvcsXzW+QNeWlt0cMcWj/xsR9Z12uCb2m3s97npmVCtIfR9kHyPl5x8j/2d+FRvBHfM9+e6r3c/x+s5Azhw92qIT+S7RdtYl5rFn67GfOHqD8nO59HtZvI9Xg7mB+WiL3jB3ngV970E22zcR8TWYdTtUGQ1j9fYAHX1F6HbhNmJ0o9AleTsR+1fYb3vthffsrbxfmS3La/16XSV3TbFKXK6Y0EgF9LKKbMNHiIjqXmgTwLYwLRjsb3rOevhQx8/12mOd97T9iLb7SZ71+X12GICsEVSLhfcvcQO2zH7raKD+flGeY2pQpkM/si2Omk/0KY1WIfBtlfokk9tRfyVY2yTw+qN4bw0+PY2W7YLoc0n+z8PI3sXOVTToMeStjulGdSrDr4qnzPut8Vy/+0PjXrSeuM9VKsSzdLctuTke7nrkl40r1cNWo2F5d/iOtiFGd//wF1R3wLwtyvO54l1PRl4ekd41w6h/qbram6//A0Y+C6njfiAT2KeIbljH38FaM8OrcBp5n59zt+57+JuXBa/FPnWXsxzYmvCQaieVBecf/WN3keYlx8Yol0Evq92Ff33f8Ed32xE8DLCufH/bd1ufuNy2AzPPG9zDktiK1FNshnQrTUfzt6M10C7b5KwI83AdWPmUuA1tKhdhQs61GPC0h0kxMcwd2OgQvaTW3qwvt17vL3AJqpfzov0OKUm02dn0NNlbzKWe5vQzhWIYCt3ZFDV3ZgmbKH/2D2MuCKVrc1fpl3fRNatPcBPyxfYfivXp9DX2WbRHjedGyfANV+SM+0/zFxpmxM/Mn49betV4+lxtpFE9UrR7M/O54InzqfKo+kgLu76eCETlu3koeiLqN+oKRfGVPa38U/NzOHVyWt5+MI2xMdEkVfgxeM1VBr+a+A3VoyZ63dz9eg5TLi7D61bnMv0NWnFjkIcDlpZrEq2aKxtoQRw02Ro1C0w6uqZ/7StS9pcYttwB/t6uH3qG0DPv9kLuq9S7FhaPcFmz3cshnWTbYW5r032uU/Zi/q5T5Zexpp3wHbW6/dg6MOKwJYt715jmwN2uymQiwKY84597fHX0G3+4zQ9fHy/bQb4RA0bcAY6FcuZuyAqlnRvPJWi3fy6Jo1nxq9g0r1nEhcdCOrGGHbuy6Le221s8eAjuwN9FZz/wfiBqxjQwQbGict3Yoyhf/t6gf/R4/v9LdFuTp7M61efSiWXB552ijTuXUF6VC0S4qORJ2qwifrUeWgZI39dz6QVu1i+3Qbvn+7pQ/9XZwDw5tWnMvfH0czLTGKFSS7ycdZlD/VlD4/+bRiXvfl7keUlqVc9jt1ZueR7DC3rVGHNrqJFYAAx5PNA1GeMKriQeXG2j0xyzifUiI/Ge3AvbV2bQ1qYFWdj3NUA/KvTbzx7eQdmrE3jse+Ws2F3KWODAd/e3psGNSoxf2M6twUNtRIf4+bjm3uwYNNehvVuygs/rWLU9A08fnFbbujdlBv+O5dpq9OY99A5PDd+JSMGtKZyTBQukZDBH2/9aAE/Ld9J1dgo7j+/FY99v5znrujgH+LlaOkw1Oro5Oy3xTJgu7gv/8be2X91k+3sc1Wh1hD5ObYZ7LrJNhB4PbYu4Ug7JZVFxnb4eDBc9Irtjdl+4HGpZCviYLrtAerrnJWbaduUFy62K6u8g/Z8agcNDvj7a7b3+NWfFr/Nqx3tNo/vt8UleQegetDoLsGBwrFu/VqqV69BrZo2SHi8hsHvzOKm05tyfru6nPKv8SFPvpu1fg9DRwdaDQ3rncy61Cw2px/kvvNacUmn+sxct5uU5EROe34Kew/m06VRDeZv2suFHerxn8GdaP2IzS7ddHpT/tb3FCrFuJm0Yhf3fraI4h7TveHZAXR64mcynb4StdlLu/rVmLrdTWyUizrV4ticftB/B1+S+2ovoGZMAc+k9aZrk4SQBzyV5sUrOzJx2U6mrAoUv/VqlsSsDYFhV/q1qsXU1XZ/3ZMT+eDG7rR51J5nzSqx7M7K5Z5zWvDWtPX0aJrI29d2ZUv6QRolxnP6C7+w76BNd2yUi9wCLzeclsyjF7Ult8Bb4ojBZaWBQB17viahZ/zDtnhQJ478bBt8Y0soPtu13BYTBgeXQ8jMyadStJsoZ9BCr9fwzvQNnNu2Dt8v3s5fz2hG5dioYocez8jJx+OxAw2+MXUdLw3qxJVdGzJz/W5W78wsMnzGhrQsFm/dx72fBTr3VY2LYunj55OT78Elwp+7D/Dkj8t55y8pzNuYTu2qsbSpW43MnAIycvLZmZHDoJGhbfxfGdKJL+Zv5dYzT2Fz+kEe/ta2hruuVxM+nBUoZmpRuwq7s3LZezA0mCTER4fMe+6KDvRslkS/l6aV+LnFRbvK1Pu7WlwUGTkFjPpLV4Z/tKDIcpfAy4M7c2nn+kdcVKSBQIXHhmm23Lu04RWUcuTkexg7dzPX9Ghie6Ifws0fzGddaibvD+tOfKzbP8hiWZ323BS8Bi7tUp8zWtSid/PAGFPLt+/nwtdsvcafzw1gyKjZdGhQnWG9k6lTLY7nxq9i4vKd5Hm87MnK5bIuDfh64TYaJVZiS3o2AJPuPYMWdaqSmplD92emFDl+8EW9VZ2qrN6VSdcmCSzYtJeqsVH+nI1Pz2aJfDq8F7f9bwETlu0ssj+wuadHLiq96KskGgiUUhEnK7cAd6FyeJ8Cj5fmD9nmyMFP5fPJK/CSnefh1v8tIDM3n2/+1ptfV6fRpXENNqcfJCbKFfLs8bl/ptM4MZ6kKjG0eGgC3ZMT+fzWXmxIy2L1zkzOa1eX9AN55Hu8zN+0lzNb1uKNX9Zycx+bk/rPz6u5rlcyTWtW5q1p63jxp9W0qlOVG3onU7daHHeO/YOs3AK+uu00ujY5ssfJaiBQSqlCpq5KpUFCJVrWKbklz+Y9B/EaQ3JQi7BD2bznIAmVo6kad2Q55YN5BczfuJdTmyRQJdbWLc39M50/Nu/lr86IuEdCA4FSSkU4HWJCKaVUiTQQKKVUhNNAoJRSEU4DgVJKRTgNBEopFeE0ECilVITTQKCUUhFOA4FSSkW4k65DmYikAZsOuWLxagKFH8dU0ek5RwY958hwNOfcxBhTq7gFJ10gOBoiMr+knnUVlZ5zZNBzjgzhOmctGlJKqQingUAppSJcpAWCUeWdgHKg5xwZ9JwjQ1jOOaLqCJRSShUVaTkCpZRShWggUEqpCBcxgUBE+ovIahFZJyIjyjs9x4qIjBGRVBFZFjQvUUQmicha5zXBmS8i8przGSwRkVPLL+VHTkQaichUEVkhIstF5G5nfoU9bxGJE5G5IrLYOecnnPlNRWSOc26fiUiMMz/WmV7nLE8uz/QfKRFxi8gfIvKjM12hzxdARDaKyFIRWSQi8515Yf1uR0QgEBE38CZwAdAWGCoiR/YE6BPP+0D/QvNGAFOMMS2AKc402PNv4fwNB94+Tmk81gqA+4wxbYGewO3O/7Min3cucJYxphPQGegvIj2BF4BXjDHNgb3ATc76NwF7nfmvOOudjO4GVgZNV/Tz9elnjOkc1GcgvN9tY0yF/wN6ARODph8EHizvdB3D80sGlgVNrwbqOe/rAaud9+8AQ4tb72T+A74Dzo2U8wbigYVAD2wv0yhnvv97DkwEejnvo5z1pLzTfpjn2dC56J0F/AhIRT7foPPeCNQsNC+s3+2IyBEADYAtQdNbnXkVVR1jzA7n/U6gjvO+wn0OThFAF2AOFfy8nWKSRUAqMAlYD+wzxhQ4qwSfl/+cneX7gaTjm+Kj9irwD8DrTCdRsc/XxwA/i8gCERnuzAvrdzvqSFOqTg7GGCMiFbKNsIhUAb4C7jHGZIiIf1lFPG9jjAfoLCI1gG+A1uWcpLARkYuAVGPMAhHpW97pOc5ON8ZsE5HawCQRWRW8MBzf7UjJEWwDGgVNN3TmVVS7RKQegPOa6syvMJ+DiERjg8DHxpivndkV/rwBjDH7gKnYopEaIuK7oQs+L/85O8urA3uOc1KPRm/gEhHZCHyKLR76Pyru+foZY7Y5r6nYgN+dMH+3IyUQzANaOC0OYoCrgO/LOU3h9D1wvfP+emwZum/+dU5Lg57A/qDs5klD7K3/e8BKY8zLQYsq7HmLSC0nJ4CIVMLWiazEBoQrndUKn7Pvs7gS+MU4hcgnA2PMg8aYhsaYZOzv9RdjzDVU0PP1EZHKIlLV9x44D1hGuL/b5V0xchwrYAYAa7Dlqg+Vd3qO4XmNBXYA+djywZuwZaNTgLXAZCDRWVewrafWA0uBlPJO/xGe8+nYctQlwCLnb0BFPm+gI/CHc87LgEed+c2AucA64Asg1pkf50yvc5Y3K+9zOIpz7wv8GAnn65zfYudvue9aFe7vtg4xoZRSES5SioaUUkqVQAOBUkpFOA0ESikV4TQQKKVUhNNAoJRSEU4DgVLHkYj09Y2kqdSJQgOBUkpFOA0EShVDRK51xv9fJCLvOAO+ZYnIK87zAKaISC1n3c4iMtsZD/6boLHim4vIZOcZAgtF5BRn91VE5EsRWSUiH0vwIElKlQMNBEoVIiJtgCFAb2NMZ8ADXANUBuYbY9oBvwKPOZt8CPzTGNMR27vTN/9j4E1jnyFwGrYHONjRUu/BPhujGXZcHaXKjY4+qlRRZwNdgXnOzXol7CBfXuAzZ53/AV+LSHWghjHmV2f+B8AXzngxDYwx3wAYY3IAnP3NNcZsdaYXYZ8n8Vv4T0up4mkgUKooAT4wxjwYMlPkkULrHen4LLlB7z3o71CVMy0aUqqoKcCVznjwvufFNsH+XnwjX14N/GaM2Q/sFZE+zvy/AL8aYzKBrSJymbOPWBGJP65noVQZ6Z2IUoUYY1aIyMPYp0S5sCO7nCbycQAAAGpJREFU3g4cALo7y1Kx9QhghwUe6VzoNwDDnPl/Ad4RkSedfQw6jqehVJnp6KNKlZGIZBljqpR3OpQ61rRoSCmlIpzmCJRSKsJpjkAppSKcBgKllIpwGgiUUirCaSBQSqkIp4FAKaUi3P8DvIrS8S+u0gMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjsmz2HZQo64"
      },
      "source": [
        "Model predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1xo_ePjGvoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d210a678-e05e-4a39-a254-27a6a88c47a0"
      },
      "source": [
        "#predict on testing dataset\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "K.set_value(model.optimizer.learning_rate, 0.0008)\n",
        "y_pred = model.predict(x_test_norm)\n",
        "y_pred\n",
        "#print('y_pred',y_pred)\n",
        "y_pred.shape, y_test.shape\n",
        "y_test = y_test.argmax(axis=-1)\n",
        "print('y_test', y_test)\n",
        "y_pred = y_pred.argmax(axis=-1)\n",
        "print('y_pred',y_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_test [3 2 4 2 1 1 1 1 1 1 0 1 1 1 1 2 2 3 3 2 2 1 1 1 1 1 1 1 1 1 0 1 1 1 2 2 2\n",
            " 3 4 4 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 2 2 3 4 3 1 0 1 1 1 0 0 0 0 0 0 1\n",
            " 1 1 2 3 2 2 1 1 0 1 0 0 0 0 1 0 1 0 2 3 2 3 1 1 1 0 0 0 0 0 2 1 2 2 2 2 2\n",
            " 3 3 2 2 1 1]\n",
            "y_pred [2 2 3 2 1 1 1 1 1 1 1 1 0 1 1 2 1 2 3 2 2 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 2\n",
            " 3 4 4 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 2 2 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 2 3 2 1 1 1 1 0 1 1 1 1 1 1 1 1 3 3 2 2 1 1 1 1 1 1 1 0 2 1 3 3 3 3 3\n",
            " 3 3 2 2 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAg-ssPAO4hN",
        "outputId": "3560dd2e-d99d-4bc6-a72d-09e8973d5477"
      },
      "source": [
        "#Compute Recall, precision, f1_score\n",
        "# from sklearn.metrics import precision_score , recall_score\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.04      0.06        24\n",
            "           1       0.63      0.85      0.72        54\n",
            "           2       0.82      0.58      0.68        24\n",
            "           3       0.50      0.73      0.59        11\n",
            "           4       1.00      0.50      0.67         4\n",
            "\n",
            "    accuracy                           0.61       117\n",
            "   macro avg       0.61      0.54      0.55       117\n",
            "weighted avg       0.56      0.61      0.57       117\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxaq8MZKPjPg",
        "outputId": "a47a4d5c-b58e-4c73-cedc-ccfdae5698dd"
      },
      "source": [
        "#Compute confusion matrix using accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1, 23,  0,  0,  0],\n",
              "       [ 8, 46,  0,  0,  0],\n",
              "       [ 0,  4, 14,  6,  0],\n",
              "       [ 0,  0,  3,  8,  0],\n",
              "       [ 0,  0,  0,  2,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "qb0VpRt_d32E",
        "outputId": "c647f7cc-45e7-4658-887f-c074da423446"
      },
      "source": [
        "#SMOTE Implementation \n",
        "#Link: https://machinelearningmastery.com/multi-class-imbalanced-classification/ \n",
        "\n",
        "# example of oversampling a multi-class classification dataset\n",
        "from pandas import read_csv\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# define the dataset location\n",
        "url = '/content/drive/Shareddrives/CS_229_project/Electricity_Consumption_data/dataset.csv'\n",
        "# load the csv file as a data frame\n",
        "df = read_csv(url, usecols=['AWND','PRCP','TAVG','TMIN','TMAX','CLASS_2'])\n",
        "df = df.fillna(0).dropna()\n",
        "data = df.values\n",
        "\n",
        "# split into input and output elements\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "\n",
        "# label encode the target variable\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize distribution\n",
        "counter = Counter(y)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class=3, n=1203 (20.000%)\n",
            "Class=2, n=1203 (20.000%)\n",
            "Class=1, n=1203 (20.000%)\n",
            "Class=4, n=1203 (20.000%)\n",
            "Class=0, n=1203 (20.000%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "NRD-2FPebJj2",
        "outputId": "684fa9e7-0c0d-4b0b-963b-8f78d7b05646"
      },
      "source": [
        "# summarize distribution\n",
        "counter = Counter(train_labels)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class=3, n=247 (4.106%)\n",
            "Class=0, n=371 (6.168%)\n",
            "Class=1, n=1149 (19.102%)\n",
            "Class=2, n=417 (6.933%)\n",
            "Class=4, n=35 (0.582%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPDUlEQVR4nO3cf6zddX3H8edrreCvzCLcENY2u01sXDozldxgF5LF0E0LGMsf6CBOO9elWYIbDhMt2x9k2z+YLf5KHEtjO2tGQIIYGiFzDWDIkoHeKkOgOm4QbBuwV/mhG1FXfe+P8+m8XlvKPef2HODzfCQ35/P9fD7n+31/Q/o6Xz7ne76pKiRJffi1SRcgSRofQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMnDf0ku5McSfLAgr6/T/KtJPcn+WKSVQvGrk4yl+TbSd6+oH9z65tLsmP5T0WSdDLP50r/s8DmRX37gDdU1e8A/wVcDZBkA3AZ8NvtPf+YZEWSFcCngQuBDcDlba4kaYxWnmxCVd2dZHpR378t2LwHuLS1twA3VtVPgO8kmQPOa2NzVfUIQJIb29yHnuvYZ511Vk1PTz/XFEnSIvv37/9+VU0db+ykof88/Anw+dZezeBD4JhDrQ/g4KL+t5xsx9PT08zOzi5DiZLUjySPnWhspC9yk/w1cBS4fpT9LNrn9iSzSWbn5+eXa7eSJEYI/SR/DLwDeE/94gE+h4G1C6ataX0n6v8VVbWzqmaqamZq6rj/dyJJGtJQoZ9kM/Bh4J1V9eyCob3AZUlOT7IOWA98FfgasD7JuiSnMfiyd+9opUuSluqka/pJbgDeCpyV5BBwDYO7dU4H9iUBuKeq/qyqHkxyE4MvaI8CV1TVz9p+PgB8GVgB7K6qB0/B+UiSnkNeyI9WnpmZKb/IlaSlSbK/qmaON+YvciWpI4a+JHXE0Jekjhj6ktSR5fhFrl6ApnfcNukSls2j11486RKklwyv9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkdOGvpJdic5kuSBBX2vTbIvycPt9YzWnySfSjKX5P4k5y54z9Y2/+EkW0/N6UiSnsvzudL/LLB5Ud8O4I6qWg/c0bYBLgTWt7/twHUw+JAArgHeApwHXHPsg0KSND4nDf2quht4clH3FmBPa+8BLlnQ/7kauAdYleQc4O3Avqp6sqqeAvbxqx8kkqRTbNg1/bOr6vHWfgI4u7VXAwcXzDvU+k7UL0kao5G/yK2qAmoZagEgyfYks0lm5+fnl2u3kiSGD/3vtWUb2uuR1n8YWLtg3prWd6L+X1FVO6tqpqpmpqamhixPknQ8w4b+XuDYHThbgVsX9L+v3cWzEXimLQN9GXhbkjPaF7hva32SpDFaebIJSW4A3gqcleQQg7twrgVuSrINeAx4d5t+O3ARMAc8C7wfoKqeTPJ3wNfavL+tqsVfDkuSTrGThn5VXX6CoU3HmVvAFSfYz25g95KqkyQtK3+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZKTQT/KXSR5M8kCSG5K8PMm6JPcmmUvy+SSntbmnt+25Nj69HCcgSXr+hg79JKuBvwBmquoNwArgMuCjwMer6nXAU8C29pZtwFOt/+NtniRpjEZd3lkJvCLJSuCVwOPABcDNbXwPcElrb2nbtPFNSTLi8SVJSzB06FfVYeAfgO8yCPtngP3A01V1tE07BKxu7dXAwfbeo23+mcMeX5K0dKMs75zB4Op9HfAbwKuAzaMWlGR7ktkks/Pz86PuTpK0wCjLO78PfKeq5qvqf4FbgPOBVW25B2ANcLi1DwNrAdr4a4AfLN5pVe2sqpmqmpmamhqhPEnSYqOE/neBjUle2dbmNwEPAXcBl7Y5W4FbW3tv26aN31lVNcLxJUlLNMqa/r0MvpD9OvDNtq+dwEeAq5LMMViz39Xesgs4s/VfBewYoW5J0hBWnnzKiVXVNcA1i7ofAc47ztwfA+8a5XiSpNH4i1xJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMjhX6SVUluTvKtJAeS/G6S1ybZl+Th9npGm5skn0oyl+T+JOcuzylIkp6vUa/0Pwn8a1X9FvBG4ACwA7ijqtYDd7RtgAuB9e1vO3DdiMeWJC3R0KGf5DXA7wG7AKrqp1X1NLAF2NOm7QEuae0twOdq4B5gVZJzhq5ckrRko1zprwPmgX9O8o0kn0nyKuDsqnq8zXkCOLu1VwMHF7z/UOuTJI3JKKG/EjgXuK6q3gz8D79YygGgqgqopew0yfYks0lm5+fnRyhPkrTYKKF/CDhUVfe27ZsZfAh879iyTXs90sYPA2sXvH9N6/slVbWzqmaqamZqamqE8iRJiw0d+lX1BHAwyetb1ybgIWAvsLX1bQVube29wPvaXTwbgWcWLANJksZg5Yjv/3Pg+iSnAY8A72fwQXJTkm3AY8C729zbgYuAOeDZNleSNEYjhX5V3QfMHGdo03HmFnDFKMeTJI3GX+RKUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0ZOfSTrEjyjSRfatvrktybZC7J55Oc1vpPb9tzbXx61GNLkpZm5TLs40rgAPDrbfujwMer6sYk/wRsA65rr09V1euSXNbm/eEyHF/6JdM7bpt0Ccvm0WsvnnQJeokZ6Uo/yRrgYuAzbTvABcDNbcoe4JLW3tK2aeOb2nxJ0piMurzzCeDDwM/b9pnA01V1tG0fAla39mrgIEAbf6bNlySNydChn+QdwJGq2r+M9ZBke5LZJLPz8/PLuWtJ6t4oV/rnA+9M8ihwI4NlnU8Cq5Ic+65gDXC4tQ8DawHa+GuAHyzeaVXtrKqZqpqZmpoaoTxJ0mJDh35VXV1Va6pqGrgMuLOq3gPcBVzapm0Fbm3tvW2bNn5nVdWwx5ckLd2puE//I8BVSeYYrNnvav27gDNb/1XAjlNwbEnSc1iOWzapqq8AX2ntR4DzjjPnx8C7luN4kqThLEvov1C9VO7X9l5tScvFxzBIUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTlpAuQtLymd9w26RKWzaPXXjzpEl5yvNKXpI4Y+pLUEUNfkjpi6EtSR4YO/SRrk9yV5KEkDya5svW/Nsm+JA+31zNaf5J8KslckvuTnLtcJyFJen5GudI/CnyoqjYAG4ErkmwAdgB3VNV64I62DXAhsL79bQeuG+HYkqQhDB36VfV4VX29tX8EHABWA1uAPW3aHuCS1t4CfK4G7gFWJTln6MolSUu2LGv6SaaBNwP3AmdX1eNt6Ang7NZeDRxc8LZDrU+SNCYjh36SVwNfAD5YVT9cOFZVBdQS97c9yWyS2fn5+VHLkyQtMFLoJ3kZg8C/vqpuad3fO7Zs016PtP7DwNoFb1/T+n5JVe2sqpmqmpmamhqlPEnSIqPcvRNgF3Cgqj62YGgvsLW1twK3Luh/X7uLZyPwzIJlIEnSGIzy7J3zgfcC30xyX+v7K+Ba4KYk24DHgHe3sduBi4A54Fng/SMcW5I0hKFDv6r+HcgJhjcdZ34BVwx7PEnS6PxFriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMrJ12AJC2X6R23TbqEZfPotRefkv16pS9JHTH0JakjYw/9JJuTfDvJXJId4z6+JPVsrKGfZAXwaeBCYANweZIN46xBkno27iv984C5qnqkqn4K3AhsGXMNktStcYf+auDggu1DrU+SNAapqvEdLLkU2FxVf9q23wu8pao+sGDOdmB723w98O2xFTics4DvT7qICen53KHv8+/53OGFf/6/WVVTxxsY9336h4G1C7bXtL7/V1U7gZ3jLGoUSWarambSdUxCz+cOfZ9/z+cOL+7zH/fyzteA9UnWJTkNuAzYO+YaJKlbY73Sr6qjST4AfBlYAeyuqgfHWYMk9Wzsj2GoqtuB28d93FPoRbMUdQr0fO7Q9/n3fO7wIj7/sX6RK0maLB/DIEkdMfRH0OsjJZLsTnIkyQOTrmXckqxNcleSh5I8mOTKSdc0TklenuSrSf6znf/fTLqmcUuyIsk3knxp0rUMw9AfUuePlPgssHnSRUzIUeBDVbUB2Ahc0dF/d4CfABdU1RuBNwGbk2yccE3jdiVwYNJFDMvQH163j5SoqruBJyddxyRU1eNV9fXW/hGDf/zd/Kq8Bv67bb6s/XXzxWCSNcDFwGcmXcuwDP3h+UiJziWZBt4M3DvZSsarLW/cBxwB9lVVT+f/CeDDwM8nXciwDH1pCEleDXwB+GBV/XDS9YxTVf2sqt7E4Bf15yV5w6RrGock7wCOVNX+SdcyCkN/eCd9pIRempK8jEHgX19Vt0y6nkmpqqeBu+jn+53zgXcmeZTBcu4FSf5lsiUtnaE/PB8p0aEkAXYBB6rqY5OuZ9ySTCVZ1dqvAP4A+NZkqxqPqrq6qtZU1TSDf+93VtUfTbisJTP0h1RVR4Fjj5Q4ANzUyyMlktwA/Afw+iSHkmybdE1jdD7wXgZXefe1v4smXdQYnQPcleR+Bhc++6rqRXnrYq/8Ra4kdcQrfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JH/g9jkL4b9MNe5AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0okPL_7miuD",
        "outputId": "221d139b-c91d-4697-b4eb-e17183d745a3"
      },
      "source": [
        "#Latest X & y values\n",
        "print('X',X.shape)\n",
        "print('y', y.shape)\n",
        "#print('X:',X)\n",
        "#print('y:',y)\n",
        "#type(X)\n",
        "type(y)\n",
        "n = X.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X (6015, 5)\n",
            "y (6015,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmBSXbkfzv8V",
        "outputId": "4df92bba-8f3a-4184-b1ae-a8291a7610b3"
      },
      "source": [
        "#Concetanate X & y\n",
        "y = np.reshape(y, (n,1))\n",
        "print('y',y)\n",
        "data = np.concatenate((X, y), axis=1)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y [[3]\n",
            " [3]\n",
            " [2]\n",
            " ...\n",
            " [4]\n",
            " [4]\n",
            " [4]]\n",
            "[[6.58105300e+00 3.34693860e-02 7.74082260e+01 9.07626600e+01\n",
            "  6.59683500e+01 3.00000000e+00]\n",
            " [6.80578950e+00 7.65306100e-02 7.61230300e+01 9.00157700e+01\n",
            "  6.45078900e+01 3.00000000e+00]\n",
            " [7.07631600e+00 3.77551020e-02 7.48801300e+01 8.82555200e+01\n",
            "  6.32902220e+01 2.00000000e+00]\n",
            " ...\n",
            " [5.40856159e+00 1.76937391e-03 7.67178621e+01 9.23969295e+01\n",
            "  6.25607612e+01 4.00000000e+00]\n",
            " [6.62582072e+00 7.73094667e-04 7.60397488e+01 9.08063850e+01\n",
            "  6.35384329e+01 4.00000000e+00]\n",
            " [5.35608123e+00 2.74300844e-04 8.06906696e+01 9.63738705e+01\n",
            "  6.62492523e+01 4.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma5Eh3Yl1inr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "936f2e74-2779-422b-eaed-2363310fc442"
      },
      "source": [
        "#Convert 'data' to pandas dataframe\n",
        "dataset_s = pd.DataFrame(data, columns=['AWND','PRCP','TAVG','TMIN','TMAX','CLASS_2'])\n",
        "dataset_s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AWND</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>TAVG</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>CLASS_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.581053</td>\n",
              "      <td>0.033469</td>\n",
              "      <td>77.408226</td>\n",
              "      <td>90.762660</td>\n",
              "      <td>65.968350</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.805790</td>\n",
              "      <td>0.076531</td>\n",
              "      <td>76.123030</td>\n",
              "      <td>90.015770</td>\n",
              "      <td>64.507890</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.076316</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>74.880130</td>\n",
              "      <td>88.255520</td>\n",
              "      <td>63.290222</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.569474</td>\n",
              "      <td>0.112245</td>\n",
              "      <td>73.870660</td>\n",
              "      <td>87.555210</td>\n",
              "      <td>62.066246</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.417368</td>\n",
              "      <td>0.071633</td>\n",
              "      <td>71.583595</td>\n",
              "      <td>84.826500</td>\n",
              "      <td>60.249210</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6010</th>\n",
              "      <td>6.181162</td>\n",
              "      <td>0.000852</td>\n",
              "      <td>80.295436</td>\n",
              "      <td>95.779341</td>\n",
              "      <td>65.792416</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6011</th>\n",
              "      <td>6.220058</td>\n",
              "      <td>0.010941</td>\n",
              "      <td>78.999983</td>\n",
              "      <td>93.647921</td>\n",
              "      <td>66.704280</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6012</th>\n",
              "      <td>5.408562</td>\n",
              "      <td>0.001769</td>\n",
              "      <td>76.717862</td>\n",
              "      <td>92.396929</td>\n",
              "      <td>62.560761</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6013</th>\n",
              "      <td>6.625821</td>\n",
              "      <td>0.000773</td>\n",
              "      <td>76.039749</td>\n",
              "      <td>90.806385</td>\n",
              "      <td>63.538433</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6014</th>\n",
              "      <td>5.356081</td>\n",
              "      <td>0.000274</td>\n",
              "      <td>80.690670</td>\n",
              "      <td>96.373870</td>\n",
              "      <td>66.249252</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6015 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          AWND      PRCP       TAVG       TMIN       TMAX  CLASS_2\n",
              "0     6.581053  0.033469  77.408226  90.762660  65.968350      3.0\n",
              "1     6.805790  0.076531  76.123030  90.015770  64.507890      3.0\n",
              "2     7.076316  0.037755  74.880130  88.255520  63.290222      2.0\n",
              "3     6.569474  0.112245  73.870660  87.555210  62.066246      2.0\n",
              "4     7.417368  0.071633  71.583595  84.826500  60.249210      2.0\n",
              "...        ...       ...        ...        ...        ...      ...\n",
              "6010  6.181162  0.000852  80.295436  95.779341  65.792416      4.0\n",
              "6011  6.220058  0.010941  78.999983  93.647921  66.704280      4.0\n",
              "6012  5.408562  0.001769  76.717862  92.396929  62.560761      4.0\n",
              "6013  6.625821  0.000773  76.039749  90.806385  63.538433      4.0\n",
              "6014  5.356081  0.000274  80.690670  96.373870  66.249252      4.0\n",
              "\n",
              "[6015 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTYD43zn3Dl9",
        "outputId": "7e27a9e7-cc18-4cbc-d28d-b94487f5a1b0"
      },
      "source": [
        "#split train & test dataset\n",
        "train_s = dataset_s.sample(frac=0.95) #random_state=0\n",
        "test_s = dataset_s.drop(train_s.index)\n",
        "print(train_s.shape, test_s.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5714, 6) (301, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx9uD8h93DoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d203d24-66cb-46d9-9b8e-7c6f40f4b4fb"
      },
      "source": [
        "#Create one-hot encoding for TRAIN dataset\n",
        "existing_vals = np.unique(train_s['CLASS_2'].values)\n",
        "mapping = {val: idx for idx, val in enumerate(existing_vals)}\n",
        "y_train_s = np.array([mapping[y] for y in train_s['CLASS_2'].values])\n",
        "y_train_s = np_utils.to_categorical(y_train_s)\n",
        "print(y_train_s.shape)\n",
        "y_train_s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5714, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ETFAkIL3Dqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27ba908-25a7-4136-d5d3-762eb58aef81"
      },
      "source": [
        "#Create one-hot encoding for TEST dataset\n",
        "existing_vals = np.unique(test_s['CLASS_2'].values)\n",
        "mapping = {val: idx for idx, val in enumerate(existing_vals)}\n",
        "y_test_s = np.array([mapping[x] for x in test_s['CLASS_2'].values])\n",
        "y_test_s = np_utils.to_categorical(y_test_s)\n",
        "\n",
        "print(y_test_s.shape)\n",
        "y_test_s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(301, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg3oJMbD3Dss",
        "outputId": "d0dab41d-4224-47f6-8d29-5e8796b03703"
      },
      "source": [
        "#train data normalization\n",
        "train_features_s = train_s.copy()\n",
        "train_labels_s = train_features_s.pop('CLASS_2')\n",
        "train_labels_s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1306    0.0\n",
              "1226    1.0\n",
              "1310    1.0\n",
              "4374    3.0\n",
              "4484    3.0\n",
              "       ... \n",
              "2885    0.0\n",
              "2465    0.0\n",
              "2616    0.0\n",
              "4651    3.0\n",
              "82      3.0\n",
              "Name: CLASS_2, Length: 5714, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJHEg_-x3Duy",
        "outputId": "87b408fc-1fad-4827-c89d-3d923a87965d"
      },
      "source": [
        "#test data normalization\n",
        "test_features_s = test_s.copy()\n",
        "test_labels_s = test_features_s.pop('CLASS_2')\n",
        "test_labels_s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1       3.0\n",
              "5       2.0\n",
              "8       2.0\n",
              "15      2.0\n",
              "53      2.0\n",
              "       ... \n",
              "5973    4.0\n",
              "5997    4.0\n",
              "6002    4.0\n",
              "6003    4.0\n",
              "6010    4.0\n",
              "Name: CLASS_2, Length: 301, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmG-rZHt3Dw3",
        "outputId": "666ecdcd-03df-47e9-8d5b-95574233dd9c"
      },
      "source": [
        "#Clean x_train_s & x_test_s\n",
        "x_train_clean_s = train_features_s.fillna(0).dropna()\n",
        "x_test_clean_s = test_features_s.fillna(0).dropna()\n",
        "print(x_train_clean_s)\n",
        "print(x_test_clean_s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          AWND      PRCP       TAVG       TMIN       TMAX\n",
            "1306  3.455000  0.006122  52.098103  65.971520  42.487343\n",
            "1226  6.958889  0.002041  49.092358  61.423570  38.694267\n",
            "1310  4.610000  0.110204  46.736507  57.542860  39.349205\n",
            "4374  6.334730  0.001396  77.439497  92.191793  63.935582\n",
            "4484  6.400099  0.000000  76.680829  92.035015  62.439842\n",
            "...        ...       ...        ...        ...        ...\n",
            "2885  6.015553  0.292613  41.100041  49.687433  34.244988\n",
            "2465  4.086738  0.006660  46.890666  59.156582  37.388747\n",
            "2616  7.197605  0.001736  63.344940  77.059835  49.932305\n",
            "4651  6.329692  0.004044   0.000000  59.087208  71.766714\n",
            "82    5.050526  0.000000  72.608284  88.394905  59.449043\n",
            "\n",
            "[5714 rows x 5 columns]\n",
            "          AWND      PRCP       TAVG       TMIN       TMAX\n",
            "1     6.805790  0.076531  76.123030  90.015770  64.507890\n",
            "5     7.605790  0.091837  70.416405  83.968450  58.738170\n",
            "8     7.323684  0.235102  60.300632  70.136080  53.110760\n",
            "15    6.334737  0.004082  72.018930  86.593060  58.242900\n",
            "53    6.204211  0.000204  71.774605  86.387300  58.707935\n",
            "...        ...       ...        ...        ...        ...\n",
            "5973  4.938067  0.008449  76.766895  92.716065  62.964802\n",
            "5997  5.531244  0.000662  80.621352  96.287534  66.345840\n",
            "6002  6.275490  0.001735  76.266116  90.854326  63.036139\n",
            "6003  5.521789  0.001927  82.062619  97.458098  67.933543\n",
            "6010  6.181162  0.000852  80.295436  95.779341  65.792416\n",
            "\n",
            "[301 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TjYfWIc3DzM",
        "outputId": "6dd85969-0fef-4e23-9225-af0fbb37f5ed"
      },
      "source": [
        "#normalize x_train_clean \n",
        "normalizer = tf.keras.layers.Normalization()\n",
        "normalizer.adapt(x_train_clean_s)\n",
        "x_train_norm_s = normalizer(x_train_clean_s)\n",
        "x_train_norm_s.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5714, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5MEuPld3D0w",
        "outputId": "429dd8dd-ec9a-40f5-c426-52d02df362f2"
      },
      "source": [
        "#normalize x_test_clean\n",
        "normalizer = tf.keras.layers.Normalization()\n",
        "normalizer.adapt(x_test_clean_s)\n",
        "x_test_norm_s = normalizer(x_test_clean_s)\n",
        "x_test_norm_s.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([301, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2O19wwN8UGR"
      },
      "source": [
        "#Import CLASS_2es\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "#Model Definition\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(5,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtCSm8ti8UPH"
      },
      "source": [
        "#Configure model training\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36_dfk0s8USO",
        "outputId": "1c0f6711-7e57-41fc-c188-596a860cd58a"
      },
      "source": [
        "#train model\n",
        "from keras import backend as K\n",
        "K.set_value(model.optimizer.learning_rate, 0.0008)\n",
        "history = model.fit(x_train_norm_s, y_train_s, validation_split=0.2, epochs=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 1.1604 - accuracy: 0.4835 - val_loss: 0.8580 - val_accuracy: 0.5818\n",
            "Epoch 2/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.9107 - accuracy: 0.5653 - val_loss: 0.7805 - val_accuracy: 0.6002\n",
            "Epoch 3/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.8493 - accuracy: 0.5972 - val_loss: 0.7592 - val_accuracy: 0.6273\n",
            "Epoch 4/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.8287 - accuracy: 0.6115 - val_loss: 0.7364 - val_accuracy: 0.6325\n",
            "Epoch 5/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.8136 - accuracy: 0.6126 - val_loss: 0.7355 - val_accuracy: 0.6483\n",
            "Epoch 6/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.8020 - accuracy: 0.6193 - val_loss: 0.7393 - val_accuracy: 0.6352\n",
            "Epoch 7/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7810 - accuracy: 0.6274 - val_loss: 0.7139 - val_accuracy: 0.6649\n",
            "Epoch 8/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7867 - accuracy: 0.6357 - val_loss: 0.7442 - val_accuracy: 0.6308\n",
            "Epoch 9/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7664 - accuracy: 0.6425 - val_loss: 0.7201 - val_accuracy: 0.6404\n",
            "Epoch 10/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7591 - accuracy: 0.6425 - val_loss: 0.6985 - val_accuracy: 0.6728\n",
            "Epoch 11/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7526 - accuracy: 0.6432 - val_loss: 0.7111 - val_accuracy: 0.6597\n",
            "Epoch 12/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.6519 - val_loss: 0.6977 - val_accuracy: 0.6640\n",
            "Epoch 13/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7486 - accuracy: 0.6517 - val_loss: 0.7143 - val_accuracy: 0.6474\n",
            "Epoch 14/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.6546 - val_loss: 0.6869 - val_accuracy: 0.6710\n",
            "Epoch 15/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.6567 - val_loss: 0.6917 - val_accuracy: 0.6693\n",
            "Epoch 16/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7316 - accuracy: 0.6574 - val_loss: 0.6862 - val_accuracy: 0.6632\n",
            "Epoch 17/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.6600 - val_loss: 0.6769 - val_accuracy: 0.6667\n",
            "Epoch 18/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.6729 - val_loss: 0.6750 - val_accuracy: 0.6702\n",
            "Epoch 19/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7256 - accuracy: 0.6532 - val_loss: 0.6830 - val_accuracy: 0.6562\n",
            "Epoch 20/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.6642 - val_loss: 0.6781 - val_accuracy: 0.6640\n",
            "Epoch 21/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7212 - accuracy: 0.6653 - val_loss: 0.6762 - val_accuracy: 0.6684\n",
            "Epoch 22/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7100 - accuracy: 0.6683 - val_loss: 0.6668 - val_accuracy: 0.6737\n",
            "Epoch 23/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7033 - accuracy: 0.6762 - val_loss: 0.6707 - val_accuracy: 0.6649\n",
            "Epoch 24/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7170 - accuracy: 0.6692 - val_loss: 0.6824 - val_accuracy: 0.6588\n",
            "Epoch 25/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.6683 - val_loss: 0.6805 - val_accuracy: 0.6535\n",
            "Epoch 26/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.6747 - val_loss: 0.6548 - val_accuracy: 0.6772\n",
            "Epoch 27/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.6701 - val_loss: 0.6492 - val_accuracy: 0.6903\n",
            "Epoch 28/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.6802 - val_loss: 0.6434 - val_accuracy: 0.7043\n",
            "Epoch 29/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.6799 - val_loss: 0.6638 - val_accuracy: 0.6614\n",
            "Epoch 30/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.6830 - val_loss: 0.6509 - val_accuracy: 0.6824\n",
            "Epoch 31/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.6633 - val_loss: 0.6708 - val_accuracy: 0.6605\n",
            "Epoch 32/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.6782 - val_loss: 0.6638 - val_accuracy: 0.6798\n",
            "Epoch 33/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.6832 - val_loss: 0.6654 - val_accuracy: 0.6702\n",
            "Epoch 34/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.6887 - val_loss: 0.6410 - val_accuracy: 0.6842\n",
            "Epoch 35/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.6869 - val_loss: 0.6393 - val_accuracy: 0.6868\n",
            "Epoch 36/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.6837 - val_loss: 0.6283 - val_accuracy: 0.6990\n",
            "Epoch 37/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6876 - val_loss: 0.6569 - val_accuracy: 0.6684\n",
            "Epoch 38/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.6863 - val_loss: 0.6542 - val_accuracy: 0.6763\n",
            "Epoch 39/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6819 - val_loss: 0.6489 - val_accuracy: 0.6798\n",
            "Epoch 40/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6858 - val_loss: 0.6293 - val_accuracy: 0.6929\n",
            "Epoch 41/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.7038 - val_loss: 0.6357 - val_accuracy: 0.6920\n",
            "Epoch 42/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6889 - val_loss: 0.6371 - val_accuracy: 0.6920\n",
            "Epoch 43/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.6922 - val_loss: 0.6225 - val_accuracy: 0.7008\n",
            "Epoch 44/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6990 - val_loss: 0.6366 - val_accuracy: 0.6885\n",
            "Epoch 45/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.6979 - val_loss: 0.6341 - val_accuracy: 0.6719\n",
            "Epoch 46/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6985 - val_loss: 0.6383 - val_accuracy: 0.6938\n",
            "Epoch 47/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6939 - val_loss: 0.6505 - val_accuracy: 0.6833\n",
            "Epoch 48/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.7018 - val_loss: 0.6226 - val_accuracy: 0.6982\n",
            "Epoch 49/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6961 - val_loss: 0.6236 - val_accuracy: 0.7165\n",
            "Epoch 50/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.6990 - val_loss: 0.6237 - val_accuracy: 0.7069\n",
            "Epoch 51/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7007 - val_loss: 0.6189 - val_accuracy: 0.6973\n",
            "Epoch 52/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.6948 - val_loss: 0.6291 - val_accuracy: 0.6877\n",
            "Epoch 53/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7016 - val_loss: 0.6104 - val_accuracy: 0.6973\n",
            "Epoch 54/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7051 - val_loss: 0.6082 - val_accuracy: 0.7139\n",
            "Epoch 55/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6996 - val_loss: 0.6097 - val_accuracy: 0.6990\n",
            "Epoch 56/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.7079 - val_loss: 0.6035 - val_accuracy: 0.7122\n",
            "Epoch 57/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.7038 - val_loss: 0.6175 - val_accuracy: 0.6982\n",
            "Epoch 58/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.7123 - val_loss: 0.6222 - val_accuracy: 0.6982\n",
            "Epoch 59/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7031 - val_loss: 0.6056 - val_accuracy: 0.7130\n",
            "Epoch 60/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7025 - val_loss: 0.5951 - val_accuracy: 0.7113\n",
            "Epoch 61/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7106 - val_loss: 0.5974 - val_accuracy: 0.7087\n",
            "Epoch 62/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.7154 - val_loss: 0.6080 - val_accuracy: 0.7008\n",
            "Epoch 63/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.7101 - val_loss: 0.6167 - val_accuracy: 0.7017\n",
            "Epoch 64/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.7138 - val_loss: 0.6141 - val_accuracy: 0.7025\n",
            "Epoch 65/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.7125 - val_loss: 0.6128 - val_accuracy: 0.7095\n",
            "Epoch 66/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.7053 - val_loss: 0.5935 - val_accuracy: 0.7165\n",
            "Epoch 67/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.7167 - val_loss: 0.5914 - val_accuracy: 0.7157\n",
            "Epoch 68/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.7156 - val_loss: 0.5911 - val_accuracy: 0.7209\n",
            "Epoch 69/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.7114 - val_loss: 0.5905 - val_accuracy: 0.7157\n",
            "Epoch 70/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.7049 - val_loss: 0.5910 - val_accuracy: 0.7157\n",
            "Epoch 71/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.7147 - val_loss: 0.6173 - val_accuracy: 0.6938\n",
            "Epoch 72/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7007 - val_loss: 0.6001 - val_accuracy: 0.7060\n",
            "Epoch 73/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.7128 - val_loss: 0.6197 - val_accuracy: 0.7209\n",
            "Epoch 74/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.7138 - val_loss: 0.6085 - val_accuracy: 0.7104\n",
            "Epoch 75/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.7082 - val_loss: 0.5992 - val_accuracy: 0.7139\n",
            "Epoch 76/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7219 - val_loss: 0.5906 - val_accuracy: 0.7139\n",
            "Epoch 77/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.7097 - val_loss: 0.6031 - val_accuracy: 0.7148\n",
            "Epoch 78/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7200 - val_loss: 0.5977 - val_accuracy: 0.7244\n",
            "Epoch 79/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.7309 - val_loss: 0.5959 - val_accuracy: 0.7218\n",
            "Epoch 80/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.7119 - val_loss: 0.5919 - val_accuracy: 0.7218\n",
            "Epoch 81/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7226 - val_loss: 0.5989 - val_accuracy: 0.7043\n",
            "Epoch 82/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.7128 - val_loss: 0.5921 - val_accuracy: 0.7122\n",
            "Epoch 83/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7217 - val_loss: 0.5861 - val_accuracy: 0.7078\n",
            "Epoch 84/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.7233 - val_loss: 0.5787 - val_accuracy: 0.7270\n",
            "Epoch 85/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7206 - val_loss: 0.5837 - val_accuracy: 0.7323\n",
            "Epoch 86/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.7241 - val_loss: 0.5770 - val_accuracy: 0.7244\n",
            "Epoch 87/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7147 - val_loss: 0.5769 - val_accuracy: 0.7200\n",
            "Epoch 88/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7198 - val_loss: 0.5734 - val_accuracy: 0.7253\n",
            "Epoch 89/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7296 - val_loss: 0.5845 - val_accuracy: 0.7148\n",
            "Epoch 90/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.7296 - val_loss: 0.5761 - val_accuracy: 0.7227\n",
            "Epoch 91/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.7173 - val_loss: 0.5795 - val_accuracy: 0.7253\n",
            "Epoch 92/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7287 - val_loss: 0.5618 - val_accuracy: 0.7332\n",
            "Epoch 93/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7173 - val_loss: 0.5803 - val_accuracy: 0.7235\n",
            "Epoch 94/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7226 - val_loss: 0.5849 - val_accuracy: 0.7165\n",
            "Epoch 95/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.7191 - val_loss: 0.5642 - val_accuracy: 0.7314\n",
            "Epoch 96/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.7226 - val_loss: 0.5750 - val_accuracy: 0.7332\n",
            "Epoch 97/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7289 - val_loss: 0.5677 - val_accuracy: 0.7349\n",
            "Epoch 98/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7373 - val_loss: 0.5744 - val_accuracy: 0.7235\n",
            "Epoch 99/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7281 - val_loss: 0.5998 - val_accuracy: 0.7305\n",
            "Epoch 100/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7200 - val_loss: 0.5674 - val_accuracy: 0.7314\n",
            "Epoch 101/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7340 - val_loss: 0.5778 - val_accuracy: 0.7262\n",
            "Epoch 102/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7327 - val_loss: 0.5613 - val_accuracy: 0.7218\n",
            "Epoch 103/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7285 - val_loss: 0.5864 - val_accuracy: 0.7262\n",
            "Epoch 104/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7296 - val_loss: 0.5799 - val_accuracy: 0.7235\n",
            "Epoch 105/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7292 - val_loss: 0.5734 - val_accuracy: 0.7384\n",
            "Epoch 106/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7313 - val_loss: 0.5737 - val_accuracy: 0.7384\n",
            "Epoch 107/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7265 - val_loss: 0.5655 - val_accuracy: 0.7244\n",
            "Epoch 108/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7329 - val_loss: 0.5744 - val_accuracy: 0.7297\n",
            "Epoch 109/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7309 - val_loss: 0.5738 - val_accuracy: 0.7244\n",
            "Epoch 110/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7305 - val_loss: 0.5725 - val_accuracy: 0.7384\n",
            "Epoch 111/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7276 - val_loss: 0.5743 - val_accuracy: 0.7305\n",
            "Epoch 112/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7322 - val_loss: 0.5766 - val_accuracy: 0.7314\n",
            "Epoch 113/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7381 - val_loss: 0.5816 - val_accuracy: 0.7332\n",
            "Epoch 114/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7320 - val_loss: 0.5976 - val_accuracy: 0.7165\n",
            "Epoch 115/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7362 - val_loss: 0.6084 - val_accuracy: 0.7244\n",
            "Epoch 116/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7346 - val_loss: 0.5452 - val_accuracy: 0.7384\n",
            "Epoch 117/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7454 - val_loss: 0.5641 - val_accuracy: 0.7437\n",
            "Epoch 118/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7456 - val_loss: 0.5576 - val_accuracy: 0.7375\n",
            "Epoch 119/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7364 - val_loss: 0.5620 - val_accuracy: 0.7349\n",
            "Epoch 120/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7425 - val_loss: 0.5655 - val_accuracy: 0.7384\n",
            "Epoch 121/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7351 - val_loss: 0.5633 - val_accuracy: 0.7428\n",
            "Epoch 122/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7416 - val_loss: 0.5519 - val_accuracy: 0.7332\n",
            "Epoch 123/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7375 - val_loss: 0.5657 - val_accuracy: 0.7332\n",
            "Epoch 124/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7412 - val_loss: 0.5653 - val_accuracy: 0.7244\n",
            "Epoch 125/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7342 - val_loss: 0.5570 - val_accuracy: 0.7375\n",
            "Epoch 126/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7484 - val_loss: 0.5955 - val_accuracy: 0.7130\n",
            "Epoch 127/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7392 - val_loss: 0.5781 - val_accuracy: 0.7279\n",
            "Epoch 128/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7445 - val_loss: 0.5764 - val_accuracy: 0.7262\n",
            "Epoch 129/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7412 - val_loss: 0.5604 - val_accuracy: 0.7332\n",
            "Epoch 130/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7429 - val_loss: 0.5757 - val_accuracy: 0.7244\n",
            "Epoch 131/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7491 - val_loss: 0.5641 - val_accuracy: 0.7279\n",
            "Epoch 132/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7414 - val_loss: 0.5541 - val_accuracy: 0.7384\n",
            "Epoch 133/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7539 - val_loss: 0.5675 - val_accuracy: 0.7323\n",
            "Epoch 134/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7359 - val_loss: 0.5645 - val_accuracy: 0.7393\n",
            "Epoch 135/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7524 - val_loss: 0.5592 - val_accuracy: 0.7393\n",
            "Epoch 136/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7454 - val_loss: 0.5890 - val_accuracy: 0.7340\n",
            "Epoch 137/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7471 - val_loss: 0.5700 - val_accuracy: 0.7340\n",
            "Epoch 138/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7565 - val_loss: 0.5822 - val_accuracy: 0.7384\n",
            "Epoch 139/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7532 - val_loss: 0.5774 - val_accuracy: 0.7218\n",
            "Epoch 140/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7486 - val_loss: 0.5600 - val_accuracy: 0.7419\n",
            "Epoch 141/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7440 - val_loss: 0.5604 - val_accuracy: 0.7489\n",
            "Epoch 142/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7532 - val_loss: 0.5622 - val_accuracy: 0.7437\n",
            "Epoch 143/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7482 - val_loss: 0.5997 - val_accuracy: 0.7227\n",
            "Epoch 144/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7508 - val_loss: 0.5701 - val_accuracy: 0.7305\n",
            "Epoch 145/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7491 - val_loss: 0.5544 - val_accuracy: 0.7454\n",
            "Epoch 146/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7532 - val_loss: 0.5656 - val_accuracy: 0.7437\n",
            "Epoch 147/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.7502 - val_loss: 0.5630 - val_accuracy: 0.7393\n",
            "Epoch 148/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7624 - val_loss: 0.5749 - val_accuracy: 0.7332\n",
            "Epoch 149/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7565 - val_loss: 0.5644 - val_accuracy: 0.7332\n",
            "Epoch 150/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7495 - val_loss: 0.5483 - val_accuracy: 0.7384\n",
            "Epoch 151/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7548 - val_loss: 0.5718 - val_accuracy: 0.7305\n",
            "Epoch 152/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7502 - val_loss: 0.5536 - val_accuracy: 0.7445\n",
            "Epoch 153/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7604 - val_loss: 0.5484 - val_accuracy: 0.7454\n",
            "Epoch 154/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7526 - val_loss: 0.5583 - val_accuracy: 0.7445\n",
            "Epoch 155/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7486 - val_loss: 0.5342 - val_accuracy: 0.7515\n",
            "Epoch 156/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7618 - val_loss: 0.5562 - val_accuracy: 0.7428\n",
            "Epoch 157/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7475 - val_loss: 0.5718 - val_accuracy: 0.7314\n",
            "Epoch 158/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7504 - val_loss: 0.5579 - val_accuracy: 0.7384\n",
            "Epoch 159/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7532 - val_loss: 0.5529 - val_accuracy: 0.7393\n",
            "Epoch 160/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7561 - val_loss: 0.5552 - val_accuracy: 0.7419\n",
            "Epoch 161/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7607 - val_loss: 0.5565 - val_accuracy: 0.7384\n",
            "Epoch 162/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7491 - val_loss: 0.5646 - val_accuracy: 0.7340\n",
            "Epoch 163/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7532 - val_loss: 0.5731 - val_accuracy: 0.7445\n",
            "Epoch 164/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7591 - val_loss: 0.5652 - val_accuracy: 0.7367\n",
            "Epoch 165/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7607 - val_loss: 0.5419 - val_accuracy: 0.7472\n",
            "Epoch 166/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7604 - val_loss: 0.5508 - val_accuracy: 0.7437\n",
            "Epoch 167/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7569 - val_loss: 0.5397 - val_accuracy: 0.7524\n",
            "Epoch 168/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7672 - val_loss: 0.5506 - val_accuracy: 0.7410\n",
            "Epoch 169/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7541 - val_loss: 0.5792 - val_accuracy: 0.7419\n",
            "Epoch 170/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7574 - val_loss: 0.5584 - val_accuracy: 0.7253\n",
            "Epoch 171/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7613 - val_loss: 0.5579 - val_accuracy: 0.7445\n",
            "Epoch 172/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7569 - val_loss: 0.5713 - val_accuracy: 0.7262\n",
            "Epoch 173/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7521 - val_loss: 0.5644 - val_accuracy: 0.7358\n",
            "Epoch 174/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7519 - val_loss: 0.5255 - val_accuracy: 0.7463\n",
            "Epoch 175/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7589 - val_loss: 0.5387 - val_accuracy: 0.7498\n",
            "Epoch 176/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7556 - val_loss: 0.5415 - val_accuracy: 0.7375\n",
            "Epoch 177/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7666 - val_loss: 0.5482 - val_accuracy: 0.7489\n",
            "Epoch 178/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7572 - val_loss: 0.5471 - val_accuracy: 0.7472\n",
            "Epoch 179/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7631 - val_loss: 0.5706 - val_accuracy: 0.7323\n",
            "Epoch 180/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7600 - val_loss: 0.5461 - val_accuracy: 0.7454\n",
            "Epoch 181/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7609 - val_loss: 0.5512 - val_accuracy: 0.7428\n",
            "Epoch 182/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7598 - val_loss: 0.5552 - val_accuracy: 0.7349\n",
            "Epoch 183/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7561 - val_loss: 0.5469 - val_accuracy: 0.7515\n",
            "Epoch 184/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7554 - val_loss: 0.5542 - val_accuracy: 0.7393\n",
            "Epoch 185/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7679 - val_loss: 0.5384 - val_accuracy: 0.7437\n",
            "Epoch 186/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7602 - val_loss: 0.5467 - val_accuracy: 0.7550\n",
            "Epoch 187/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7631 - val_loss: 0.5519 - val_accuracy: 0.7515\n",
            "Epoch 188/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7609 - val_loss: 0.5341 - val_accuracy: 0.7585\n",
            "Epoch 189/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7699 - val_loss: 0.5340 - val_accuracy: 0.7612\n",
            "Epoch 190/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7696 - val_loss: 0.5559 - val_accuracy: 0.7498\n",
            "Epoch 191/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7688 - val_loss: 0.5278 - val_accuracy: 0.7585\n",
            "Epoch 192/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7670 - val_loss: 0.5191 - val_accuracy: 0.7725\n",
            "Epoch 193/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7661 - val_loss: 0.5545 - val_accuracy: 0.7445\n",
            "Epoch 194/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.5120 - accuracy: 0.7664 - val_loss: 0.5327 - val_accuracy: 0.7524\n",
            "Epoch 195/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7709 - val_loss: 0.5377 - val_accuracy: 0.7542\n",
            "Epoch 196/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7681 - val_loss: 0.5471 - val_accuracy: 0.7542\n",
            "Epoch 197/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7679 - val_loss: 0.5290 - val_accuracy: 0.7550\n",
            "Epoch 198/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7655 - val_loss: 0.5314 - val_accuracy: 0.7577\n",
            "Epoch 199/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7701 - val_loss: 0.5318 - val_accuracy: 0.7550\n",
            "Epoch 200/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7712 - val_loss: 0.5472 - val_accuracy: 0.7542\n",
            "Epoch 201/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7664 - val_loss: 0.5610 - val_accuracy: 0.7480\n",
            "Epoch 202/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7618 - val_loss: 0.5561 - val_accuracy: 0.7463\n",
            "Epoch 203/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7716 - val_loss: 0.5535 - val_accuracy: 0.7498\n",
            "Epoch 204/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7705 - val_loss: 0.5524 - val_accuracy: 0.7480\n",
            "Epoch 205/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7642 - val_loss: 0.5898 - val_accuracy: 0.7515\n",
            "Epoch 206/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7738 - val_loss: 0.5568 - val_accuracy: 0.7515\n",
            "Epoch 207/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7642 - val_loss: 0.5509 - val_accuracy: 0.7629\n",
            "Epoch 208/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7677 - val_loss: 0.5882 - val_accuracy: 0.7262\n",
            "Epoch 209/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7736 - val_loss: 0.5415 - val_accuracy: 0.7550\n",
            "Epoch 210/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7734 - val_loss: 0.5509 - val_accuracy: 0.7550\n",
            "Epoch 211/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7653 - val_loss: 0.5499 - val_accuracy: 0.7524\n",
            "Epoch 212/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7604 - val_loss: 0.5538 - val_accuracy: 0.7402\n",
            "Epoch 213/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7705 - val_loss: 0.5686 - val_accuracy: 0.7410\n",
            "Epoch 214/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7679 - val_loss: 0.5493 - val_accuracy: 0.7550\n",
            "Epoch 215/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7760 - val_loss: 0.5374 - val_accuracy: 0.7515\n",
            "Epoch 216/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7650 - val_loss: 0.5411 - val_accuracy: 0.7515\n",
            "Epoch 217/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7664 - val_loss: 0.5668 - val_accuracy: 0.7489\n",
            "Epoch 218/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7703 - val_loss: 0.5616 - val_accuracy: 0.7402\n",
            "Epoch 219/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7749 - val_loss: 0.5351 - val_accuracy: 0.7612\n",
            "Epoch 220/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7653 - val_loss: 0.5402 - val_accuracy: 0.7524\n",
            "Epoch 221/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7727 - val_loss: 0.5471 - val_accuracy: 0.7568\n",
            "Epoch 222/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7725 - val_loss: 0.5472 - val_accuracy: 0.7507\n",
            "Epoch 223/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7639 - val_loss: 0.5528 - val_accuracy: 0.7498\n",
            "Epoch 224/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7736 - val_loss: 0.5489 - val_accuracy: 0.7367\n",
            "Epoch 225/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7753 - val_loss: 0.5468 - val_accuracy: 0.7533\n",
            "Epoch 226/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7764 - val_loss: 0.5817 - val_accuracy: 0.7445\n",
            "Epoch 227/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7779 - val_loss: 0.5687 - val_accuracy: 0.7559\n",
            "Epoch 228/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7734 - val_loss: 0.5373 - val_accuracy: 0.7603\n",
            "Epoch 229/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7812 - val_loss: 0.5629 - val_accuracy: 0.7542\n",
            "Epoch 230/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7699 - val_loss: 0.5715 - val_accuracy: 0.7419\n",
            "Epoch 231/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7744 - val_loss: 0.5401 - val_accuracy: 0.7638\n",
            "Epoch 232/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7692 - val_loss: 0.5472 - val_accuracy: 0.7629\n",
            "Epoch 233/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7696 - val_loss: 0.5468 - val_accuracy: 0.7515\n",
            "Epoch 234/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7769 - val_loss: 0.5399 - val_accuracy: 0.7734\n",
            "Epoch 235/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7747 - val_loss: 0.5540 - val_accuracy: 0.7577\n",
            "Epoch 236/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7740 - val_loss: 0.5376 - val_accuracy: 0.7620\n",
            "Epoch 237/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7788 - val_loss: 0.5433 - val_accuracy: 0.7559\n",
            "Epoch 238/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7845 - val_loss: 0.5574 - val_accuracy: 0.7472\n",
            "Epoch 239/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7701 - val_loss: 0.5622 - val_accuracy: 0.7515\n",
            "Epoch 240/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7777 - val_loss: 0.5692 - val_accuracy: 0.7603\n",
            "Epoch 241/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7845 - val_loss: 0.5456 - val_accuracy: 0.7594\n",
            "Epoch 242/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7808 - val_loss: 0.5546 - val_accuracy: 0.7594\n",
            "Epoch 243/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7738 - val_loss: 0.5469 - val_accuracy: 0.7480\n",
            "Epoch 244/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7705 - val_loss: 0.5439 - val_accuracy: 0.7463\n",
            "Epoch 245/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7823 - val_loss: 0.5368 - val_accuracy: 0.7585\n",
            "Epoch 246/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7806 - val_loss: 0.5755 - val_accuracy: 0.7445\n",
            "Epoch 247/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7825 - val_loss: 0.5720 - val_accuracy: 0.7384\n",
            "Epoch 248/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7808 - val_loss: 0.5439 - val_accuracy: 0.7594\n",
            "Epoch 249/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7747 - val_loss: 0.5596 - val_accuracy: 0.7533\n",
            "Epoch 250/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7788 - val_loss: 0.5676 - val_accuracy: 0.7489\n",
            "Epoch 251/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7856 - val_loss: 0.5420 - val_accuracy: 0.7594\n",
            "Epoch 252/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7784 - val_loss: 0.5469 - val_accuracy: 0.7507\n",
            "Epoch 253/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7716 - val_loss: 0.5338 - val_accuracy: 0.7690\n",
            "Epoch 254/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7832 - val_loss: 0.5510 - val_accuracy: 0.7533\n",
            "Epoch 255/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7863 - val_loss: 0.5379 - val_accuracy: 0.7524\n",
            "Epoch 256/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7882 - val_loss: 0.5343 - val_accuracy: 0.7655\n",
            "Epoch 257/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7742 - val_loss: 0.5701 - val_accuracy: 0.7559\n",
            "Epoch 258/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7821 - val_loss: 0.5816 - val_accuracy: 0.7533\n",
            "Epoch 259/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7749 - val_loss: 0.5651 - val_accuracy: 0.7480\n",
            "Epoch 260/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7869 - val_loss: 0.5424 - val_accuracy: 0.7664\n",
            "Epoch 261/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7882 - val_loss: 0.5654 - val_accuracy: 0.7594\n",
            "Epoch 262/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7760 - val_loss: 0.5615 - val_accuracy: 0.7515\n",
            "Epoch 263/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7823 - val_loss: 0.5616 - val_accuracy: 0.7533\n",
            "Epoch 264/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7849 - val_loss: 0.5211 - val_accuracy: 0.7647\n",
            "Epoch 265/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7723 - val_loss: 0.5693 - val_accuracy: 0.7524\n",
            "Epoch 266/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7801 - val_loss: 0.5574 - val_accuracy: 0.7603\n",
            "Epoch 267/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7891 - val_loss: 0.5709 - val_accuracy: 0.7594\n",
            "Epoch 268/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7834 - val_loss: 0.5848 - val_accuracy: 0.7507\n",
            "Epoch 269/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7736 - val_loss: 0.5581 - val_accuracy: 0.7629\n",
            "Epoch 270/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7834 - val_loss: 0.5722 - val_accuracy: 0.7585\n",
            "Epoch 271/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7874 - val_loss: 0.5388 - val_accuracy: 0.7655\n",
            "Epoch 272/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7810 - val_loss: 0.5706 - val_accuracy: 0.7638\n",
            "Epoch 273/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7819 - val_loss: 0.5516 - val_accuracy: 0.7550\n",
            "Epoch 274/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7909 - val_loss: 0.5581 - val_accuracy: 0.7594\n",
            "Epoch 275/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4809 - accuracy: 0.7819 - val_loss: 0.5371 - val_accuracy: 0.7717\n",
            "Epoch 276/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4602 - accuracy: 0.7867 - val_loss: 0.5397 - val_accuracy: 0.7638\n",
            "Epoch 277/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7849 - val_loss: 0.5552 - val_accuracy: 0.7725\n",
            "Epoch 278/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4806 - accuracy: 0.7854 - val_loss: 0.5801 - val_accuracy: 0.7533\n",
            "Epoch 279/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7773 - val_loss: 0.5564 - val_accuracy: 0.7550\n",
            "Epoch 280/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7904 - val_loss: 0.5619 - val_accuracy: 0.7515\n",
            "Epoch 281/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7775 - val_loss: 0.5545 - val_accuracy: 0.7612\n",
            "Epoch 282/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7871 - val_loss: 0.5619 - val_accuracy: 0.7708\n",
            "Epoch 283/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4646 - accuracy: 0.7895 - val_loss: 0.5544 - val_accuracy: 0.7612\n",
            "Epoch 284/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7817 - val_loss: 0.5729 - val_accuracy: 0.7594\n",
            "Epoch 285/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.5751 - val_accuracy: 0.7533\n",
            "Epoch 286/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7860 - val_loss: 0.5693 - val_accuracy: 0.7620\n",
            "Epoch 287/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7891 - val_loss: 0.5478 - val_accuracy: 0.7778\n",
            "Epoch 288/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7900 - val_loss: 0.5511 - val_accuracy: 0.7647\n",
            "Epoch 289/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7845 - val_loss: 0.5589 - val_accuracy: 0.7550\n",
            "Epoch 290/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7814 - val_loss: 0.5573 - val_accuracy: 0.7647\n",
            "Epoch 291/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7869 - val_loss: 0.5684 - val_accuracy: 0.7594\n",
            "Epoch 292/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7887 - val_loss: 0.5746 - val_accuracy: 0.7638\n",
            "Epoch 293/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7828 - val_loss: 0.5772 - val_accuracy: 0.7612\n",
            "Epoch 294/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7926 - val_loss: 0.5874 - val_accuracy: 0.7629\n",
            "Epoch 295/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7867 - val_loss: 0.5595 - val_accuracy: 0.7717\n",
            "Epoch 296/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7823 - val_loss: 0.5709 - val_accuracy: 0.7603\n",
            "Epoch 297/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7946 - val_loss: 0.5790 - val_accuracy: 0.7577\n",
            "Epoch 298/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7895 - val_loss: 0.5611 - val_accuracy: 0.7752\n",
            "Epoch 299/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7856 - val_loss: 0.5762 - val_accuracy: 0.7647\n",
            "Epoch 300/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7898 - val_loss: 0.5688 - val_accuracy: 0.7690\n",
            "Epoch 301/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7808 - val_loss: 0.5940 - val_accuracy: 0.7489\n",
            "Epoch 302/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7922 - val_loss: 0.5583 - val_accuracy: 0.7620\n",
            "Epoch 303/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7906 - val_loss: 0.5687 - val_accuracy: 0.7603\n",
            "Epoch 304/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.7924 - val_loss: 0.5819 - val_accuracy: 0.7647\n",
            "Epoch 305/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7856 - val_loss: 0.5665 - val_accuracy: 0.7682\n",
            "Epoch 306/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7930 - val_loss: 0.5703 - val_accuracy: 0.7638\n",
            "Epoch 307/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5892 - val_accuracy: 0.7559\n",
            "Epoch 308/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7869 - val_loss: 0.5851 - val_accuracy: 0.7603\n",
            "Epoch 309/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7887 - val_loss: 0.5625 - val_accuracy: 0.7647\n",
            "Epoch 310/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7909 - val_loss: 0.5507 - val_accuracy: 0.7690\n",
            "Epoch 311/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.5556 - val_accuracy: 0.7699\n",
            "Epoch 312/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7919 - val_loss: 0.5696 - val_accuracy: 0.7699\n",
            "Epoch 313/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7961 - val_loss: 0.5775 - val_accuracy: 0.7612\n",
            "Epoch 314/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7804 - val_loss: 0.5452 - val_accuracy: 0.7760\n",
            "Epoch 315/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7944 - val_loss: 0.5850 - val_accuracy: 0.7489\n",
            "Epoch 316/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7880 - val_loss: 0.5611 - val_accuracy: 0.7673\n",
            "Epoch 317/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7880 - val_loss: 0.5807 - val_accuracy: 0.7585\n",
            "Epoch 318/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7915 - val_loss: 0.5614 - val_accuracy: 0.7577\n",
            "Epoch 319/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7965 - val_loss: 0.5729 - val_accuracy: 0.7673\n",
            "Epoch 320/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7930 - val_loss: 0.5797 - val_accuracy: 0.7603\n",
            "Epoch 321/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7976 - val_loss: 0.5841 - val_accuracy: 0.7769\n",
            "Epoch 322/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7871 - val_loss: 0.5550 - val_accuracy: 0.7725\n",
            "Epoch 323/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7974 - val_loss: 0.5723 - val_accuracy: 0.7638\n",
            "Epoch 324/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7941 - val_loss: 0.5803 - val_accuracy: 0.7629\n",
            "Epoch 325/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7889 - val_loss: 0.5614 - val_accuracy: 0.7734\n",
            "Epoch 326/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7845 - val_loss: 0.5666 - val_accuracy: 0.7708\n",
            "Epoch 327/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4572 - accuracy: 0.7902 - val_loss: 0.5483 - val_accuracy: 0.7629\n",
            "Epoch 328/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7996 - val_loss: 0.5491 - val_accuracy: 0.7760\n",
            "Epoch 329/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7930 - val_loss: 0.5879 - val_accuracy: 0.7620\n",
            "Epoch 330/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.8014 - val_loss: 0.5437 - val_accuracy: 0.7725\n",
            "Epoch 331/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4571 - accuracy: 0.7928 - val_loss: 0.5570 - val_accuracy: 0.7690\n",
            "Epoch 332/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7963 - val_loss: 0.5762 - val_accuracy: 0.7533\n",
            "Epoch 333/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7952 - val_loss: 0.5639 - val_accuracy: 0.7760\n",
            "Epoch 334/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7972 - val_loss: 0.5643 - val_accuracy: 0.7725\n",
            "Epoch 335/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8000 - val_loss: 0.5669 - val_accuracy: 0.7717\n",
            "Epoch 336/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7919 - val_loss: 0.5691 - val_accuracy: 0.7769\n",
            "Epoch 337/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7895 - val_loss: 0.5893 - val_accuracy: 0.7603\n",
            "Epoch 338/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7961 - val_loss: 0.5984 - val_accuracy: 0.7568\n",
            "Epoch 339/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7915 - val_loss: 0.5536 - val_accuracy: 0.7717\n",
            "Epoch 340/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7981 - val_loss: 0.5399 - val_accuracy: 0.7743\n",
            "Epoch 341/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7963 - val_loss: 0.5564 - val_accuracy: 0.7769\n",
            "Epoch 342/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4406 - accuracy: 0.7981 - val_loss: 0.5577 - val_accuracy: 0.7699\n",
            "Epoch 343/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7935 - val_loss: 0.5577 - val_accuracy: 0.7585\n",
            "Epoch 344/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4526 - accuracy: 0.7985 - val_loss: 0.5581 - val_accuracy: 0.7743\n",
            "Epoch 345/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7957 - val_loss: 0.5439 - val_accuracy: 0.7682\n",
            "Epoch 346/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7933 - val_loss: 0.5383 - val_accuracy: 0.7778\n",
            "Epoch 347/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7961 - val_loss: 0.5452 - val_accuracy: 0.7822\n",
            "Epoch 348/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.7957 - val_loss: 0.5722 - val_accuracy: 0.7664\n",
            "Epoch 349/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7867 - val_loss: 0.5864 - val_accuracy: 0.7585\n",
            "Epoch 350/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7961 - val_loss: 0.5658 - val_accuracy: 0.7559\n",
            "Epoch 351/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7902 - val_loss: 0.5566 - val_accuracy: 0.7620\n",
            "Epoch 352/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7996 - val_loss: 0.5649 - val_accuracy: 0.7647\n",
            "Epoch 353/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7992 - val_loss: 0.5559 - val_accuracy: 0.7647\n",
            "Epoch 354/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8027 - val_loss: 0.5562 - val_accuracy: 0.7752\n",
            "Epoch 355/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7930 - val_loss: 0.5581 - val_accuracy: 0.7594\n",
            "Epoch 356/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4327 - accuracy: 0.8003 - val_loss: 0.5470 - val_accuracy: 0.7743\n",
            "Epoch 357/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4511 - accuracy: 0.8018 - val_loss: 0.5543 - val_accuracy: 0.7760\n",
            "Epoch 358/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7983 - val_loss: 0.5602 - val_accuracy: 0.7822\n",
            "Epoch 359/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7987 - val_loss: 0.5422 - val_accuracy: 0.7787\n",
            "Epoch 360/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8031 - val_loss: 0.5705 - val_accuracy: 0.7655\n",
            "Epoch 361/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7970 - val_loss: 0.5356 - val_accuracy: 0.7839\n",
            "Epoch 362/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8040 - val_loss: 0.5572 - val_accuracy: 0.7690\n",
            "Epoch 363/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7926 - val_loss: 0.5609 - val_accuracy: 0.7699\n",
            "Epoch 364/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7935 - val_loss: 0.5729 - val_accuracy: 0.7612\n",
            "Epoch 365/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4514 - accuracy: 0.7928 - val_loss: 0.5640 - val_accuracy: 0.7690\n",
            "Epoch 366/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7974 - val_loss: 0.5438 - val_accuracy: 0.7734\n",
            "Epoch 367/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4365 - accuracy: 0.7998 - val_loss: 0.5741 - val_accuracy: 0.7699\n",
            "Epoch 368/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7987 - val_loss: 0.5564 - val_accuracy: 0.7699\n",
            "Epoch 369/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8044 - val_loss: 0.5454 - val_accuracy: 0.7699\n",
            "Epoch 370/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7963 - val_loss: 0.5347 - val_accuracy: 0.7778\n",
            "Epoch 371/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.8007 - val_loss: 0.5315 - val_accuracy: 0.7822\n",
            "Epoch 372/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8005 - val_loss: 0.5432 - val_accuracy: 0.7699\n",
            "Epoch 373/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7963 - val_loss: 0.5478 - val_accuracy: 0.7725\n",
            "Epoch 374/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8009 - val_loss: 0.5369 - val_accuracy: 0.7673\n",
            "Epoch 375/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4409 - accuracy: 0.8000 - val_loss: 0.5627 - val_accuracy: 0.7778\n",
            "Epoch 376/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4545 - accuracy: 0.7926 - val_loss: 0.5631 - val_accuracy: 0.7664\n",
            "Epoch 377/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8066 - val_loss: 0.5428 - val_accuracy: 0.7664\n",
            "Epoch 378/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8005 - val_loss: 0.5524 - val_accuracy: 0.7647\n",
            "Epoch 379/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8051 - val_loss: 0.5484 - val_accuracy: 0.7743\n",
            "Epoch 380/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4177 - accuracy: 0.8095 - val_loss: 0.5500 - val_accuracy: 0.7900\n",
            "Epoch 381/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4423 - accuracy: 0.7996 - val_loss: 0.5253 - val_accuracy: 0.7769\n",
            "Epoch 382/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.8029 - val_loss: 0.5369 - val_accuracy: 0.7752\n",
            "Epoch 383/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7957 - val_loss: 0.5397 - val_accuracy: 0.7620\n",
            "Epoch 384/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4337 - accuracy: 0.8009 - val_loss: 0.5449 - val_accuracy: 0.7839\n",
            "Epoch 385/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4261 - accuracy: 0.8046 - val_loss: 0.5338 - val_accuracy: 0.7813\n",
            "Epoch 386/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4322 - accuracy: 0.7963 - val_loss: 0.5457 - val_accuracy: 0.7682\n",
            "Epoch 387/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4337 - accuracy: 0.7976 - val_loss: 0.5459 - val_accuracy: 0.7690\n",
            "Epoch 388/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4298 - accuracy: 0.8055 - val_loss: 0.5526 - val_accuracy: 0.7795\n",
            "Epoch 389/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7970 - val_loss: 0.5443 - val_accuracy: 0.7743\n",
            "Epoch 390/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.8042 - val_loss: 0.5374 - val_accuracy: 0.7822\n",
            "Epoch 391/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4355 - accuracy: 0.8020 - val_loss: 0.5199 - val_accuracy: 0.7795\n",
            "Epoch 392/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4336 - accuracy: 0.8020 - val_loss: 0.5405 - val_accuracy: 0.7708\n",
            "Epoch 393/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4285 - accuracy: 0.8090 - val_loss: 0.5754 - val_accuracy: 0.7533\n",
            "Epoch 394/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4377 - accuracy: 0.8068 - val_loss: 0.5432 - val_accuracy: 0.7577\n",
            "Epoch 395/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4413 - accuracy: 0.7979 - val_loss: 0.5473 - val_accuracy: 0.7620\n",
            "Epoch 396/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4377 - accuracy: 0.8003 - val_loss: 0.5554 - val_accuracy: 0.7787\n",
            "Epoch 397/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4347 - accuracy: 0.8007 - val_loss: 0.5773 - val_accuracy: 0.7673\n",
            "Epoch 398/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7961 - val_loss: 0.5639 - val_accuracy: 0.7647\n",
            "Epoch 399/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4237 - accuracy: 0.8060 - val_loss: 0.5595 - val_accuracy: 0.7594\n",
            "Epoch 400/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4286 - accuracy: 0.8057 - val_loss: 0.5447 - val_accuracy: 0.7787\n",
            "Epoch 401/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4293 - accuracy: 0.8038 - val_loss: 0.5232 - val_accuracy: 0.7813\n",
            "Epoch 402/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4355 - accuracy: 0.7979 - val_loss: 0.5581 - val_accuracy: 0.7734\n",
            "Epoch 403/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4188 - accuracy: 0.8105 - val_loss: 0.5358 - val_accuracy: 0.7612\n",
            "Epoch 404/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4375 - accuracy: 0.8000 - val_loss: 0.5647 - val_accuracy: 0.7629\n",
            "Epoch 405/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8020 - val_loss: 0.5588 - val_accuracy: 0.7647\n",
            "Epoch 406/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4226 - accuracy: 0.8132 - val_loss: 0.5584 - val_accuracy: 0.7752\n",
            "Epoch 407/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4308 - accuracy: 0.8007 - val_loss: 0.5554 - val_accuracy: 0.7813\n",
            "Epoch 408/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4185 - accuracy: 0.8125 - val_loss: 0.5632 - val_accuracy: 0.7682\n",
            "Epoch 409/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8068 - val_loss: 0.5341 - val_accuracy: 0.7795\n",
            "Epoch 410/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4250 - accuracy: 0.8092 - val_loss: 0.5445 - val_accuracy: 0.7787\n",
            "Epoch 411/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4223 - accuracy: 0.8081 - val_loss: 0.5481 - val_accuracy: 0.7725\n",
            "Epoch 412/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4364 - accuracy: 0.8051 - val_loss: 0.5929 - val_accuracy: 0.7594\n",
            "Epoch 413/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8011 - val_loss: 0.5699 - val_accuracy: 0.7725\n",
            "Epoch 414/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4397 - accuracy: 0.8011 - val_loss: 0.5411 - val_accuracy: 0.7830\n",
            "Epoch 415/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4252 - accuracy: 0.8064 - val_loss: 0.5507 - val_accuracy: 0.7865\n",
            "Epoch 416/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4365 - accuracy: 0.8029 - val_loss: 0.5509 - val_accuracy: 0.7795\n",
            "Epoch 417/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8068 - val_loss: 0.5752 - val_accuracy: 0.7717\n",
            "Epoch 418/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4440 - accuracy: 0.7965 - val_loss: 0.5642 - val_accuracy: 0.7743\n",
            "Epoch 419/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4338 - accuracy: 0.8025 - val_loss: 0.5625 - val_accuracy: 0.7717\n",
            "Epoch 420/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4303 - accuracy: 0.8040 - val_loss: 0.5504 - val_accuracy: 0.7673\n",
            "Epoch 421/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4290 - accuracy: 0.8011 - val_loss: 0.5549 - val_accuracy: 0.7690\n",
            "Epoch 422/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4278 - accuracy: 0.8035 - val_loss: 0.5330 - val_accuracy: 0.7883\n",
            "Epoch 423/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8123 - val_loss: 0.5540 - val_accuracy: 0.7743\n",
            "Epoch 424/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8066 - val_loss: 0.5639 - val_accuracy: 0.7673\n",
            "Epoch 425/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8049 - val_loss: 0.5743 - val_accuracy: 0.7734\n",
            "Epoch 426/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4193 - accuracy: 0.8077 - val_loss: 0.5759 - val_accuracy: 0.7769\n",
            "Epoch 427/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4263 - accuracy: 0.8049 - val_loss: 0.5463 - val_accuracy: 0.7830\n",
            "Epoch 428/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8116 - val_loss: 0.5562 - val_accuracy: 0.7717\n",
            "Epoch 429/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8018 - val_loss: 0.5426 - val_accuracy: 0.7690\n",
            "Epoch 430/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8049 - val_loss: 0.5409 - val_accuracy: 0.7690\n",
            "Epoch 431/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8075 - val_loss: 0.5807 - val_accuracy: 0.7638\n",
            "Epoch 432/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4196 - accuracy: 0.8060 - val_loss: 0.5643 - val_accuracy: 0.7699\n",
            "Epoch 433/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8103 - val_loss: 0.5725 - val_accuracy: 0.7612\n",
            "Epoch 434/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8110 - val_loss: 0.5533 - val_accuracy: 0.7822\n",
            "Epoch 435/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8090 - val_loss: 0.5582 - val_accuracy: 0.7752\n",
            "Epoch 436/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8005 - val_loss: 0.5529 - val_accuracy: 0.7682\n",
            "Epoch 437/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8110 - val_loss: 0.5747 - val_accuracy: 0.7717\n",
            "Epoch 438/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8040 - val_loss: 0.5640 - val_accuracy: 0.7673\n",
            "Epoch 439/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4203 - accuracy: 0.8143 - val_loss: 0.5577 - val_accuracy: 0.7804\n",
            "Epoch 440/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8064 - val_loss: 0.5540 - val_accuracy: 0.7804\n",
            "Epoch 441/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4190 - accuracy: 0.8095 - val_loss: 0.5667 - val_accuracy: 0.7682\n",
            "Epoch 442/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4147 - accuracy: 0.8123 - val_loss: 0.5683 - val_accuracy: 0.7717\n",
            "Epoch 443/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8219 - val_loss: 0.5949 - val_accuracy: 0.7655\n",
            "Epoch 444/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8206 - val_loss: 0.5686 - val_accuracy: 0.7760\n",
            "Epoch 445/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4218 - accuracy: 0.8143 - val_loss: 0.5560 - val_accuracy: 0.7734\n",
            "Epoch 446/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5623 - val_accuracy: 0.7769\n",
            "Epoch 447/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8138 - val_loss: 0.5866 - val_accuracy: 0.7638\n",
            "Epoch 448/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4232 - accuracy: 0.8062 - val_loss: 0.5779 - val_accuracy: 0.7673\n",
            "Epoch 449/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8011 - val_loss: 0.5468 - val_accuracy: 0.7638\n",
            "Epoch 450/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4199 - accuracy: 0.8119 - val_loss: 0.5229 - val_accuracy: 0.7699\n",
            "Epoch 451/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8154 - val_loss: 0.5272 - val_accuracy: 0.7874\n",
            "Epoch 452/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4238 - accuracy: 0.8097 - val_loss: 0.5496 - val_accuracy: 0.7717\n",
            "Epoch 453/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.5722 - val_accuracy: 0.7927\n",
            "Epoch 454/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8119 - val_loss: 0.5639 - val_accuracy: 0.7647\n",
            "Epoch 455/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4124 - accuracy: 0.8095 - val_loss: 0.5472 - val_accuracy: 0.7752\n",
            "Epoch 456/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4238 - accuracy: 0.8051 - val_loss: 0.5604 - val_accuracy: 0.7769\n",
            "Epoch 457/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8101 - val_loss: 0.5627 - val_accuracy: 0.7883\n",
            "Epoch 458/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4284 - accuracy: 0.8049 - val_loss: 0.5870 - val_accuracy: 0.7787\n",
            "Epoch 459/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4335 - accuracy: 0.8038 - val_loss: 0.5839 - val_accuracy: 0.7743\n",
            "Epoch 460/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8147 - val_loss: 0.5663 - val_accuracy: 0.7953\n",
            "Epoch 461/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4169 - accuracy: 0.8108 - val_loss: 0.5565 - val_accuracy: 0.7752\n",
            "Epoch 462/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4063 - accuracy: 0.8121 - val_loss: 0.5652 - val_accuracy: 0.7839\n",
            "Epoch 463/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4180 - accuracy: 0.8103 - val_loss: 0.5485 - val_accuracy: 0.7953\n",
            "Epoch 464/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8134 - val_loss: 0.6210 - val_accuracy: 0.7585\n",
            "Epoch 465/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4195 - accuracy: 0.8086 - val_loss: 0.5795 - val_accuracy: 0.7760\n",
            "Epoch 466/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.5641 - val_accuracy: 0.7795\n",
            "Epoch 467/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8099 - val_loss: 0.5591 - val_accuracy: 0.7848\n",
            "Epoch 468/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4063 - accuracy: 0.8132 - val_loss: 0.5617 - val_accuracy: 0.7848\n",
            "Epoch 469/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4009 - accuracy: 0.8149 - val_loss: 0.5530 - val_accuracy: 0.7848\n",
            "Epoch 470/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4270 - accuracy: 0.8053 - val_loss: 0.5859 - val_accuracy: 0.7743\n",
            "Epoch 471/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4087 - accuracy: 0.8151 - val_loss: 0.5613 - val_accuracy: 0.7804\n",
            "Epoch 472/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4247 - accuracy: 0.8099 - val_loss: 0.5568 - val_accuracy: 0.7927\n",
            "Epoch 473/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8042 - val_loss: 0.5518 - val_accuracy: 0.7743\n",
            "Epoch 474/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.3989 - accuracy: 0.8241 - val_loss: 0.5640 - val_accuracy: 0.7787\n",
            "Epoch 475/500\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.4029 - accuracy: 0.8178 - val_loss: 0.5673 - val_accuracy: 0.7813\n",
            "Epoch 476/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8156 - val_loss: 0.5663 - val_accuracy: 0.7673\n",
            "Epoch 477/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4181 - accuracy: 0.8081 - val_loss: 0.5457 - val_accuracy: 0.7944\n",
            "Epoch 478/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8110 - val_loss: 0.5670 - val_accuracy: 0.7752\n",
            "Epoch 479/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4111 - accuracy: 0.8130 - val_loss: 0.5709 - val_accuracy: 0.7839\n",
            "Epoch 480/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.8165 - val_loss: 0.5822 - val_accuracy: 0.7725\n",
            "Epoch 481/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8090 - val_loss: 0.5565 - val_accuracy: 0.7848\n",
            "Epoch 482/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4132 - accuracy: 0.8077 - val_loss: 0.5548 - val_accuracy: 0.7760\n",
            "Epoch 483/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8116 - val_loss: 0.5515 - val_accuracy: 0.7787\n",
            "Epoch 484/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4132 - accuracy: 0.8184 - val_loss: 0.5798 - val_accuracy: 0.7813\n",
            "Epoch 485/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4240 - accuracy: 0.8136 - val_loss: 0.5413 - val_accuracy: 0.7787\n",
            "Epoch 486/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4113 - accuracy: 0.8173 - val_loss: 0.5384 - val_accuracy: 0.7769\n",
            "Epoch 487/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8149 - val_loss: 0.5472 - val_accuracy: 0.7830\n",
            "Epoch 488/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8191 - val_loss: 0.5687 - val_accuracy: 0.7743\n",
            "Epoch 489/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4196 - accuracy: 0.8075 - val_loss: 0.5576 - val_accuracy: 0.7813\n",
            "Epoch 490/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8136 - val_loss: 0.5799 - val_accuracy: 0.7725\n",
            "Epoch 491/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8217 - val_loss: 0.5626 - val_accuracy: 0.7848\n",
            "Epoch 492/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8184 - val_loss: 0.5982 - val_accuracy: 0.7743\n",
            "Epoch 493/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4290 - accuracy: 0.8042 - val_loss: 0.5527 - val_accuracy: 0.7769\n",
            "Epoch 494/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8099 - val_loss: 0.5561 - val_accuracy: 0.7822\n",
            "Epoch 495/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8042 - val_loss: 0.5809 - val_accuracy: 0.7778\n",
            "Epoch 496/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4084 - accuracy: 0.8156 - val_loss: 0.5803 - val_accuracy: 0.7664\n",
            "Epoch 497/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4086 - accuracy: 0.8158 - val_loss: 0.5604 - val_accuracy: 0.7830\n",
            "Epoch 498/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8206 - val_loss: 0.5553 - val_accuracy: 0.7778\n",
            "Epoch 499/500\n",
            "143/143 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8116 - val_loss: 0.5607 - val_accuracy: 0.7795\n",
            "Epoch 500/500\n",
            "143/143 [==============================] - 1s 4ms/step - loss: 0.4154 - accuracy: 0.8200 - val_loss: 0.5503 - val_accuracy: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mzz_B518edS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246872e2-6c73-4af1-d39a-ddb51a1ce0b2"
      },
      "source": [
        "#plot training accuracy\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUVd6A3zOTSe8JKRACoVfpRRAFUUQUwYZdce1d1/Kh6yq21XVdu+5asYvY0cUCSpMmIEiTTiAJBEJCCunJnO+Pc+/cO5MJBGEICed9njxz77nn3ntmxPM751eFlBKNRqPRaHxxNPYANBqNRnNsogWERqPRaPyiBYRGo9Fo/KIFhEaj0Wj8ogWERqPRaPyiBYRGo9Fo/KIFhEYDCCHeEUI83sC+mUKI0wI9Jo2msdECQqPRaDR+0QJCo2lGCCGCGnsMmuaDFhCaJoOh2rlXCLFKCFEqhHhLCJEshPhOCFEihJglhIiz9T9HCLFWCFEohJgjhOhqu9ZHCPGbcd8nQKjPu84WQqw07l0ohDihgWM8SwixQghRLITIEkJM9rl+kvG8QuP6RKM9TAjxbyHEdiFEkRDiF6NtuBAi28/vcJpxPFkI8ZkQ4gMhRDEwUQgxUAixyHjHLiHEy0KIYNv93YUQM4UQBUKI3UKIB4QQKUKIMiFEgq1fXyFEnhDC1ZDvrml+aAGhaWqcD5wOdALGAt8BDwAtUP+ebwcQQnQCPgbuNK7NAL4RQgQbk+VXwPtAPPCp8VyMe/sAbwM3AAnAa8B0IURIA8ZXClwJxAJnATcJIcYbz21jjPclY0y9gZXGfc8A/YAhxpjuA9wN/E3GAZ8Z7/wQqAXuAhKBE4GRwM3GGKKAWcD3QEugA/CTlDIXmANMsD33CmCqlLK6gePQNDO0gNA0NV6SUu6WUuYA84ElUsoVUsoK4Eugj9HvIuB/UsqZxgT3DBCGmoAHAy7geSlltZTyM2Cp7R3XA69JKZdIKWullO8ClcZ9B0RKOUdKuVpK6ZZSrkIJqVOMy5cCs6SUHxvvzZdSrhRCOIC/AHdIKXOMdy6UUlY28DdZJKX8ynhnuZRyuZRysZSyRkqZiRJw5hjOBnKllP+WUlZIKUuklEuMa+8ClwMIIZzAJSghqjlO0QJC09TYbTsu93MeaRy3BLabF6SUbiALaGVcy5HemSq3247bAHcbKppCIUQh0Nq474AIIQYJIWYbqpki4EbUSh7jGVv83JaIUnH5u9YQsnzG0EkI8a0QItdQO/2jAWMA+BroJoTIQO3SiqSUv/7JMWmaAVpAaJorO1ETPQBCCIGaHHOAXUAro80k3XacBTwhpYy1/YVLKT9uwHs/AqYDraWUMcB/AfM9WUB7P/fsBSrquVYKhNu+hxOlnrLjm5L5P8B6oKOUMhqlgrOPoZ2/gRu7sGmoXcQV6N3DcY8WEJrmyjTgLCHESMPIejdKTbQQWATUALcLIVxCiPOAgbZ73wBuNHYDQggRYRifoxrw3iigQEpZIYQYiFIrmXwInCaEmCCECBJCJAghehu7m7eBZ4UQLYUQTiHEiYbNYyMQarzfBTwIHMwWEgUUA/uFEF2Am2zXvgVShRB3CiFChBBRQohBtuvvAROBc9AC4rhHCwhNs0RKuQG1En4JtUIfC4yVUlZJKauA81ATYQHKXvGF7d5lwHXAy8A+YLPRtyHcDDwqhCgBHkIJKvO5O4AxKGFVgDJQ9zIu3wOsRtlCCoB/Ag4pZZHxzDdRu59SwMuryQ/3oARTCUrYfWIbQwlKfTQWyAU2ASNs1xegjOO/SSntajfNcYjQBYM0Go0dIcTPwEdSyjcbeyyaxkULCI1G40EIMQCYibKhlDT2eDSNi1YxaTQaAIQQ76JiJO7UwkEDegeh0Wg0mnrQOwiNRqPR+KXZJPZKTEyUbdu2bexhaDQaTZNi+fLle6WUvrE1QDMSEG3btmXZsmWNPQyNRqNpUggh6nVn1iomjUaj0fhFCwiNRqPR+EULCI1Go9H4pdnYIPxRXV1NdnY2FRUVjT2UgBMaGkpaWhoul67totFojgzNWkBkZ2cTFRVF27Zt8U7c2byQUpKfn092djYZGRmNPRyNRtNMaNYqpoqKChISEpq1cAAQQpCQkHBc7JQ0Gs3Ro1kLCKDZCweT4+V7ajSao0ezFxAajUZzLLM9v5Q5G/Y09jD8ogVEgCksLOTVV1895PvGjBlDYWFhAEak0WgOl6oaNzsLy4/Is859dSETpyyl1n3wvHhVNe4j8s6GogVEgKlPQNTU1BzwvhkzZhAbGxuoYWk0msPgzV+2MuSpn1maWXDYzyoorQIgq6DsgP027S6h04Pf8cPaXE/b/E15rMwqpLTywPPJn0ULiAAzadIktmzZQu/evRkwYADDhg3jnHPOoVu3bgCMHz+efv360b17d15//XXPfW3btmXv3r1kZmbStWtXrrvuOrp3786oUaMoLz8yKxeNRvPnWLezGIApC7Yd9rMSIoIB2LRnv1d7Ta2bvfsrkVLy/qJMj2B4ZfZmACqqa7nirV8Z/8oCLvzvosMehz+atZurnUe+Wev5j3qk6NYymofHdj9gn6eeeoo1a9awcuVK5syZw1lnncWaNWs87qhvv/028fHxlJeXM2DAAM4//3wSEhK8nrFp0yY+/vhj3njjDSZMmMDnn3/O5ZdffkS/i0ajaTjmin3j7v0H6XlwUmJCyS+t4o9dxZzeLRkpJUIInpjxB1MWZDKmZwozVlu7hm17SwFYu7PI09Y6Puywx+EPvYM4ygwcONArVuHFF1+kV69eDB48mKysLDZt2lTnnoyMDHr37g1Av379yMzMPFrD1Wg0fthVpFzKM/eWeuwCOYXl/LZjX4Pur6pxs6+0io27rbpMnyzNoqrGTacHv+PJ7/7gyxU5AF7CAaCy2k1NrZsn/veHpy0tLvywvk99HDc7iIOt9I8WERERnuM5c+Ywa9YsFi1aRHh4OMOHD/cbyxASEuI5djqdWsWk0TSQ/ZU1hLucOBxHxg38yRl/MKhdPLnFFUSFBlFSUcO/Z27gmpMyGP6v2VTXSrY9Ocbjdl5YVkXvR2fy7IRejOicRGWNm+ToEE5/bi7b88twOgRhLiegBMwXv2VTXSt5be5WWseHUVhWXWcMVbVuVmQV8tsOy4klLS4wO4jjRkA0FlFRUZSU+K/eWFRURFxcHOHh4axfv57Fixcf5dFpNM2X/ZU19Hj4B4KdDv514QmM692q3r7zNuaxr6yKcb1bUVJRTXlVLUnRoV593G7Ja/O28tq8rQCc2iWJn9fv4bW5W5m5bjfVtcoLac7GPNonRpKeEM72fGV4/uu03z3P+fTGEz3ttW7J/soa+qbH8tuOQl6Zo+wLMWEuCvYr4/WQ9glszy8jx+Y1tSFXzSmpMaHsKqogJiwwKXa0iinAJCQkMHToUHr06MG9997rdW306NHU1NTQtWtXJk2axODBgxtplBpN8+Lz5dn8sEapZqpq3dwxdeUB+1/59q+ePqOfn8/Af/wEKM+hC/+7kPcXb2fIUz973TMoI95zvDWv1HN89ZSlXDXlV1ZlF3qpkEw+WrKjTlv3ljEAZBUoIVBUXk1pVS2PjevOh9cOomtqtNFPff70x24AxvdRQq9TctQBv9+fRe8gjgIfffSR3/aQkBC+++47v9dMO0NiYiJr1qzxtN9zzz1HfHwazbHKJa8vZlT3ZK4e6j/H2GPfrmNk1ySGtE/0ar/709/r9L3pg+U8c2EvIkLqn/bySio9K3W3W/LcrI0szdzH0kxv20JMmItxvVvx5Hfr6zwjJszFtr2lnPPyAk9bZEgQ+w3DtmlbsNMiylIjTxzSlncWZgIwuJ1KFVRYpnYTgzISWLuzmNkb8gC47dQOXD64Da1itZFao9EcJ+QUlrMss4BFW/P5dZv/WIPCsire+mUbl76xBLctyKy+gLPv1uTy8uzNVFTXklVQxtcrc5BSet174pM/eY7v/vR3ZqzO9dgI7IzpmUpiZHCd9jeu7M/3dw6r077876ex9pEzPOendU32uh4ZEuR53jUnWcKwQ1IkAEFOZdPok+4dGxUeHBQw4QB6B6HRaBoZKdUEbc8nNtSmzsktVo4bRWXVBAc5eP6njYzv3Yry6lpPn617S6moruXqd5ZyUgfv3YRJmMvJ9JU72ZZXyvdGTEHbhAhSYixbQ41NWJgr/XN6teSTZVlezzq/byuCnHXX16d1TaqTFy0i2ElIkBP7xuWUTonMMtREoATEzLtOQQLxEcF8duOJVNa4Pc/61wW9+HplDoPaxXM0CaiAEEKMBl4AnMCbUsqnfK6nA+8CsUafSVLKGca1+4FrgFrgdinlD4Ecq0ajOfKYPv0ma3KK+Gx5Nv3bxnH2CS0BuPXjFczdkMca2wrbzra9peyvrKHXoz/SNiGczPwyXpu7lahQa/raWVjO9oIy8koq/apwPrhmEDuLyrnvs1Vext4PFm9n4ZZ8QMUSmDYAkytPbMONp7T3EhAzbh9GN8MW4Iv5XW87tQMv/awMzqVVliCLCXNRVF7Nie0T6dEqmj6t43h/8XaiQoOIi7B2JP3beguC1vHh3HpqR6prj26qjYAJCCGEE3gFOB3IBpYKIaZLKdfZuj0ITJNS/kcI0Q2YAbQ1ji8GugMtgVlCiE5Sylo0Gs1RpbrWzba9pX/KEDrquXmkx4czukcKYcFObv1oBQDvLMz0CIj/rdoFKNWQQ9TNTFxYVk2Ph9X6MDPfSkdRUmGll9hZWM7uovrT3SdEBnvUNXY+XZ7tOf74usFEBAexp6SSM56fR+/WsTw6rodnhwPwwJgu9QoHO3eP6sxfT+/EszM3etk8plw9gA8WbScjMYJvbxtGrVvSISmS4Z2TDvpMAJfTwQsX96a6VpKRGJjYBzuB3EEMBDZLKbcCCCGmAuMAu4CQgPlrxwA7jeNxwFQpZSWwTQix2XheYOLJNRqNX4rKq5n0+Sq+W5PLwkmnEhEcxNe/53DF4DYHTTH/e1Yhm/bsZ9Oe/fy03n+20tXZVjRw5we/Izk6lBp3w1fJFw9ozdSlWUz6YjUAKdGhHpWUnbjwYFJiQmljuJ7eOqIDLxspKwDatYjwBJtFh7nomx7LdcPaAd4C6/qT29c7lrhwb1dTIQR3j+rs1dY3PY6+6XGec6dDcNWQtg38tooDueseaQIpIFoBdsVdNjDIp89k4EchxG1ABHCa7V57UEC20eaFEOJ64HqA9PT0IzJojeZ4pqK6FpfTgdMILBv/ygJPaoedheW88NMm5m/aS9/0ODqnRDF/Ux4OIdi8Zz9dU6MZauj/a2rdjHtlQb3vAZWuYuzLv3jOa9zSS/0DMHlsNyZ/s873VgDevLI/p3VLZupSa5qxC5cwl5OXL+1DbnGFx87w3l8GsiVvPyd3bOEREJ9cP5jOKdbuyOkQfHHzUK93vXBxb78C8Z/n92Tb3jIuH5xOqB9jdlOnsY3UlwDvSCn/LYQ4EXhfCNGjoTdLKV8HXgfo37//wXPlNgEiIyPZv//w87toNAejoLQKpxDEhLuQUvLpsmzu+3wVAN1So5lxxzCPcAD4dFk28zftBZRReM6GPTzz40bP9XaJEUy5egAJkSGsyq6bqt53dT/9d6UwcDmFJ8jMzr8uOIEL+qURHhLEfZ+tqnM9zcg/1Co2zCNY9u6vYmyvlnzz+05WTx5Vx5DcJiGCNgkRXm2D2nnnPvNHfav2iwY074VpIAVEDtDadp5mtNm5BhgNIKVcJIQIBRIbeK9Go/FDYVkVOYXlnuCr+uj72EyiQoP46e5TyC2q8AgHgHW7itlV5L2atxtqb/94RZ3nbd1byin/muPVNq53S75euZOBGfFMu+FEVuzYx7mvLgRg9vo9JEeH8Mv/nUrHv33HiM4tPP79oNRCQggGZ6gJ3BQwVw9tS61b0jFJrfpn3DEMKSW9H53JyC5JPDuhF38/q6tfLyM743u39LJjBITaaph+O/S7Cn59Hca+ACH12HLKDHfe8KPrqXQgAikglgIdhRAZqMn9YuBSnz47gJHAO0KIrkAokAdMBz4SQjyLMlJ3BH4N4FgDxqRJk2jdujW33HILAJMnTyYoKIjZs2ezb98+qqurefzxxxk3blwjj1TT1JFSkltcwR1TV/LrtgI2PD6akCCl9qiqcTNnwx4GtI0nLiLYE3hVUlHDwCd+4vHxdTfus9btrtM2cUhbPl+eTYmt/kCoy0FFtX+7QUfDMGyqX/qkx/H0+Sdw3+er+HHdbsb0TMHldLDx8TNxOQWVNW4ufn0xK7MKPcbd9IRwXri4N8M7JRHictRR5ZhpJn59YCTRYS5cTkedNBn+eP7iPgftc8i43VCcDbHGziJnOfz+kfoDyDhFCQuTsgJwOCE0Bp424h8mF3GsEDABIaWsEULcCvyAcmF9W0q5VgjxKLBMSjkduBt4QwhxF8pgPVEql4G1QohpKIN2DXDLYXswfTcJclcf1iPqkNITznzqgF0uuugi7rzzTo+AmDZtGj/88AO333470dHR7N27l8GDB3POOefoutIaLypraimvqiU2vG5Alj+mLMjk0W8tff0fu0rI2VfOLR/95mkb1jGRN67sz49rvSd/exEakx99BES7FhFMPqc7S7YV8McuK3X+h9cO5ovfskmPD2fq0iwvtdQZ3VN45seNXGsL/rInljO9d4KD1Go/1OXk9G7JrMwqpEWU9b0bYphtiFAIOHOfgrn/hDtWQVybutdDfTygns6A4Eh44NhUkATUBmHENMzwaXvIdrwOGOp7n3HtCeCJQI7vaNCnTx/27NnDzp07ycvLIy4ujpSUFO666y7mzZuHw+EgJyeH3bt3k5KS0tjD1TQiJRXVuJzWCvmG95czZ0MemU+dBcDYl37hjO7JdE6JZmBGPEh48edNTOjfms4pUSzamu/1vDfmb2WuTWUDKqZg3MsL2OCTI2j+pr2M7JJEamwoHyze4WkDeO2Kfgzv3MLTt296rEdAPHNhL/q1iaNfG+WZc3avll5Bbh2SIj3jNxncLoHv7hhG6/hwIoLrGnZvOqU9o3uk0L5FJPzyPLTsA+1OaeCv2Mhsmqk+S/OUgHD7qLBcflxTqw7T5jjrEagqhTFPH95z/NDYRuqjx0FW+oHkwgsv5LPPPiM3N5eLLrqIDz/8kLy8PJYvX47L5aJt27Z+03xrmh+/bitgaWYBt4zowLLMAuZsyOOeM5QrZM/JP9IhKZKZd51MYVk1c4zJvaSimsiQIFbnFLE6R6kfJg5pS0FpFdN/30lZVS1pcWHM9Fnxm/EFdrL31Z8q/tSuSZ6JPzk6hN3FlQBkJEZ4VFUAfzkpgw+X7ODDawd5vJZMkm05hR4b193vrtjhEJ7kc/5wOIQSDgCzHlafgVS7lBXAz4/BqCcg+DBiC6oroNywIwgHzP83VPpM/rVV1rE8Qn41mb+AS6f7brJcdNFFXHfddezdu5e5c+cybdo0kpKScLlczJ49m+3btzf2EDUBpLrWTXWtG5fTwYTXVCjPxCFtucAoE3nziPaefD+b9+zn1Tlb+NcPGzz3j33pF96/xttD3EzmBipVta97qJ3+beJYtv3AhWxaxYYxqlsK+w2j7RndU3hvkfp32S7R2+unfYtIr5oHduyG4StObHvAdx6U2rq1EI4ImQsgawkM+6s6n/s0LHsbknvAgGv+/HPfPRv2Zarjmkr46dG6fWoqrePKI1ThsiQX2px4ZJ7lgxYQR4Hu3btTUlJCq1atSE1N5bLLLmPs2LH07NmT/v3706VLl8YeouYwyCooY3VOEa1iwyitrGGIz6r6xveX89P6Pbx5ZX9P2zqbDv+/c7d6JmaAF2Z5VxXMzC9j2NOz/b7brCPgS5BDePIKBQc5CA92UmakfDi3TyuvdBSnd0vmDWNs15yUQev4cE7p1MIjIPx5Ax3IXvbUeT1JiAzxf9Fdq9Qhvrp4f1TYdg3uWqgsgbDY+vs3lHfGqM8Tb4WgYJCGgb3mMHfx2Uut4+J6bAq1VbDkNdg2DyKT/ffZu0kJrJEPg8tmV6kuV0LnlPsgzAi2kxL250JUYNTTWkAcJVavtgzkiYmJLFrkPyhcx0A0Pf4zdwufLM3yZBHd+o8xbMsvpbi8ms4pUZ4oYntA15oca/J78SdvgVDVwHw7z07ohdMh+G1H3VoHlwxMJyTIwZu/bKOqxs3ce0dwxvPzKCit4vy+adS4JZEhTj7+NQt7sbUgp4MxPVMBZdA+Ie3ArrJ1qCzh4v5p4PDjYlpeCDMfgt/ehYf2efeRUq2oQ2O8+5sseF5NjvdsgsgkNVkKBwTVI4jqo8K2ai/cAYkdwGlEQNdWK5XQnCdh+P0QYqi5qkohKFR5GzWUfdv8t1eXwU+PQZVPnQi7uullYyGR1A36XgFbZkNRNiBh8avq2in/BwVbYf3/lNCJDIyA0Om+NZpDYMqCbV5eOqDSRdhTTL+3KJOR/57Lua8uZOIUa1U5Z8MeT4TyI/VEB/vDnpTOTv828YzoYuXwSYgI5oJ+aQB0SY1iVHc1aVTXumkRFcLrV/RjROcWDMiI46VL+njsB456dgPvXzOIe884hN1teSE8mQa//LvutbVfwT/bKOEAddUr8/8NT6VDqc3QXmETEDmGJ9bvH6vPlwfAq37UKrXVagIuNIryFGyFef+yJuA8S3VHgaoM5yUgFr4Ei162xmm+a9ErxpiKYb//tCFe7KtHbbxnvRIOsT4Bdj8/VrfvjsUw5yl4fzxMvxVm/0O1L35V/ZZvjID5z6g2vYPQaBqXfaVVPPLNOt5ZmMnce0cAyhV1fa73ZPeFTX1jr2VQ45Z0SYlifa7/ErR2okOD6N4yhksHpdO3TZyXZ9AlA1vTLjGS1vFhCCF48KyuJEaGeKqL3TGyI61iw8gvVQbR8/oqodG/bTxTrh7oeU5SlFJf2NNMHBamimXjD3Cyd/VEtnhXY6N8n7e6aK7hgVOyEyKMyGb7DiI8wXrHghegyNiNFWZBbGtlIHaFwprP1aRZmgfnvAjvjYfC7UptM/x+KLEZ7k0BYXoaVRZZwWoOY2qsqVLqopxl6vylvurZd/wOcW3r/y0K6xEQWUYGoU5nwq+vWe3z/QjVlR94n5fUdTrwEJVa/7XDoNkLCN90w80VeaQ8IjR+2VNcweVvLQFUAjtQ2Uc35u6vkyZilZGA7h/n9uSBL71jbzol1y8gzFTQAO/+ZSB9bEnd7HRMiuIvJ2VA1q9QuINrh13gdb11vPLEaREVwvrHRhMS5F9RMDAjno+uG8RAe2rp2hoQ4sDqlNoapd5xONQxgDMItqsIaRI61L2nfJ+fc1uVuFrDeFu6F5a/A2kDve8xdwR7N8Mf31jtOxarCf7F3nDua0rlYsecqFd9ov7O/Jd1zRQQlcZ/j7J96v1g7XBMF9S9m5UdpNRwGy7YpgREfb9XfTuI3NUQEg3thnsLiMOlReeD9/kTNGsVU2hoKPn5+c1+8pRSkp+fT2joMRAo1ITZvKeEr1fWNS5W1tRy2ZtL2LhbTRbhLqeR2uFHznnlF6++ZsCXyykY3cPa9kcaUcEd/aScNmkdb7kq2ovYAFxoqI4ATjFjEt46HT6vx+tGSpCSUJez/gWSu5YhO98lqNomsB5LgKm2hAfZy2Htl+p41ypY8aGajP9rhC99cS18NEEd7/lDfdo9dYxxsMdHpWaf/MtsFeNKcuGbO+D14d4qJnN3kveH93OKstTuAJQAMCfwoiz8kr8JhFMFufoKiPIC2GuooEw1knmtYAuU2dRfZfmw6lN4vAU827Xue+rbQQB0GAkxafVf9yCg85iDdxv7YsDSczTrHURaWhrZ2dnk5eUdvHMTJzQ0lLS0hvyj04ASBmlx4RSWVRMfEUxwkINRz83DLVV072VvLuaRc3rQr00cz/ywgU17LOeBnUUVfLB4u988Pqd2TuL7tbkkRIQQbysA07dNHPM25tGuhbeAGNUtGSHgh7W7SYsNZ02OWrm28PECeur8E5h8Tnf/9ZSlVKtYO4/EwgkXw3kHWKWu/1YZfoty4OxnrfaN36tPdy28eao67n4ufHgB7LfFWhRmwbqvIThKfW406qvbJ/bnuvv36CnfZwkP0zUUYM9a9VlbaamYIpO932unKEtN9qAEkzmh78uEqrK6/bfOUfr6hA5K8G343rona4klBEwBUWXYm2oqlIA0Kc2D7ycZfXd7C0WTwbfA4lfqtqcPaZjNYOB1MPopWD4F/ne397XYdLWr6nqOd+qOI0yzFhAul4uMDP/FzjXNmD1/KGNk9/F1LkkpKams4bRn59EtNZp1u4pp1yKCn+8ejmln/n7NLtbkFHPTB8sZ3UPFA0zon8a0ZVZxmb9/vZbM0Et5p2YUs9vdy9yNeSRFhdCrdaynnCXA0+efQGy4i4Vb8pm3MY8WUSH0TY8lNSaMywalM6RDIjvyy5SAiAsjNSaUXUUV3q6lmb/gdNcSUV80cWWJt9uouWNeNfXAAsJ0IzUntxpbENcvz8Gsydb5ktfqRgH/9p5yEa0sgmlXWu1224EpHIKjYND1lq69fB8sfRNm3KMS2JksfMk6Ltur7mt/qmWcNgmLV95MhVmWOqim0jou3GF4/viwdyO07Gut4D++CFJ7G+8zhENsuk1A2LwKTfuB/Xt5vrOfOJPOZ4KsVZ5Lfa6Et4xqBmFxEJ4IrQdB70th8X8gb726Nvhmy1NpjKEO6ztR7dx2Gob6TmdCfIbqF3qIXmaHSLMWEJrjDykl4tXBAMxwr0dKGNMzhTfmb8XpcDBzXa7HC8mMRdiaV+qVW+hbIwJ5T0mlJxbg5E4tuO3Ujlz430XkFlfgQLmiTgz6kSsmTqPD32bQNjGCEV1a8M/v13vSWk8YoJIS7y5Rk3BydEidWgNJ0SEkRgbTJz2OW0/tQHG5bWcy2TYBTC5SKp/KIjVpmpTlWwLiP0Mtv/4DUVttuXyarqL2uINZj3j3/+4+cHkHzLHqEzVBVfhEOZs7CLtqN7KFtyG1fJ/KbgrK598fxTkQ3dIyUNv56zr4/FrI32y9v9a2g3DX1FVHOYJUe2QyRFipQ9hlcxMOjYG0Acq2IaX1PFDeUCZ2QQaWjcROVGaNcnYAACAASURBVCqc+c+67aHRyn5zzY/qvN9EeHWI2j11OQt2/Q5dzrb6O4Pg+tnw6USIbwcjH1IC3PxOAUQLCE2zYfb6Pdz4wXI2GP+qb/5QrbjeuLI//5ix/oD3nvnCfM+xmYPITmpMKK3jwxneuQVTl2YRgRVU5XQIkqJC6JQcSWejLOf5fb3VfRd0i6LP7k20ia+rUw51OVn24Omec09yvmo/0dGmyseeeqIsX60oAXav8e6/bR5knOzdlrUUPjhfCRpQPv7gM9H7sdtVl0KLriqtw84VSr3TbTys/cK7n7mDsLuyhsV7T/SzbWnWdv0OEUlQ6uM+WryzfgHhClMTcOYv1rirK9SEHpeh4hByfX6L8ASlDopIgIE3KCPzV7cot1OHC9zV4AyBDqcpb6h3zoLtBy56RM8JsHqaElQAQ26HhS+q46h6AuFC/AQJmgFxDhdcPaPudYAL37GOzUA5e+qOANCsjdSapovbLfl0WVadIu21bkmNT9vfvlzNW79sY8WOfVTWWNeEscq/7r1lhz2elBhlQL5/TFf+cW5PhqR7G5E/vHYQd5/eGSEEm584k2cuPMHretiP99BjxcOQfQhjKa0rqDy4bcmNTdWI20/C43fHqs+vb4E3Rqrj+c9YwgFgy0/KK2fRS3Xv9yW6JfQ4H5Bqp5Lczft6TLqasKVUBmeTsFj/6pAe58Oox+GCt+D6ud7X8jdDdCtLQDiMeIXETuozNFoJBFMgleapHUK8KhVaJ3uz+ZzwRDUhdxtnudR2HKU+ncHK3iKcBxcOAMnd1efXt6rPPldY1+qr++DvdwgyHBQaGs3t6e/H9nEE0QJCc0zy+W/Z3PvZKt7+xTsiddRzcznpn95pJz5csoPHvl1HTmEFLW3eP6FU0av1gVMzjO7esACjJCMJXUyYi0sHpfPaBO8Asg5JUcQZRukgp6Ou51CJYWTds84wjO6H53vCVp9JEZRXz2/vHTggy+4lYwqS+gy57lpY8YHy5S8rgO2LoJWV9oO89cozafk79b/PJDjCe4KzR/B2HqMMq7JW7R7sfvsOl5p8AVrYfrs+l8OQ29Qup2VvOPVB61pFEUSnQoSRuqRVXxj/H7jO+O8fGqPeVWyUsjdVW3YBERQK1/4Ety6z3m/fkZwyCZJ7wtjnleA48ym1O7nR2zuNK75Uu4WkbnCzzRaRbNTRMKsRmO8+EP7SjJx8t/fzDkakESAZoAA5Ey0gNMckewydfUGp9xZ6S14pucUVnshlty2COaugjJaxlqvofae24bMbTyQjMYL7z+ziKSxj56KBVuHCJ85V/3OGuZxceaJ3Ln+X3Wi8bb6V1rmhmGklvrldGUaLspXeOvMX+PIm+O8wq++iV2D6bTDPJ32z3fi72+Y2+vXN8PqI+nX5Ocut4+VT1O7hhIvqH6s/FYhJcKR3gFuYLVZjwDWW8Td/M7xnK4IlBKQYk99pk61232Czk++FSVnQboQxliilngIl6HpfaqXAMMdZuMPbgG5O0sXZagJN6w+JHa3rEbZcWb0vgZt+URPufVugq7HjMncpJulD4Pw34OZFkNQVznpWjauFTz9nA7T2/n7f9qcqtWGEH3WaP9oNh/Pf8haoAUDbIDRHhW17S/loyXYmndnVk26ipKKaPSWVVmpnG1WGqsjldPgNdmz/wAzWPzbak4AO4NfMAs7qkQLGQvrqgcngdDD7nuEALNqaz5wNeUw6swth66Zx1e6nqG67C4cAt1QlLefdO4IWUSGEBDm4/8yuvDF/K1kFPu6SUy/zVtHk/KZWtwdC+ARSmT74BVthzWdW+5ynrPQJprupiannhrpxBTt/s7xcfPnuPut4iWEY7jwavrvXf/+Mk5ULbFRq3ehd3x2EXUCExlmT+QJDDx+eYKjAhOrrm7Y7pjV1CI2Gyz+H36dC17OV+gvqqlPMcRRlqUnbFIT2NBY9J9R9vj+bhi/OIPU7bJunzn1zPg24Rv3VVEForNq9DL5ZXbv2Zyt9hz+C64+FaTBCQM8LDt7vMNE7CM1R4f4vVvHG/G2sySmiqKyadxdmcvlbvzLy30rFsnZnEc/N3EhVjZuHv17DC0YCu2nLssi4fwZ791fWsUd0+fv3LLEVyTnbsYinttpcW32MvMM6tiAmzMU1J2VwVbGaKF1VxaQa9oX4iGDSE8IJc+/H8XgiYdtmcvvIjvzrwl7qAflbVLRwpc8k98YIFVG75nP/hmVQkcd2TA8bU1CAylc058m6955htOXZDO2Zv9Tt50t/I4hup1E/OqqlyvwZnVY3F5Cd8a/C2c/DdT/D2Ya3jOnBFBzuLSDsAVphsZaxfN1X6n1nGW6t9QXr1TeROpzQ5zL1LnNHMOQ27z6mqqZ4p1J1mf3s4zvprrrPDm1gRtirbBHb9Y0/KBgmbVeCb7Tx3ymtH6Se4L8/+E9keIyidxCao4KposnML+XdhZle+YrKq2o560U14VXWuHl3kaVfN1VNyzILWGLLa2Ry04fWqvnl4JfALkNqvCfriUPackG/NDUWj2tkNU9fcAIPfLmaToYHEvsylbFz1mS10jZ5ydglhMTUFRJ/fA2f/UUdX/6FMp4GhcCXN8CAa5Uh2M4eY7Iv2GK1feon4MkZYnnDmAIiKhW2GbYLV7jyszfbL3gbppypzqNbWs85+V4l3Ep2Qpshqu3q72GK7fuZhERD/6vVcf+/qL/5z8JPjyjjs93uEBanhJ90q4k3LM5yfU3tZRlqfVNb3zDff+yAP0Kj/RcMCjEFgYTWA5WAMgXuJVOVusteACgmTbm0HkpRoFuXe/83Os5oOqJM0yQor6qtq5IBog39//rcEk8SOZN9Zdb5p8uySI+v+z/wwi35TFmQ6TlPiwvjvtFW/pkfbvSzYqsuV0Xk3xsPS17D6RCWHcI0KtZWMbRDInPvHWFFKZveQHl/qEAsUM8x8RUOoFIym3x9i5rsP75YTZT+ErGZOwjfGAITUwceHm/prM1MpCMesPqZE2+H0+C25dbkD5Yh0xWudNWmvt8sLuNbZCY4Sk3E/lbLpoHXXePtvhkaq/zywVq5m7mYkrpA+5FqF3G6T/Gc1BMOv4yofafQZogKLBvzDLQZqoLUzAhrk3NeUmkpGmoIBpUOvNMZhzdOk06jA5ZUL1BoAaE5ovzty9UMe3o2JRXe1cCKjSR0K3bso7DMW0DY01jkl1YxonMLhrT31hN/8Zu144gODeLNq/pzWlc1UQncpP3xZt3BVJerlfbW2UoPX+PHZ/y39yx1zYbvVR979Ozrw9VnXj1xFJ2NesubZqoVbWjMgbNumvi6YNoZdJM16ca0tlbhm35UAV5m5C9YSeJGPqTsA6A8ds57w7rPnNxNAZFuEyImIx+CSz+pf0zmM0y/+8E3K7uKK1SpcSYXWQZa02U0KlUJmwHXWoblI4mpYgoKU79JcITyoqpPhRMer9JSNFbyzks/gbsPHI9zrBFQASGEGC2E2CCE2CyEmOTn+nNCiJXG30YhRKHtWq3t2vRAjlNzeCzcvJfnZm4ElKEY4Of1e1iWWUBFdS25RRUs2qJsBYu3FvB7tveq+T1b+UyAzinRfHTdYE/iu4sHtGZ/pYou7tEqml//dhpdUqLplBzFvWd0ZlLGViKWPF93YN/cAe+fazu/vW6fBc+rgKht85R30Yx7vOsIl+1VEce+qR5MzjFiB/bnqrTT9VUJOxTC4qzV79A7vI2aQaHeHjaDb1KfsTavq8SOcMIEtSMw7wHlUjrmGf+ZP7ufC22H1m03MSd/swzoGf+Ah/L99x16p/JU6nN5/c87Epg7q7T+yhagOeIEzAYhhHACrwCnA9nAUiHEdCmlx/1CSnmXrf9tQB/bI8qllLalkuZY5dI3VRrs+ZvyPFlLpy3LYsHmfMb2asmSrfme8pd2TnSsZam7Mz+t3+PJQQTQNTUKvrqFOYNa8kvqlcSEuTzV2D65/kRCXZZH0C3t8iAyEv5X5/EqViD9RBj3Cvz8uKpTIKX/TJumi+hv73q7RAJ8cV1djyKTiAQ1UVUWq9V+ZYnK93Mg2p9atz6CHXeNWu0/XKhWu/Zsp0VZatXuDFYr9QHXqj9/mDsIc/KMbqlW2H77HiSnj7nrMFNAHGgVbu4qAo0rTAXmdTkr8O86TgmkkXogsFlKuRVACDEVGAfUV0rrEuDhAI5HE2DstZHNHcM3v+/027ev2MjHwU/wYs14nq2ZwLXD2vHYt+qfRo9WMfD2B7QEJkz+GyUV1QztkEB3kUlEbTFgeM6U5HobWYXTsi2YXDJVGS9bD1IpIbb8DN/fX3dAO2zBTz8avuVmxsz6hINJVKoSEHFt6w9WA2VwHnoHdBljCYj49mri7nK28ttf+JI1oZuTcHg8PLgHHk9SeXsA/rb74KoS0xjrbEBZzvqifk2SulgC61hBCFW451gaUzMjkCqmVoA9KXu20VYHIUQbVPUQ+7IqVAixTAixWAhRNy2nuu96o8+y4yGl97HCrHW7WZmlhMEtH9b1vQ9yCK50fM//BXmrZW4dYRWSOTVZJczrKHJwOQXn9rH+abhqvdMNRIW6+PCK7jyQdQM8nQHfG0ZaeyI1h0tNoiExPl42hktjkpGz/4PzVM7/BJ9dgmk3MAO0ACbOqGtUNJOjXfQBPGSs7MuNz/RB9auYYlrDjfPh1L952xBuXgxXfg2Db4RT/64ie01/ejtBIfBgnnI/BaVnP9jEaMZemMbqA9EQFc2xOBE35HfQ/GmOFTfXi4HPpPRa/rWRUuYIIdoBPwshVkspvfzNpJSvA68D9O/fv3lXBTqGuNbIbbTtyTH8b3Vdg+zZJ6Qyef17ADxdcxF3ntaFG05pR6jLydheLemUHEn17DUwD6oJYkTnJOIjgnl7Yn9aRrvgtZPrPNNLJbP4Feh2jpWbB9RE7gxS0bBVpapmrx1fz5UhtyobBXjXGxh0ozJqg8oD1PlM7wjloDCV3C0kyjIQm+NIH2Kl1DBJG6gCrobebnndCKFUI7VV3hNzUAiM8LO78Vw/RD17UlflvdT7ALaAG+bXH2CnOe4J5A4iB7CHSaYZbf64GPBabkopc4zPrcAcvO0TmqPA1rz9nPHcPB75Zq3f6+Yuwpfrh1n5aLbeGM8dO+8ltDgTUPWPxR/TCZ6nCrCfkubgsfFq8j61cxJdCuerql8m1eWqUEumT+K0t0d7l2w0V8lOl391SUQC9DVqFvz1D2WbMDGjeV0R3uUyHQ6Vn8eOmXUz2PaOy6bBqCeU+6evYTYiEUb+vW6CttuWw50H8GQ6Egih4h+iD+BamXqCpbbSaHwIpIBYCnQUQmQIIYJRQqCON5IQogsQByyytcUJIUKM40RgKPXbLjQBYt2a37m34CE+X7iO8j1boHyfVzTzua8urHPPk+f1pFuMlRJBLH1DrcjfNnzJ3W744gbP9ZjKXJKjjUl31SfehWcAvroJXhvmJ3JYqv4mdjWKubLvcb73LWNfhP/LVDp/e+qEWENAhMdDjI8W1J6WoWUfZRgF72CrlJ5qRwLKnfP+HOhhpEGoL61CULD2vNEc8wRMxSSlrBFC3Ar8ADiBt6WUa4UQjwLLpJSmsLgYmCq9C0d3BV4TQrhRQuwpu/eT5ujQZc2/6OBcwSm1Kwl79VpywzuyYORXB7znkoHpVvF6UMXeQaViripTRV1qyuG0R1RBmOXvKpXQlzeofP6+mPWQ9/jfxXjw9Ty6P9tKiWwihJU7yG64NdNOhMVaAsDEFBDx7eAvP8Bbo/wXh7ETEqnSYK85cDeN5lgnoDYIKeUMYIZP20M+55P93LcQ6OnbrjnKGEbgYQ6lCkkp28Tdn/7u1WVMzxRmrM6lvcghEiO1hd2Tp8g2mWYvtbJ9RiYrg29tJSx9C/6w5b0BlV7ZHsNwMNr4+PAfzCvHvoMwjdr2xHMmZnZNZ4i6Z8J7qlRmop9YAjtJRp0Ef2UvNZomwrFipNYcJWrdEofAyo66+jM1QY96TGXdzFnOTynXEOR00LVCuahOCFJ5f6qkkyBqSBH7yJYt+Of5PZlwQjzVzhcJXm/sLJZFwUybt7I9lcTmWaq4PaiVuakKmvn3ugPNGA69LoXfP2rYF0sb0MBfwMAuIDqdobKjjvibOr9gihUxbO4g3EYZ0Lg26rc6GGYwW32pNDSaJoAWEMcZ7R+YwXl9WvHsRYar5epPYcdClcZhrqqfe21FTySCTSG7weZBWE0Qjwe9zcVBc/h+7DJG90uHdV9bwgHgW1uAlDNYTbRhcSqYzCzFCErfb9fB97ta1SowcTgs11STFl38p7y4e6N3VtGGYFcxJbSHcS9b5z3Os45NG4JvNtaDEd9OZR894eJDu0+jOYbQuZiOI6o2/sQDQR/yxYoc9hRXIKW0CtfbonWT2UcU5bhELZkOyxEtQlRycdAcAE5INhPb1dT/wiib6ibJpzRlWJx3zIDd93/0U+rT1/Nn5MNwpx/Ffn21fw9EQwq7gKpvPPAGmPDuoT1fCFVKM+UQEsNpNMcYegfR3CgrUOoTM3HbtnmQ9SsMvJ7gj87j+iB4pmYCA//xEyM6t2CKkXI5N3cnZnjZg64P2OhWgmFf94m0FZtYVRbDCZstt9I4Vw3MfMir7rBM6ICwF7UJjQV2GAKiK2z8zroWnuBdQ9k0MrfqZ+UX8hUQ0amWxxGovEL+6jAfSRwOGPP0wftpNM0QLSCaOPtKq9i0Zz8DMwwVy9MZyu3SrKlrFq236cLvDPqcTJnMtA0jqE0owAlsytxOimESONu5BJwqv1KfHj2g8z2cULwLnrUERNj+LFjwgtdYxNXfqVQRpirJNBSHxakC8VlLrELwoTEqL5LnZgF/Xe+d9dNXQJhRzZ1Gq/QX/a9pUsVXNJqmhv6/q4nz9oJtXP7mElWj2axZnLua7fml3Dl1hdVxnWUnuDloOk+73gAkNfuVammYsx6fTFO3H52q0kCY7Fpl65Oggr4ik1ThehNTfx8WrwrSXz3DSnEhhJrch94Bl35qvcPufWSvfSycKtU1wIXvwB2rtHDQaAKM3kE0cXIKy6mqdVNaVUP0LssF9fs1uXy1cifPGzFoFO6gIKQV8ZVWMHtnkUWI8K7bMK3mFCJEJWc5jeR1YTbjr+miCjDL5qmU0MGKJbCv+k1PIbta6LqfvSuJ+RaSsWN/VlSK5fXkClPeRBqNJqDoJVgTZ0+xilreX1EDu61gsv15WURT6tV3u8O7QPwXcS/Ved7eiI507Gjz8bd7B8X6KTAP3kFq9kndVGvFZdiuRzd8crfXDo5Kqb+fRqMJCHoH0ZRx1zIm7w22MkwV1Cm3PJHuXjOOk4K7eHVfV5XiSWhVJZ1ElNVNjXXzwFi18jdK+3qv4uvJ6ZMx3Dq29y8zCsqYlcwOFbMgDATGXXTI7VYeJo1GUwctIJooUkoKtv3OpZWfMjbkW+6a0YV7yMEuEgY51lMugwkTKuhrS0UUuCBHJtICW6K9Ux+EDd+prKT9JsIGI/hdOC21Dijf/uQesNuwV1wyVWU67WK3O0RYx6V71aepfjpUnEFw00J1/8Eio/8MDQl402iOY7SKqSlQXQGz/6FiFty1MPdpPl2whrveUoVsokQ5fba8zOot2eyU3gFjs929qZZqki+UESwZM4NbIp9jscMIlLvwXRh2j7INXPODUiOZuwDf4DOnCyZ+a523GwGXfeotFMwI7ahUOO91yDjF23ZxqCR3D4xw0Gg0B0XvIJoCv3+sopzdtdB6IMx+gtZRy0gR1so8XewhiFpKZDj7KSNSqMR322QK+4giiUIKiaRXn8HErl3OS8X3cfJ58dDaT4oKU/fvLzeRyyYMzNTXvty0SHk0RSRCu1P+7LfWaDSNjBYQTYCqgu0EA+zPBanSbUfX7iMV5Ua6zt2GKMpxUkur5CRGZk3ix5D7iBFl7JDJ5MsokkQhJ/dsT6jLyeSx3amoqYWUaP8vNDOa+hMQDUlRndzt4H00Gs0xj1YxNRZTL4P/3VPv5TU5RewsLId10wle+JxqXPGBR//vopoUUUCejGGvjCZalBIlynGFx7CbeLZJZVDOcyazTCrLxMTh3QFomxhBl/qEA4DLqHXQqv9hfkmNRtOU0TuIxmL3WihW2VJV/QQBbVSVM+l2c/ZLKhJ6fvfvaA1ky0TSxF72/fQ8cQI6la2ghTOS7TKJEsJIpQCBxBURQ7DTwWbZit5s4e3bz4XYO2DrHEjt1bCxtR4Al07zrs+s0WiOO7SAaCwqS1Q5TYApZwJQOn4Kmxb/j26lv+LgH7hxsHXjGvaJDM6peoJVIdcSJ/Z7HhEn9nNz9R2Mcyygo9NwWQ2J4se7TmZvQQ8Q6yHRKKHZadShja/TGYf7DTUaTRNHC4jGorIYaqvVn0HEV1dj+BYxzrGAL93DaCd2sVyqQLT9hBJNmaf/WZVPsFZmMMKx0npuSBRtEyNomxiBd0nwI8h1s+vmSdJoNM0ObYNoDGoqjYI00isbKkCeVBPvFUEzCaGKVmIv29yp9EqLoUxaXkNb3KmslW0BuGakTXXk87yA0KqvqqGg0WiaNVpANAZmDQaw7BAGLYRKT9HXsZmV1yXhEJJtMpXB7RIoRQmIde42jKz6NxmJkcy+ZzjOUFsGVHtgm0aj0RwGWsXUGFTaBETB1jqXt7pTaOfIJWz7bAC2yFTGt4undJESEEUygtn3DCc5OoTw4CBYY9gl4jJg9D8DPnyNRnN8ENAdhBBitBBigxBisxBikp/rzwkhVhp/G4UQhbZrVwkhNhl/VwVynIfNktfh04n1Xp69YQ9f/GYrXm8XEHvW1em/WrZTB5tnASDj23ntIPKJIiMxQgkHsLKmnnQXRCT86a+h0Wg0dgK2gxBCOIFXgNOBbGCpEGK6lNIzI0op77L1vw1ULjkhRDzwMNAfkMBy415bnuhjiMz5qhhOPVw9ZSkA5/VVKSeKCwswoxDKstcQ7tN/lTuDcc6FsHMFRKUy426V6+iUHm3hj9/Ilz4xDINvUuko+lx+BL6MRqPRKAK5gxgIbJZSbpVSVgFTgXEH6H8J8LFxfAYwU0pZYAiFmcDoAI718CgrUIbnA3C2YxE83xNqa/hg7mpP+77tv9fpO6B3H9xh8SAcMPx+T3twiIpwzpc+HkRBITDgGm1/0Gg0R5RA2iBaAVm282xgkL+OQog2QAbw8wHubeXnvuuB6wHS0/9kxtAjQVm+l7sqAN/coXInjXsZgGdc/4XCai594RtS9+6CYMhyt6C1I6/O40YP6Aq9/qt2BW2GWBdqVH6lcSc1MOBNo9FoDoNjxYvpYuAzKeUhVaCXUr4upewvpezfokWLAA2tAZTlG26rNpa/Ayve95yGGpXb9uXtIlqoQj6bpCXzSnteiTSrt8W1VYFqduEAKqsr0L4xhaFGozluCKSAyME7UivNaPPHxVjqpUO9t3GRUhXqcVer44PQPrycWENAbJDWV4wY8yji7g1wf0796bGrjSC54Ej/1zUajeYIEkgBsRToKITIEEIEo4TAdN9OQoguQBywyNb8AzBKCBEnhIgDRhltxx6VxeCuUcfmLsImKGqrqzjZYdkZHo3+mjuCvqCECK4cPcx6TmisypQacoDJ30yip+sjaDSao0DAbBBSyhohxK2oid0JvC2lXCuEeBRYJqU0hcXFwFQprVlVSlkghHgMJWQAHpVSFnAsYpbVBCUggkJUniWDivWzeC/Yik2I36eERVhMIkEtbKois9DOgRj7PKT1VzUhNBqNJsAENFBOSjkDmOHT9pDP+eR67n0beDtggztSlNnklmmoLrUMz5X7cogAFtR2Z6hzrac9KCQColse2rsik2DYXw9jsBqNRtNwjhUjddPFZwchpeSxafM8TVUlSlhcU30P+Q5bEFtNJUTXcczSaDSaY4YGCQghxBdCiLOEEFqg+GIXEDWV7C6uJDsr09P049I1lMkQLh7SmdiEZK++hBsCo9elR2esGo1Gcwg0VMX0KnA18KIQ4lNgipRyQ+CG1YTw2kFUs3pXEaOcyzxNcbX5FDiiuLB/Gs69sba+lcruMCnLMj5rNBrNMUSDdgRSyllSysuAvkAmMEsIsVAIcbUQwhXIAR7z2ATEjJ9/ZnV2IWc4LAGRKgookFF0To7yrqHgMH620Ghw6pyJGo3m2KPBKiMhRAIwEbgWWAG8gBIYMwMysqaCzUg9Zt29rF75K5GigspIFcvQUuxlH1EEOR3eAuKyT4/2SDUajeaQaNDSVQjxJdAZeB8YK6XcZVz6RAixrP47jwPsKibgxdJ7QUBIXBrsz6alKCCy83B10YxfGH4/pPQ4uuPUaDSaQ6Shuo0XpZSz/V2QUvY/guNpepQV4MaBAzcAUcKoM21zYY1O664OnMHq0xV2NEeo0Wg0f4qGqpi6CSE8FlYjwvnmAI2pSTBnwx4+WboDygsoFH7qM9tjHDoZiWjNbKvSHfgBajQazWHSUAFxnZTSU8zHSMF9XWCG1DS4d8pM/u/z1RQXF5JXG1G3gz2fUrKxgzAFhPuQchJqNBpNo9BQAeEUwsoFYRQDCg7MkI4Rti+Exf/1avp0WRbvLsyEddNZGnoz/cQGaiv2U4QfARGVah2bP53D0OhpAaHRaJoADbVBfI8ySL9mnN9gtDVfppypPgdcAz/+HQbfyIOfrQDgiv7f4gA6O7IJp5Ii6SfBnqliCgq12pINw3Rix8CNW6PRaI4QDRUQ/4cSCjcZ5zOBNwMyomON3NWw5D+w5D+86OpPMNVUFsUQBsRRQoioplD62UGYwW9RKVZb9/EQPw9STjgqQ9doNJrDoUECQkrpBv5j/B1fFFmF7UY4VrBTJiL25gLQwaFKVPTtnAFbrPxL3LpMlQsF6DjK+3mpuhqcRqNpGjQ0DqIj8CTQDfDoTKSU7QI0rsZDSqu+A0DhDs9hsKilrdgNhifr2anFsAfap7eGLbZnmCqka3/WAkGj0TRZNk1eswAAEz1JREFUGmqknoLaPdQAI4D3gA8CNahGZcHz8Fiidf7jg3675bta4irYpE7CYv32Ia2fTqOh0WiaLA0VEGFSyp8AIaXcbtRwOCtww2pEfnuv3kuV0prsI/pdCDWqRjRhcYEelUaj0Rx1GiogKo1U35uEELcKIc4Fmmdh5HrqSq8f/hpP1qi03LVSENq6j3VRCwiNRtMMaaiAuAMIB24H+gGXA1cFalCNi38BsdLRjS1Sua6WEA7JPa2LIVFwzUzofBYMusnv/RqNRtPUOKiC3AiKu0hKeQ+wH1UXovlSzw7i9cW7CTfiHUpFBLHxGcqVtboMgiNUtPQlHx3NkWo0Gk1AOegOQkpZC5x0FMZyjGATEB3P8BxmF9Vw3oldAfjD0UmlzTBTaOiCPxqNphnSUBXTCiHEdCHEFUKI88y/g90khBgthNgghNgshJhUT58JQoh1Qoi1QoiPbO21QoiVxt/0Bo7z8LFvIKKsEqE3j2jPiQMGcm3V3TwfcbtqNCOjg5unOUaj0RzfNNQHMxTIB061tUngi/puMFRTrwCnA9nAUiHEdCnlOlufjsD9wFAp5T4hRJLtEeVSyt4NHN8RxJIQZY4ozL3BpYPScQjBLHc/HhxoxDl0HgM5y+p3c9VoNJomTEMjqf+M3WEgsFlKuRVACDEVGAess/W5DnjFyA6LlHLPn3jPkcWWintjQQ2mhEqKUvGB6x49gzCXkZW10yj1p9FoNM2QhkZST8GPe4+U8i8HuK0VkGU7zwYG+fTpZDx/AeAEJkspzSSAoUa1uhrgKSnlV37GdT1wPUB6enpDvsqB2bsZinM8p/uqnHW6hAfrwDeNRnN80NDZ7lvbcShwLrDzCL2/IzAcSAPmCSF6GrUn2kgpc4QQ7YCfhRCrpZT2hBZIKV8HXgfo37+/f/ejQ+Hlfl6n+ZWino4ajUbT/Gmoiulz+7kQ4mPgl4PclgO0tp2nGW12soElUspqYJsQYiNKYCyVUuYY794qhJgD9ME741HAySuHR1o8x8PjdPZVjUZz/NFQLyZfOgJJB+mzFOgohMgQQgQDFwO+3khfoXYPCCESUSqnrUZJ0xBb+1C8bRdHhR3FtZQl94e047vstkajOT5pqA2iBG8bRC6qRkS9SClrhBC3Aj+g7AtvSynXCiEeBZZJKacb10YJIdYBtcC9Usp8IcQQ4DUhhBslxJ6yez8dLUpqXIzIiD/ar9VoNJpjgoaqmKL+zMOllDOAGT5tD9mOJfBX48/eZyHQk0bm/EHtGdEv7eAdNRqNphnSIBWTEOJcIUSM7TxWCDE+cMNqBNzuOk2DenRqhIFoNBrNsUFDbRAPSymLzBPDy+jhwAypkagsrtMUntDaT0eNRqM5PmiogPDXr3kFBFQU1m2LTKnbptFoNMcJDRUQy4QQzwoh2ht/zwLLAzmwo065ISDaDLXagoIbZywajUZzDNBQAXEbUAV8AkwFKoBbAjWoRmH/bgCqh/svMarRaDTHGw31YioF/GZjbTbs+h2A7OAMMoDSsFQiGndEGo1G06g01ItpphAi1nYeJ4T4IXDDagR2roSEDmTud9KlYgrrz5/d2CPSaDSaRqWhKqZEw3MJACP76sEiqZsWeX9Acg+yCsqoIITWSbrOtEajOb5pqIBwCyE86VKFEG2pr3hzU6VyP4TFsj2/jDCXkxZRIY09Io1Go2lUGuqq+jfgFyHEXEAAwzDSbDcbqsvBFc723WWkx4cjhM7kqtFojm8aaqT+XgjRHyUUVqCS7JUHcmBHFSmhugxcYewoKKVNgjZPazQaTUOT9V0L3IFK2b0SGAwswrsEadOlthpkLTIojB0FZQzr2KKxR6TRaDSNTkNtEHcAA4DtUsoRqNoMfkKPmyjVZQCUuF1UVLtpmxB+kBs0Go2m+dNQAVEhpawAEEKESCnXA50DN6yjTLXSlu0pVz9H+6TIxhyNRqPRHBM01EidbcRBfAXMFELsA7YHblhHGWMHkVuuDNMdWmgBodFoNA01Up9rHE4WQswGYoDvAzaqo42xg9hS6CYqJEi7uGo0Gg1/IiOrlHJuIAbSqNRUADB7y37O7JuiXVw1Go2GP1+TunlhqJgqCOaqIW0bdywajUZzjKAFBHhUTOUymLhwneJbo9FoQAsIhbGDKCdECwiNRqMxCKiAEEKMFkJsEEJsFkL4TRcuhJgghFgnhFgrhPjI1n6VEGKT8XdVIMdp7iBqnaGEBTsD+iqNRqNpKgSsbKgQwgm8ApwOZANLhRDTpZTrbH06AvcDQ6WU+4QQSUZ7PKrmdX9UUsDlxr37AjJYYwcREqbdWzUajcYkkDuIgcBmKeVWKWUVqhLdOJ8+1wGvmBO/lHKP0X4GMFNKWWBcmwmMDthIjR1EaLgWEBqNRmMSSAHRCsiynWcbbXY6/X979x5jR1mHcfz7dLftbgGh0JU0tKFcariEWmSD3EwQQ61oCgkYuYjUQPoPDRCNSqOWWBKj/wiaNApqI0YiBARdSJNaCpKgAl2glF4olFpDG7QrLbRFWLp7fv4x727nnB3idrvT0z3n+SQnO/POzOn7np6dZ9+5vAN8QtJfJT0rae4BbIukBZK6JXX39PSMvKYfvgdA+6SjRv4eZmYNpt4nqVuBmcDFwDXAL/NPrvt/IuLeiOiMiM6OjoMYYK93D+/TxtFHto38PczMGkyZAbEdmJ6bn5bK8rYBXRGxLyL+AbxGFhjD2Xb0fPAue2nniAmlnZIxMxtzygyI1cBMSSdJmgBcDXTVrPNHst4DkqaQHXLaAqwA5qRnX08G5qSycvTuZi+TmDi+3h0qM7PDR2l/MkdEn6SFZDv2FmBZRKyXtATojogu9gfBBqAf+FZEvA0g6U6ykAFYEhE7y6orvXvYHe20tfoSVzOzAaUeU4mI5cDymrLFuekAvpFetdsuA5aVWb9BH+xmd7S7B2FmluM9IhApINyDMDPbzwEBRO9u9obPQZiZ5XmPCKh3N3top228exBmZgMcEP19aN9/2ROTmNjqj8PMbID3iB/uAWAv7Uz0OQgzs0EOCMSu065lQ5xIm89BmJkN8h6x/Ri2XvBD/l450z0IM7McBwTQ21cB8FVMZmY53iMCH+zrB3APwswsxwHB/h6Ez0GYme3nPSLuQZiZFXFAkDsH4fsgzMwGeY8I9KYehO+kNjPbzwGBr2IyMyviPSL7A2JCiz8OM7MB3iMC/ZUAYLwDwsxskPeIQF8KiHGqc0XMzA4jDgigUgnGCSQnhJnZAAcE0B9Bi7sPZmZVHBBk5yAcEGZm1UoNCElzJW2StFnS7QXL50vqkbQmvW7KLevPlXeVWc/+StDiw0tmZlVay3pjSS3AUuBSYBuwWlJXRGyoWfXBiFhY8BbvR8TssuqX118JxrkHYWZWpcwexLnA5ojYEhEfAg8Al5f4741YJYJWB4SZWZUyA+IE4M3c/LZUVutKSWslPSxpeq68TVK3pGclXVH0D0hakNbp7unpGXFF+3wOwsxsiHqfpH4MmBERs4CVwH25ZSdGRCdwLXC3pFNqN46IeyOiMyI6Ozo6RlyJ7DJXB4SZWV6ZAbEdyPcIpqWyQRHxdkT0ptlfAefklm1PP7cAfwHOLquivorJzGyoMgNiNTBT0kmSJgBXA1VXI0mampudB2xM5ZMlTUzTU4ALgdqT26PG90GYmQ1V2lVMEdEnaSGwAmgBlkXEeklLgO6I6AJukTQP6AN2AvPT5qcD90iqkIXYjwqufho17kGYmQ1VWkAARMRyYHlN2eLc9CJgUcF2fwPOKrNueb4PwsxsqHqfpD4sVML3QZiZ1XJAAH39vg/CzKyWA4LUg/AhJjOzKg4IfJLazKyIAwLoDxwQZmY1HBBAf6XigDAzq+GAwJe5mpkVcUAAlQqM8ydhZlbFu0WyoTZanRBmZlW8VyQb7ts3ypmZVXNAkA333eJ8MDOr4oDA90GYmRVxQOCAMDMr4oDAz4MwMyvigMCPHDUzK+KAYOAyVweEmVmeA4JsuG9f5mpmVs0BQTbct4faMDOr5oDAVzGZmRVxQJB6EA4IM7MqpQaEpLmSNknaLOn2guXzJfVIWpNeN+WW3SDp9fS6ocx69rkHYWY2RGtZbyypBVgKXApsA1ZL6oqIDTWrPhgRC2u2PRa4A+gEAnghbburjLr2+zJXM7MhyuxBnAtsjogtEfEh8ABw+TC3/TywMiJ2plBYCcwtqZ5UKr7M1cysVpkBcQLwZm5+WyqrdaWktZIeljT9QLaVtEBSt6Tunp6eEVfUh5jMzIaq90nqx4AZETGLrJdw34FsHBH3RkRnRHR2dHSMuBKV8H0QZma1ygyI7cD03Py0VDYoIt6OiN40+yvgnOFuO5r8yFEzs6HKDIjVwExJJ0maAFwNdOVXkDQ1NzsP2JimVwBzJE2WNBmYk8pGXURQCXyIycysRmlXMUVEn6SFZDv2FmBZRKyXtATojogu4BZJ84A+YCcwP227U9KdZCEDsCQidpZRz/5KAA4IM7NapQUEQEQsB5bXlC3OTS8CFn3EtsuAZWXWD7KB+sABYWZWq94nqeuuUsl++j4IM7NqTR8QfSkhfB+EmVm1pg+IwR6EA8LMrErTB8TgOQjng5lZlaYPiNYW8cWzpjJjyhH1roqZ2WGl1KuYxoKPtY1n6XWfqnc1zMwOO03fgzAzs2IOCDMzK+SAMDOzQg4IMzMr5IAwM7NCDggzMyvkgDAzs0IOCDMzK6RIQ02MdZJ6gH8exFtMAf4zStUZK9zm5uA2N4eRtvnEiCh8ZnPDBMTBktQdEZ31rseh5DY3B7e5OZTRZh9iMjOzQg4IMzMr5IDY7956V6AO3Obm4DY3h1Fvs89BmJlZIfcgzMyskAPCzMwKNX1ASJoraZOkzZJur3d9RoukZZJ2SFqXKztW0kpJr6efk1O5JP0sfQZrJY3JJyhJmi7pKUkbJK2XdGsqb9h2S2qT9Lykl1Obf5DKT5L0XGrbg5ImpPKJaX5zWj6jnvU/GJJaJL0k6fE039BtlrRV0iuS1kjqTmWlfrebOiAktQBLgS8AZwDXSDqjvrUaNb8B5taU3Q6sioiZwKo0D1n7Z6bXAuDnh6iOo60P+GZEnAGcB9yc/j8bud29wCUR8UlgNjBX0nnAj4G7IuJUYBdwY1r/RmBXKr8rrTdW3QpszM03Q5s/GxGzc/c7lPvdjoimfQHnAyty84uARfWu1yi2bwawLje/CZiapqcCm9L0PcA1ReuN5RfwJ+DSZmk3MAl4Efg02R21ral88HsOrADOT9OtaT3Vu+4jaOu0tEO8BHgcUBO0eSswpaas1O92U/cggBOAN3Pz21JZozo+It5K0/8Cjk/TDfc5pMMIZwPP0eDtToda1gA7gJXAG8A7EdGXVsm3a7DNafm7wHGHtsaj4m7g20AlzR9H47c5gD9LekHSglRW6ne7daQ1tbEtIkJSQ17jLOlI4A/AbRGxW9LgskZsd0T0A7MlHQM8CpxW5yqVStKXgB0R8YKki+tdn0PooojYLunjwEpJr+YXlvHdbvYexHZgem5+WiprVP+WNBUg/dyRyhvmc5A0niwc7o+IR1Jxw7cbICLeAZ4iO7xyjKSBPwDz7Rpsc1p+NPD2Ia7qwboQmCdpK/AA2WGmn9LYbSYitqefO8j+EDiXkr/bzR4Qq4GZ6eqHCcDVQFed61SmLuCGNH0D2TH6gfKvpSsfzgPezXVbxwxlXYVfAxsj4ie5RQ3bbkkdqeeApHaycy4byYLiqrRabZsHPourgCcjHaQeKyJiUURMi4gZZL+zT0bEdTRwmyUdIemogWlgDrCOsr/b9T7xUu8XcBnwGtlx2+/Wuz6j2K7fA28B+8iOP95Idtx1FfA68ARwbFpXZFdzvQG8AnTWu/4jbPNFZMdp1wJr0uuyRm43MAt4KbV5HbA4lZ8MPA9sBh4CJqbytjS/OS0/ud5tOMj2Xww83uhtTm17Ob3WD+yryv5ue6gNMzMr1OyHmMzM7CM4IMzMrJADwszMCjkgzMyskAPCzMwKOSDMDgOSLh4YldTscOGAMDOzQg4IswMg6avp+QtrJN2TBsrbK+mu9DyGVZI60rqzJT2bxuN/NDdW/6mSnkjPcHhR0inp7Y+U9LCkVyXdr/wgUmZ14IAwGyZJpwNfAS6MiNlAP3AdcATQHRFnAk8Dd6RNfgt8JyJmkd3NOlB+P7A0smc4XEB2xztko8/eRvZskpPJxhwyqxuP5mo2fJ8DzgFWpz/u28kGR6sAD6Z1fgc8Iulo4JiIeDqV3wc8lMbTOSEiHgWIiA8A0vs9HxHb0vwasud5PFN+s8yKOSDMhk/AfRGxqKpQ+n7NeiMdv6Y3N92Pfz+tznyIyWz4VgFXpfH4B54HfCLZ79HAKKLXAs9ExLvALkmfSeXXA09HxB5gm6Qr0ntMlDTpkLbCbJj8F4rZMEXEBknfI3uq1ziykXJvBt4Dzk3LdpCdp4Bs+OVfpADYAnw9lV8P3CNpSXqPLx/CZpgNm0dzNTtIkvZGxJH1rofZaPMhJjMzK+QehJmZFXIPwszMCjkgzMyskAPCzMwKOSDMzKyQA8LMzAr9D6HzvH4f4vdaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E_kALHn8efk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "efb3e248-93fc-42c3-c207-6a862235d93d"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFvNdC5xxcc7",
        "outputId": "0cb4fea9-e4ed-4203-f753-27542a549808"
      },
      "source": [
        "y_test_s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7LQrvY48ehr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea1ec82-da21-4668-c3e7-bf4b5e3ef9ae"
      },
      "source": [
        "#predict on testing dataset\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "K.set_value(model.optimizer.learning_rate, 0.0008)\n",
        "y_pred_s = model.predict(x_test_norm_s)\n",
        "y_pred_s.shape, y_test_s.shape\n",
        "\n",
        "y_test_s = y_test_s.argmax(axis=-1)\n",
        "print('y_test_s', y_test_s)\n",
        "y_pred_s = y_pred_s.argmax(axis=-1)\n",
        "print('y_pred_s',y_pred_s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_test_s [3 2 2 2 2 2 1 1 1 1 1 1 1 1 0 2 2 3 3 3 3 2 2 1 1 1 1 1 1 1 1 1 1 1 4 3 3\n",
            " 2 4 1 0 1 1 1 1 1 1 0 1 1 0 0 1 2 2 4 2 2 2 1 1 1 1 0 1 1 2 1 3 2 2 3 3 2\n",
            " 3 3 2 1 0 0 1 1 1 1 0 0 0 0 1 2 4 2 1 1 0 1 0 1 0 0 0 0 1 1 1 2 2 2 1 3 1\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4]\n",
            "y_pred_s [3 2 2 2 2 2 1 0 0 1 0 0 0 0 1 2 2 2 2 3 3 2 2 1 0 1 1 1 1 1 0 0 1 2 4 3 3\n",
            " 3 4 0 0 0 0 0 0 0 1 0 1 0 0 1 0 2 2 4 2 1 1 2 1 1 1 0 1 1 2 2 3 2 2 3 3 3\n",
            " 3 2 3 0 1 0 1 1 0 0 0 0 0 0 2 3 4 2 2 1 0 0 1 0 0 0 0 1 1 0 1 3 2 3 3 3 1\n",
            " 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 2 0 0 0 0 0 0 0 0 1\n",
            " 0 1 0 0 0 0 0 0 3 2 3 1 2 1 2 2 2 2 1 3 2 2 2 3 2 2 2 1 2 2 2 2 2 3 4 2 2\n",
            " 2 2 0 0 2 2 1 2 3 3 4 3 3 3 2 3 3 3 3 3 3 2 3 3 2 3 3 2 3 2 4 2 4 3 3 3 3\n",
            " 3 3 3 4 3 3 3 3 3 2 1 4 3 3 4 3 3 3 1 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 4 3\n",
            " 4 3 4 3 4 4 4 3 4 4 4 3 3 2 4 3 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4\n",
            " 4 4 2 4 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8D_jq6a8ejv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f88042b-eec8-408e-a9d7-f855080c8c69"
      },
      "source": [
        "#Compute Recall, precision, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_s, y_pred_s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.77      0.71        61\n",
            "           1       0.53      0.45      0.49        53\n",
            "           2       0.68      0.66      0.67        62\n",
            "           3       0.72      0.75      0.74        76\n",
            "           4       0.82      0.76      0.79        49\n",
            "\n",
            "    accuracy                           0.68       301\n",
            "   macro avg       0.68      0.68      0.68       301\n",
            "weighted avg       0.68      0.68      0.68       301\n",
            "\n"
          ]
        }
      ]
    }
  ]
}